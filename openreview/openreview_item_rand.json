[{"number": "2150", "title": "On Symmetry and Initialization for Neural Networks", "authors": "['Ido Nachum', 'Amir Yehudayoff']", "abstract": "This work provides an additional step in the theoretical understanding of neural networks. We consider neural networks with one hidden layer and show that when learning symmetric functions, one can choose initial conditions so that standard SGD training efficiently produces generalization guarantees. We empirically verify this and show that this does not hold when the initial conditions are chosen at random. The proof of convergence investigates the interaction between the two layers of the network. Our results highlight the importance of using symmetry in the design of neural networks.", "pdf": "/pdf/aa42c4a7138b364449b57f898bc18731cab6cb3d.pdf", "keywords": "['Neural Network Theory', 'Symmetry']", "id": "Skeh-xBYDH"}, {"number": "690", "title": "Demonstration Actor Critic", "authors": "['Guoqing Liu', 'Li Zhao', 'Pushi Zhang', 'Jiang Bian', 'Tao Qin', 'Nenghai Yu', 'Tie-Yan Liu']", "abstract": "We study the problem of \\textit{Reinforcement learning from demonstrations (RLfD)}, where the learner is provided with both some expert demonstrations and reinforcement signals from the environment. One approach leverages demonstration data in a supervised manner, which is simple and direct, but can only provide supervision signal over those states seen in the demonstrations. Another approach uses demonstration data for reward shaping. By contrast, the latter approach can provide guidance on how to take actions, even for those states are not seen in the demonstrations. But existing algorithms in the latter one adopt shaping reward which is not directly dependent on current policy, limiting the algorithms to treat demonstrated states the same as other states, failing to directly exploit supervision signal in demonstration data. In this paper, we propose a novel objective function with policy-dependent shaping reward, so as to get the best of both worlds. We present a convergence proof for policy iteration of the proposed objective, under the tabular setting. Then we develop a new practical algorithm, termed as Demonstration Actor Critic (DAC). Experiments on a range of popular benchmark sparse-reward tasks shows that our DAC method obtains a significant performance gain over five strong and off-the-shelf baselines.", "pdf": "/pdf/da604872980e8c14b2fedbca47e6be8ab7ea3bc7.pdf", "keywords": "['Deep Reinforcement Learning', 'Reinforcement Learning from Demonstration']", "id": "BklRFpVKPH"}, {"number": "563", "title": "BRIDGING ADVERSARIAL SAMPLES AND ADVERSARIAL NETWORKS", "authors": "['Faqiang Liu', 'Mingkun Xu', 'Guoqi Li', 'Jing Pei', 'Luping Shi']", "abstract": "Generative adversarial networks have achieved remarkable performance on various tasks but suffer from sensitivity to hyper-parameters, training instability, and mode collapse. We find that this is partly due to gradient given by non-robust discriminator containing non-informative adversarial noise, which can hinder generator from catching the pattern of real samples. Inspired by defense against adversarial samples, we introduce adversarial training of discriminator on real samples that does not exist in classic GANs framework to make adversarial training symmetric, which can balance min-max game and make discriminator more robust. Robust discriminator can give more informative gradient with less adversarial noise, which can stabilize training and accelerate convergence. We validate the proposed method on image generation tasks with varied network architectures quantitatively. Experiments show that training stability, perceptual quality, and diversity of generated samples are consistently improved with small additional training computation cost.", "pdf": "/pdf/8caf970a168bc127b73b97459466ad55939b8e1c.pdf", "keywords": "['ADVERSARIAL SAMPLES', 'ADVERSARIAL NETWORKS']", "id": "rklPITVKvS"}, {"number": "1900", "title": "Improving Model Compatibility of Generative Adversarial Networks by Boundary Calibration", "authors": "['Si-An Chen', 'Chun-Liang Li', 'Hsuan-Tien Lin']", "abstract": "Generative Adversarial Networks (GANs) is a powerful family of models that learn an underlying distribution to generate synthetic data. Many existing studies of GANs focus on improving the realness of the generated image data for visual applications, and few of them concern about improving the quality of the generated data for training other classifiers---a task known as the model compatibility problem. As a consequence, existing GANs often prefer generating `easier' synthetic data that are far from the boundaries of the classifiers, and refrain from generating near-boundary data, which are known to play an important roles in training the classifiers. To improve GAN in terms of model compatibility, we propose Boundary-Calibration GANs (BCGANs), which leverage the boundary information from a set of pre-trained classifiers using the original data. In particular, we introduce an auxiliary Boundary-Calibration loss (BC-loss) into the generator of GAN to match the statistics between the posterior distributions of original data and generated data with respect to the boundaries of the pre-trained classifiers. The BC-loss is provably unbiased and can be easily coupled with different GAN variants to improve their model compatibility. Experimental results demonstrate that BCGANs not only generate realistic images like original GANs but also achieves superior model compatibility than the original GANs.", "pdf": "/pdf/c5ed91773940f5fb1cb2104bb9d3af2d6403f165.pdf", "keywords": "['generative adversarial network', 'GAN', 'model compatibility', 'machine learning efficacy']", "id": "S1xJikHtDH"}, {"number": "2125", "title": "Unsupervised Learning of Efficient and Robust Speech Representations", "authors": "['Kazuya Kawakami', 'Luyu Wang', 'Chris Dyer', 'Phil Blunsom', 'Aaron van den Oord']", "abstract": "We present an unsupervised method for learning speech representations based on a bidirectional contrastive predictive coding that implicitly discovers phonetic structure from large-scale corpora of unlabelled raw audio signals. The representations, which we learn from up to 8000 hours of publicly accessible speech data, are evaluated by looking at their impact on the behaviour of supervised speech recognition systems. First, across a variety of datasets, we find that the features learned from the largest and most diverse pretraining dataset result in significant improvements over standard audio features as well as over features learned from smaller amounts of pretraining data. Second, they significantly improve sample efficiency in low-data scenarios. Finally, the features confer significant robustness advantages to the resulting recognition systems: we see significant improvements in out-of-domain transfer relative to baseline feature sets, and the features likewise provide improvements in four different low-resource African language datasets.", "pdf": "/pdf/ef7d5e36057351c491522b302edba745f51f0b3c.pdf", "keywords": "[]", "id": "HJe-blSYvH"}, {"number": "691", "title": "Influence-Based Multi-Agent Exploration", "authors": "['Tonghan Wang*', 'Jianhao Wang*', 'Yi Wu', 'Chongjie Zhang']", "abstract": "Intrinsically motivated reinforcement learning aims to address the exploration challenge for sparse-reward tasks. However, the study of exploration methods in transition-dependent multi-agent settings is largely absent from the literature. We aim to take a step towards solving this problem. We present two exploration methods: exploration via information-theoretic influence (EITI) and exploration via decision-theoretic influence (EDTI), by exploiting the role of interaction in coordinated behaviors of agents. EITI uses mutual information to capture the interdependence between the transition dynamics of agents. EDTI uses a novel intrinsic reward, called Value of Interaction (VoI), to characterize and quantify the influence of one agent's behavior on expected returns of other agents. By optimizing EITI or EDTI objective as a regularizer, agents are encouraged to coordinate their exploration and learn policies to optimize the team performance. We show how to optimize these regularizers so that they can be easily integrated with policy gradient reinforcement learning. The resulting update rule draws a connection between coordinated exploration and intrinsic reward distribution. Finally, we empirically demonstrate the significant strength of our methods in a variety of multi-agent scenarios.", "pdf": "/pdf/ed71e74b6d27183d7d2c1f422be6180d56ea7698.pdf", "keywords": "['Multi-agent reinforcement learning', 'Exploration']", "id": "BJgy96EYvr"}, {"number": "2553", "title": "Conservative Uncertainty Estimation By Fitting  Prior Networks", "authors": "['Kamil Ciosek', 'Vincent Fortuin', 'Ryota Tomioka', 'Katja Hofmann', 'Richard Turner']", "abstract": "Obtaining high-quality uncertainty estimates is essential for many applications of deep neural networks. In this paper, we theoretically justify a scheme for estimating uncertainties, based on sampling from a prior distribution. Crucially, the uncertainty estimates are shown to be conservative in the sense that they never underestimate a posterior uncertainty obtained by a hypothetical Bayesian algorithm. We also show concentration, implying that the uncertainty estimates converge to zero as we get more data. Uncertainty estimates obtained from random priors can be adapted to any deep network architecture and trained using standard supervised learning pipelines. We provide experimental evaluation of random priors on calibration and out-of-distribution detection on typical computer vision tasks, demonstrating that they outperform deep ensembles in practice.", "pdf": "/pdf/523d0ff6817176db2a8897bf673b70ca56eb81c8.pdf", "keywords": "['uncertainty quantification', 'deep learning', 'Gaussian process', 'epistemic uncertainty', 'random network', 'prior', 'Bayesian inference']", "id": "BJlahxHYDS"}, {"number": "770", "title": "Attention Privileged Reinforcement Learning for Domain Transfer", "authors": "['Sasha Salter', 'Dushyant Rao', 'Markus Wulfmeier', 'Raia Hadsell', 'Ingmar Posner']", "abstract": "Applying reinforcement learning (RL) to physical systems presents notable challenges, given requirements regarding sample efficiency, safety, and physical constraints compared to simulated environments. To enable transfer of policies trained in simulation, randomising simulation parameters leads to more robust policies, but also in significantly extended training time. In this paper, we exploit access to privileged information (such as environment states) often available in simulation, in order to improve and accelerate learning over randomised environments. We introduce Attention Privileged Reinforcement Learning (APRiL), which equips the agent with an attention mechanism and makes use of state information in simulation, learning to align attention between state- and image-based policies while additionally sharing generated data. During deployment we can apply the image-based policy to remove the requirement of access to additional information. We experimentally demonstrate accelerated and more robust learning on a number of diverse domains, leading to improved final performance for environments both within and outside the training distribution.", "pdf": "/pdf/e5ed55d3a5a2cc3008b419f807d56125b36bce33.pdf", "keywords": "['sim-to-real', 'domain randomisation', 'attention', 'transfer learning', 'reinforcement learning']", "id": "HygW26VYwS"}, {"number": "2503", "title": "Critical initialisation in continuous approximations of binary neural networks", "authors": "['George Stamatescu', 'Federica Gerace', 'Carlo Lucibello', 'Ian Fuss', 'Langford White']", "abstract": "The training of stochastic neural network models with binary ($\\pm1$) weights and activations via continuous surrogate networks is investigated. We derive new surrogates using a novel derivation based on writing the stochastic neural network as a Markov chain. This derivation also encompasses existing variants of the surrogates presented in the literature. Following this, we theoretically study the surrogates at initialisation. We derive, using mean field theory, a set of scalar equations describing how input signals propagate through the randomly initialised networks. The equations reveal whether so-called critical initialisations exist for each surrogate network, where the network can be trained to arbitrary depth. Moreover, we predict theoretically and confirm numerically, that common weight initialisation schemes used in standard continuous networks, when applied to the mean values of the stochastic binary weights, yield poor training performance. This study shows that, contrary to common intuition, the means of the stochastic binary weights should be initialised close to $\\pm 1$, for deeper networks to be trainable.", "pdf": "/pdf/71a41b43a6dc91d6e4322cb83f251fd555711e7e.pdf", "keywords": "[]", "id": "rylmoxrFDH"}, {"number": "1904", "title": "Self-labelling via simultaneous clustering and representation learning", "authors": "['Asano YM.', 'Rupprecht C.', 'Vedaldi A.']", "abstract": "Combining clustering and representation learning is one of the most promising approaches for unsupervised learning of deep neural networks. However, doing so naively leads to ill posed learning problems with degenerate solutions.\nIn this paper, we propose a novel and principled learning formulation that addresses these issues.\nThe method is obtained by maximizing the information between labels and input data indices.\nWe show that this criterion extends standard cross-entropy minimization to an optimal transport problem, which we solve efficiently for millions of input images and thousands of labels using a fast variant of the Sinkhorn-Knopp algorithm.\nThe resulting method is able to self-label visual data so as to train highly competitive image representations without manual labels. Our method achieves state of the art representation learning performance for AlexNet and ResNet-50 on SVHN, CIFAR-10, CIFAR-100 and ImageNet and yields the first self-supervised AlexNet that outperforms the supervised Pascal VOC detection baseline. ", "pdf": "/pdf/7139bd6cf4eabdaff3fc07ec37d30cf8dd25c27b.pdf", "keywords": "['self-supervision', 'feature representation learning', 'clustering']", "id": "Hyx-jyBFPr"}, {"number": "1113", "title": "Four Things Everyone Should Know to Improve Batch Normalization", "authors": "['Cecilia Summers', 'Michael J. Dinneen']", "abstract": "A key component of most neural network architectures is the use of normalization layers, such as Batch Normalization. Despite its common use and large utility in optimizing deep architectures, it has been challenging both to generically improve upon Batch Normalization and to understand the circumstances that lend themselves to other enhancements. In this paper, we identify four improvements to the generic form of Batch Normalization and the circumstances under which they work, yielding performance gains across all batch sizes while requiring no additional computation during training. These contributions include proposing a method for reasoning about the current example in inference normalization statistics, fixing a training vs. inference discrepancy; recognizing and validating the powerful regularization effect of Ghost Batch Normalization for small and medium batch sizes; examining the effect of weight decay regularization on the scaling and shifting parameters  and ; and identifying a new normalization algorithm for very small batch sizes by combining the strengths of Batch and Group Normalization. We validate our results empirically on six datasets: CIFAR-100, SVHN, Caltech-256, Oxford Flowers-102, CUB-2011, and ImageNet.", "pdf": "/pdf/87f243a3aaed725e0ae736b85445ae61f09b7cb1.pdf", "keywords": "['batch normalization']", "id": "HJx8HANFDH"}, {"number": "586", "title": "Risk Averse Value Expansion for Sample Efficient and Robust Policy Learning", "authors": "['Bo Zhou', 'Fan Wang', 'Hongsheng Zeng', 'Hao Tian']", "abstract": "Model-based Reinforcement Learning(RL) has shown great advantage in sample-efficiency, but suffers from poor asymptotic performance and high inference cost. A promising direction is to combine model-based reinforcement learning with model-free reinforcement learning, such as model-based value expansion(MVE). However, the previous methods do not take into account the stochastic character of the environment, thus still suffers from higher function approximation errors. As a result, they tend to fall behind the best model-free algorithms in some challenging scenarios. We propose a novel Hybrid-RL method, which is developed from MVE, namely the Risk Averse Value Expansion(RAVE). In the proposed method, we use an ensemble of probabilistic models for environment modeling to generate imaginative rollouts, based on which we further introduce the aversion of risks by seeking the lower confidence bound of the estimation. Experiments on different environments including MuJoCo and robo-school show that RAVE yields state-of-the-art performance. Also we found that it greatly prevented some catastrophic consequences such as falling down and thus reduced the variance of the rewards.", "pdf": "/pdf/14b062bf6d157f7f3358ed599c51ec26d9dcaba3.pdf", "keywords": "['reinforcement learning', 'model-based RL', 'risk-sensitive', 'sample efficiency']", "id": "SJlbvp4YvS"}, {"number": "1380", "title": "JAUNE: Justified And Unified Neural language Evaluation", "authors": "['Hassan Kan\u00e9', 'Yusuf Kocyigit', 'Ali Abdalla', 'Pelkins Ajanoh', 'Mohamed Coulibali']", "abstract": "We review the limitations of BLEU and ROUGE -- the most popular metrics used to assess reference summaries against hypothesis summaries, and introduce JAUNE:  a set of criteria for what a good metric should behave like and propose concrete ways to use recent Transformers-based Language Models to assess reference summaries against hypothesis summaries.\n\n", "pdf": "/pdf/616f357613725fba95999854273bd25f362ad7d5.pdf", "keywords": "['NLP', 'Evaluation Metrics', 'Summarization', 'Translation', 'BLEU', 'ROUGE', 'Transformers']", "id": "r1gx60NKPS"}, {"number": "2406", "title": "Classification-Based Anomaly Detection for General Data", "authors": "['Liron Bergman', 'Yedid Hoshen']", "abstract": "Anomaly detection, finding patterns that substantially deviate from those seen previously, is one of the fundamental problems of artificial intelligence. Recently, classification-based methods were shown to achieve superior results on this task. In this work, we present a unifying view and propose an open-set method, GOAD, to relax current generalization assumptions. Furthermore, we extend the applicability of transformation-based methods to non-image data using random affine transformations. Our method is shown to obtain state-of-the-art accuracy and is applicable to broad data types. The strong performance of our method is extensively validated on multiple datasets from different domains.  ", "pdf": "/pdf/0cc1c7474fb7a5d646d371f84aef56b3e920caa7.pdf", "keywords": "['anomaly detection']", "id": "H1lK_lBtvS"}, {"number": "143", "title": "Mincut Pooling in Graph Neural Networks", "authors": "['Filippo Maria Bianchi', 'Daniele Grattarola', 'Cesare Alippi']", "abstract": "The advance of node pooling operations in Graph Neural Networks (GNNs) has lagged behind the feverish design of new message-passing techniques, and pooling remains an important and challenging endeavor for the design of deep architectures.\nIn this paper, we propose a pooling operation for GNNs that leverages a differentiable unsupervised loss based on the minCut optimization objective.\nFor each node, our method learns a soft cluster assignment vector that depends on the node features, the target inference task (e.g., a graph classification loss), and, thanks to the minCut objective, also on the connectivity structure of the graph.\nGraph pooling is obtained by applying the matrix of assignment vectors to the adjacency matrix and the node features.\nWe validate the effectiveness of the proposed pooling method on a variety of supervised and unsupervised tasks.", "pdf": "/pdf/9e4420fa6fb6f26c557ab4bb4d618eb2cf4ece5f.pdf", "keywords": "['Graph Neural Networks', 'Pooling', 'Graph Cuts', 'Spectral Clustering']", "id": "BkxfshNYwB"}, {"number": "119", "title": "Analytical Moment Regularizer for Training Robust Networks", "authors": "['Modar Alfadly', 'Adel Bibi', 'Muhammed Kocabas', 'Bernard Ghanem']", "abstract": "Despite the impressive performance of deep neural networks (DNNs) on numerous learning  tasks, they still exhibit uncouth behaviours. One puzzling behaviour is the subtle sensitive reaction of DNNs to various noise attacks. Such a nuisance has strengthened the line of research around developing and training noise-robust networks. In this work, we propose a new training regularizer that aims to minimize the probabilistic expected training loss of a DNN subject to a generic Gaussian input. We provide an efficient and simple approach to approximate such a regularizer for arbitrarily deep networks. This is done by leveraging the analytic expression of the output mean of a shallow neural network, avoiding the need for memory and computation expensive data augmentation. We conduct extensive experiments on LeNet and AlexNet on various datasets including MNIST, CIFAR10, and CIFAR100 to demonstrate the effectiveness of our proposed regularizer. In particular, we show that networks that are trained with the proposed regularizer benefit from a boost in robustness against Gaussian noise to an equivalent amount of performing 3-21 folds of noisy data augmentation. Moreover, we empirically show on several architectures and datasets that improving robustness against Gaussian noise, by using the new regularizer, can improve the overall robustness against 6 other types of attacks by two orders of magnitude.", "pdf": "/pdf/49aa146261ded92b6fa112444b84b290b0ab0a3b.pdf", "keywords": "['robustness', 'analytic regularizer', 'first moment']", "id": "B1xDq2EFDH"}, {"number": "2238", "title": "Ergodic Inference: Accelerate Convergence by Optimisation", "authors": "['Yichuan Zhang', 'Jos\u00e9 Miguel Hern\u00e1ndez-Lobato']", "abstract": "Statistical inference methods are fundamentally important in machine learning. Most state-of-the-art inference algorithms are \nvariants of Markov chain Monte Carlo (MCMC) or variational inference (VI). However, both methods struggle with limitations in practice: MCMC methods can be computationally demanding; VI methods may have large bias. \nIn this work, we aim to improve upon MCMC and VI by a novel hybrid method based on the idea of reducing simulation bias of finite-length MCMC chains using gradient-based optimisation. The proposed method can generate low-biased samples by increasing the length of MCMC simulation and optimising the MCMC hyper-parameters, which offers attractive balance between approximation bias and computational efficiency. We show that our method produces promising results on popular benchmarks when compared to recent hybrid methods of MCMC and VI.", "pdf": "/pdf/07f4cf199dc7b56ec074e6497b02d445e080cb91.pdf", "keywords": "['MCMC', 'variational inference', 'statistical inference']", "id": "HkxZVlHYvH"}, {"number": "236", "title": "MULTIPOLAR: Multi-Source Policy Aggregation for Transfer Reinforcement Learning between Diverse Environmental Dynamics", "authors": "['Mohammadamin Barekatain', 'Ryo Yonetani', 'Masashi Hamaya']", "abstract": "Transfer reinforcement learning (RL) aims at improving learning efficiency of an agent by exploiting knowledge from other source agents trained on relevant tasks. However, it remains challenging to transfer knowledge between different environmental dynamics without having access to the source environments. In this work, we explore a new challenge in transfer RL, where only a set of source policies collected under unknown diverse dynamics is available for learning a target task efficiently. To address this problem, the proposed approach, MULTI-source POLicy AggRegation (MULTIPOLAR), comprises two key techniques. We learn to aggregate the actions provided by the source policies adaptively to maximize the target task performance. Meanwhile, we learn an auxiliary network that predicts residuals around the aggregated actions, which ensures the target policy's expressiveness even when some of the source policies perform poorly. We demonstrated the effectiveness of MULTIPOLAR through an extensive experimental evaluation across six simulated environments ranging from classic control problems to challenging robotics simulations, under both continuous and discrete action spaces.", "pdf": "/pdf/12f36cd088194283da579be18d2ae84dfd64b851.pdf", "keywords": "['reinforcement learning', 'transfer learning', 'policy aggregation', 'residual policy learning']", "id": "Byx9p2EtDH"}, {"number": "2423", "title": "Differentiable learning of numerical rules in knowledge graphs", "authors": "['Po-Wei Wang', 'Daria Stepanova', 'Csaba Domokos', 'J. Zico Kolter']", "abstract": "Rules over a knowledge graph (KG) capture interpretable patterns in data and can be used for KG cleaning and completion. Inspired by the TensorLog differentiable logic framework, which compiles rule inference into a sequence of differentiable operations, recently a method called Neural LP has been proposed for learning the parameters as well as the structure of rules. However, it is limited with respect to the treatment of numerical features like age, weight or scientific measurements. We address this limitation by extending Neural LP to learn rules with numerical values, e.g., People younger than 18 typically live with their parents. We demonstrate how dynamic programming and cumulative sum operations can be exploited to ensure efficiency of such extension. Our novel approach allows us to extract more expressive rules with aggregates, which are of higher quality and yield more accurate predictions compared to rules learned by the state-of-the-art methods, as shown by our experiments on synthetic and real-world datasets.", "pdf": "/pdf/d66021fe991280447daf0d6a7e0f577b9a11b7ed.pdf", "keywords": "['knowledge graphs', 'rule learning', 'differentiable neural logic']", "id": "rJleKgrKwS"}, {"number": "2313", "title": "FLAT MANIFOLD VAES", "authors": "['Nutan Chen', 'Alexej Klushyn', 'Francesco Ferroni', 'Justin Bayer', 'Patrick van der Smagt']", "abstract": "Latent-variable models represent observed data by mapping a prior distribution over some latent space to an observed space.  Often, the prior distribution is specified by the user to be very simple, effectively shifting the burden of a learning algorithm to the estimation of a highly non-linear likelihood function. This poses a problem for the calculation of a popular distance function, the geodesic between data points in the latent space, as this is often solved iteratively via numerical methods. These are less effective if the problem at hand is not well captured by first or second-order approximations. In this work, we propose less complex likelihood functions by allowing complex distributions and explicitly penalising the curvature of the decoder. This results in geodesics which are approximated well by the Euclidean distance in latent space, decreasing the runtime by a factor of 1,000 with little loss in accuracy. \n", "pdf": "/pdf/52b2c77d9004895f05a92318c8ab46a48076fcb2.pdf", "keywords": "[]", "id": "SkgWIxSFvr"}, {"number": "38", "title": "Out-of-Distribution Detection Using Layerwise Uncertainty in Deep Neural Networks", "authors": "['Hirono Okamoto', 'Masahiro Suzuki', 'Yutaka Matsuo']", "abstract": "In this paper, we tackle the problem of detecting samples that are not drawn from the training distribution, i.e., out-of-distribution (OOD) samples, in classification. Many previous studies have attempted to solve this problem by regarding samples with low classification confidence as OOD examples using deep neural networks (DNNs). However, on difficult datasets or models with low classification ability, these methods incorrectly regard in-distribution samples close to the decision boundary as OOD samples. This problem arises because their approaches use only the features close to the output layer and disregard the uncertainty of the features. Therefore, we propose a method that extracts the uncertainties of features in each layer of DNNs using a reparameterization trick and combines them. In experiments, our method outperforms the existing methods by a large margin, achieving state-of-the-art detection performance on several datasets and classification models. For example, our method increases the AUROC score of prior work (83.8%) to 99.8% in DenseNet on the CIFAR-100 and Tiny-ImageNet datasets.", "pdf": "/pdf/699ccba976fc09e43c43f59a9c7053400d6f6abf.pdf", "keywords": "['out-of-distribution', 'uncertainty']", "id": "rklVOnNtwH"}, {"number": "1267", "title": "Probabilistic Connection Importance Inference and Lossless Compression of Deep Neural Networks", "authors": "['Xin Xing', 'Long Sha', 'Pengyu Hong', 'Zuofeng Shang', 'Jun S. Liu']", "abstract": "Deep neural networks (DNNs) can be huge in size, requiring a considerable a mount of energy and computational resources to operate, which limits their applications in numerous scenarios. It is thus of interest to compress DNNs while maintaining their performance levels.  We here propose a probabilistic importance inference approach for pruning DNNs. Specifically, we test the significance of the relevance of a connection in a DNN to the DNNs outputs using a nonparemtric scoring testand keep only those significant ones. Experimental results show that the proposed approach achieves better lossless compression rates than existing techniques", "pdf": "/pdf/0b4d4acde853a70c2593060c34e9c3d57e83700f.pdf", "keywords": "[]", "id": "HJgCF0VFwr"}, {"number": "497", "title": "Do Image Classifiers Generalize Across Time?", "authors": "['Vaishaal Shankar', 'Achal Dave', 'Rebecca Roelofs', 'Deva Ramanan', 'Ben Recht', 'Ludwig Schmidt']", "abstract": "We study the robustness of image classifiers to temporal perturbations derived from videos. As part of this study, we construct ImageNet-Vid-Robust and YTBB-Robust, containing a total 57,897 images grouped into 3,139 sets of perceptually similar images. Our datasets were derived from ImageNet-Vid and Youtube-BB respectively and thoroughly re-annotated by human experts for image similarity. We evaluate a diverse array of classifiers pre-trained on ImageNet and show a median classification accuracy drop of 16 and 10 percent on our two datasets. Additionally, we evaluate three detection models and show that natural perturbations induce both classification as well as localization errors, leading to a median drop in detection mAP of 14 points. Our analysis demonstrates that perturbations occurring naturally in videos pose a substantial and realistic challenge to deploying convolutional neural networks in environments that require both reliable and low-latency predictions.", "pdf": "/pdf/6a70b8252f8901af3e6b77af6fe6ac6ecc30b2d4.pdf", "keywords": "['robustness', 'image classification', 'distribution shift']", "id": "Syx9ET4YPB"}, {"number": "2529", "title": "FINBERT:  FINANCIAL SENTIMENT ANALYSIS   WITH PRE-TRAINED LANGUAGE MODELS", "authors": "['Dogu Araci', 'Zulkuf Genc']", "abstract": "While many sentiment classification solutions report  high accuracy scores in product or movie review datasets, the performance of the methods in niche domains such as finance still largely falls behind. The reason of this gap is the domain-specific language, which decreases the applicability of existing models, and lack of quality labeled data to learn the new context of positive and negative in the specific domain. Transfer learning has been shown to be successful in adapting to new domains without large training data sets. In this paper, we explore the effectiveness of NLP transfer learning in financial sentiment classification. We introduce FinBERT, a language model based on BERT, which improved the state-of-the-art performance by 14 percentage points for a financial sentiment classification task in FinancialPhrasebank dataset.", "pdf": "/pdf/5dbefc43f37cf73dbcb6ad14c3b31b99748296fa.pdf", "keywords": "['Financial sentiment analysis', 'financial text classification', 'transfer learning', 'pre-trained language models', 'BERT', 'NLP']", "id": "HylznxrYDr"}, {"number": "2535", "title": "Learning to Coordinate Manipulation Skills via Skill Behavior Diversification", "authors": "['Youngwoon Lee', 'Jingyun Yang', 'Joseph J. Lim']", "abstract": "When mastering a complex manipulation task, humans often decompose the task into sub-skills of their body parts, practice the sub-skills independently, and then execute the sub-skills together. Similarly, a robot with multiple end-effectors can perform complex tasks by coordinating sub-skills of each end-effector. To realize temporal and behavioral coordination of skills, we propose a modular framework that first individually trains sub-skills of each end-effector with skill behavior diversification, and then learns to coordinate end-effectors using diverse behaviors of the skills. We demonstrate that our proposed framework is able to efficiently coordinate skills to solve challenging collaborative control tasks such as picking up a long bar, placing a block inside a container while pushing the container with two robot arms, and pushing a box with two ant agents. Videos and code are available at https://clvrai.com/coordination", "pdf": "/pdf/b91b8720df5d00e5d36d1b9877ba04c392abb48a.pdf", "keywords": "['reinforcement learning', 'hierarchical reinforcement learning', 'modular framework', 'skill coordination', 'bimanual manipulation']", "id": "ryxB2lBtvH"}, {"number": "654", "title": "DeepEnFM: Deep neural networks with Encoder enhanced Factorization Machine", "authors": "['Qiang Sun', 'Zhinan Cheng', 'Yanwei Fu', 'Wenxuan Wang', 'Yu-Gang Jiang', 'Xiangyang Xue']", "abstract": "Click Through Rate (CTR) prediction is a critical task in industrial applications, especially for online social and commerce applications. It is challenging to find a proper way to automatically discover the effective cross features in CTR tasks. We propose a novel model for CTR tasks, called Deep neural networks with Encoder enhanced Factorization Machine (DeepEnFM). Instead of learning the cross features directly, DeepEnFM adopts the Transformer encoder as a backbone to align the feature embeddings with the clues of other fields. The embeddings generated from encoder are beneficial for the further feature interactions. Particularly, DeepEnFM utilizes a bilinear approach to generate different similarity functions with respect to different field pairs. Furthermore, the max-pooling method makes DeepEnFM feasible to capture both the supplementary and suppressing information among different attention heads. Our model is validated on the Criteo and Avazu datasets, and achieves state-of-art performance.", "pdf": "/pdf/172f7a073710dcf32034814f99bd0b87fa2d863c.pdf", "keywords": "['CTR', 'Attention', 'Transformer', 'Encoder']", "id": "SJlyta4YPS"}, {"number": "426", "title": "How many weights are enough : can tensor factorization learn efficient policies ?", "authors": "['Pierre H. Richemond', 'Arinbjorn Kolbeinsson', 'Yike Guo']", "abstract": "Deep reinforcement learning requires a heavy price in terms of sample efficiency and overparameterization in the neural networks used for function approximation. In this work, we employ tensor factorization in order to learn more compact representations for reinforcement learning policies. We show empirically that in the low-data regime, it is possible to learn online policies with 2 to 10 times less total coefficients, with little to no loss of performance. We also leverage progress in second order optimization, and use the theory of wavelet scattering to further reduce the number of learned coefficients, by foregoing learning the topmost convolutional layer filters altogether. We evaluate our results on the Atari suite against recent baseline algorithms that represent the state-of-the-art in data efficiency, and get comparable results with an order of magnitude gain in weight parsimony.", "pdf": "/pdf/d460c69d0084c2a2642e45a213ca42d7616f8254.pdf", "keywords": "['reinforcement learning', 'Q-learning', 'tensor factorization', 'low-rank approximation', 'data efficiency', 'second-order optimization', 'scattering']", "id": "B1l3M64KwB"}, {"number": "1229", "title": "Capsules with Inverted Dot-Product Attention Routing", "authors": "['Yao-Hung Hubert Tsai', 'Nitish Srivastava', 'Hanlin Goh', 'Ruslan Salakhutdinov']", "abstract": "We introduce a new routing algorithm for capsule networks, in which a child capsule is routed to a parent based only on agreement between the parent's state and the child's vote. \nThe new mechanism 1) designs routing via inverted dot-product attention; 2) imposes Layer Normalization as normalization; and 3) replaces sequential iterative routing with concurrent iterative routing.\nWhen compared to previously proposed routing algorithms, our method improves performance on benchmark datasets such as CIFAR-10 and CIFAR-100, and it performs at-par with a powerful CNN (ResNet-18) with 4x fewer parameters.\nOn a different task of recognizing digits from overlayed digit images, the proposed capsule model performs favorably against CNNs given the same number of layers and neurons per layer.  We believe that our work raises the possibility of applying capsule networks to complex real-world tasks.", "pdf": "/pdf/55eedfff3a825776360fe3304b2c369506e2070b.pdf", "keywords": "['capsule networks', 'routing', 'attention']", "id": "HJe6uANtwH"}, {"number": "401", "title": "Learning Self-Correctable Policies and Value Functions from Demonstrations with Negative Sampling", "authors": "['Yuping Luo', 'Huazhe Xu', 'Tengyu Ma']", "abstract": "Imitation learning, followed by reinforcement learning algorithms, is a promising paradigm to solve complex control tasks sample-efficiently. However, learning from demonstrations often suffers from the covariate shift problem, which results\nin cascading errors of the learned policy. We introduce a notion of conservatively extrapolated value functions, which provably lead to policies with self-correction. We design an algorithm Value Iteration with Negative Sampling (VINS) that practically learns such value functions with conservative extrapolation. We show that VINS can correct mistakes of the behavioral cloning policy on simulated robotics benchmark tasks. We also propose the algorithm of using VINS to initialize a reinforcement learning algorithm, which is shown to outperform prior works in sample efficiency.", "pdf": "/pdf/ffd4070fdb6f1ce2691d35def62153b18778730d.pdf", "keywords": "['imitation learning', 'model-based imitation learning', 'model-based RL', 'behavior cloning', 'covariate shift']", "id": "rke-f6NKvS"}, {"number": "534", "title": "Generative Adversarial Networks For Data Scarcity Industrial Positron Images With Attention", "authors": "['Mingwei Zhu', 'Min Zhao', 'Min Yao', 'Ruipeng Guo']", "abstract": "In the industrial field, the positron annihilation is not affected by complex environment, and the gamma-ray photon penetration is strong, so the nondestructive detection of industrial parts can be realized. Due to the poor image quality caused by gamma-ray photon scattering, attenuation and short sampling time in positron process, we propose the idea of combining deep learning to generate positron images with good quality and clear details by adversarial nets. The structure of the paper is as follows: firstly, we encode to get the hidden vectors of medical CT images based on transfer Learning, and use PCA to extract positron image features. Secondly, we construct a positron image memory based on attention mechanism as a whole input to the adversarial nets which uses medical hidden variables as a query. Finally, we train the whole model jointly and update the input parameters until convergence. Experiments have proved the possibility of generating rare positron images for industrial non-destructive testing using countermeasure networks, and good imaging results have been achieved.", "pdf": "/pdf/ec84da186c47d5983042e4bfe010bdb6baeeba64.pdf", "keywords": "[]", "id": "SkxcSpEKPS"}, {"number": "2334", "title": "Imitation Learning of Robot Policies using Language, Vision and Motion", "authors": "['Simon Stepputtis', 'Joseph Campbell', 'Mariano Phielipp', 'Chitta Baral', 'Heni Ben Amor']", "abstract": "In this work we propose a novel end-to-end imitation learning approach which combines natural language, vision, and motion information to produce an abstract representation of a task, which in turn can be used to synthesize specific motion controllers at run-time. This multimodal approach enables generalization to a wide variety of environmental conditions and allows an end-user to influence a robot policy through verbal communication. We empirically validate our approach with an extensive set of simulations and show that it achieves a high task success rate over a variety of conditions while remaining amenable to probabilistic interpretability.", "pdf": "/pdf/d1d3892cfb7b4019c297d2a42c1e31c139b360e9.pdf", "keywords": "['robot learning', 'imitation learning', 'natural language processing']", "id": "Bkg5LgrYwS"}, {"number": "790", "title": "Optimizing Data Usage via Differentiable Rewards", "authors": "['Xinyi Wang', 'Hieu Pham', 'Paul Michel', 'Antonios Anastasopoulos', 'Graham Neubig', 'Jaime Carbonell']", "abstract": "To acquire a new skill, humans learn better and faster if a tutor, based on their current knowledge level, informs them of how much attention they should pay to particular content or practice problems. Similarly, a machine learning model could potentially be trained better with a scorer that adapts to its current learning state and estimates the importance of each training data instance. Training such an adaptive scorer efficiently is a challenging problem; in order to precisely quantify the effect of a data instance at a given time during the training, it is typically necessary to first complete the entire training process. To efficiently optimize data usage, we propose a reinforcement learning approach called Differentiable Data Selection (DDS). In DDS, we formulate a scorer network as a learnable function of the training data, which can be efficiently updated along with the main model being trained. Specifically, DDS updates the scorer with an intuitive reward signal: it should up-weigh the data that has a similar gradient with a dev set upon which we would finally like to perform well. Without significant computing overhead, DDS delivers strong and consistent improvements over several strong baselines on two very different tasks of machine translation and image classification.", "pdf": "/pdf/3d572357f0598b1c73d55e8cf8bb64c44ab2f5ea.pdf", "keywords": "['data selection', 'multilingual neural machine translation', 'data usage optimzation', 'transfer learning', 'classification']", "id": "BJxt2aVFPr"}, {"number": "2022", "title": "Crafting Data-free Universal Adversaries with Dilate Loss", "authors": "['Deepak Babu Sam', 'ABINAYA K', 'Sudharsan K A', 'Venkatesh Babu RADHAKRISHNAN']", "abstract": "We introduce a method to create Universal Adversarial Perturbations (UAP) for a given CNN in a data-free manner. Data-free approaches suite scenarios where the original training data is unavailable for crafting adversaries. We show that the adversary generation with full training data can be approximated to a formulation without data. This is realized through a sequential optimization of the adversarial perturbation with the proposed dilate loss. Dilate loss basically maximizes the Euclidean norm of the output before nonlinearity at any layer. By doing so, the perturbation constrains the ReLU activation function at every layer to act roughly linear for data points and thus eliminate the dependency on data for crafting UAPs. Extensive experiments demonstrate that our method not only has theoretical support, but achieves higher fooling rate than the existing data-free work. Furthermore, we evidence improvement in limited data cases as well.", "pdf": "/pdf/753dcb8abc30e461917ca89b7e6cb5e874fd9e16.pdf", "keywords": "[]", "id": "HJxVC1SYwr"}, {"number": "1136", "title": "Neural ODEs for Image Segmentation with Level Sets", "authors": "['Rafael Valle', 'Fitsum Reda', 'Mohammad Shoeybi', 'Patrick Legresley', 'Andrew Tao', 'Bryan Catanzaro']", "abstract": "We propose a novel approach for image segmentation that combines Neural Ordinary Differential Equations (NODEs) and the Level Set method.  Our approach parametrizes the evolution of an initial contour with a NODE that implicitly learns from data a speed function describing the evolution.  In addition, for cases where an initial contour is not available and to alleviate the need for careful choice or design of contour embedding functions, we propose a NODE-based method that evolves an image embedding into a dense per-pixel semantic label space. We evaluate our methods on kidney segmentation (KiTS19) and on salient object detection (PASCAL-S, ECSSD and HKU-IS). In addition to improving initial contours provided by deep learning models while using a fraction of their number of parameters, our approach achieves F scores that are higher than several state-of-the-art deep learning algorithms", "pdf": "/pdf/e04274311e894c7e7079cbd952f222d805094d38.pdf", "keywords": "['neural odes', 'level sets', 'image segmentation']", "id": "r1gNLAEFPS"}, {"number": "881", "title": "Unsupervised Learning of Automotive 3D Crash Simulations using LSTMs", "authors": "['Amin Abbasloo', 'Jochen Garcke', 'Rodrigo Iza-Teran']", "abstract": "Long short-term memory (LSTM) networks allow to exhibit temporal dynamic behavior with feedback connections and seem a natural choice for learning sequences of 3D meshes. We introduce an approach for dynamic mesh representations as used for numerical simulations of car crashes. To bypass the complication of using 3D meshes, we transform the surface mesh sequences into spectral descriptors that efficiently encode the shape. A two branch LSTM based network architecture is chosen to learn the representations and dynamics of the crash during the simulation. The architecture is based on unsupervised video prediction by an LSTM without any convolutional layer. It uses an encoder LSTM to map an input sequence into a fixed length vector representation. On this representation one decoder LSTM performs the reconstruction of the input sequence, while the other decoder LSTM predicts the future behavior by receiving initial steps of the sequence as seed. The spatio-temporal error behavior of the model is analysed to study how well the model can extrapolate the learned spectral descriptors into the future, that is, how well it has learned to represent the underlying dynamical structural mechanics. Considering that only a few training examples are available, which is the typical case for numerical simulations, the network performs very well.", "pdf": "/pdf/93edaf1d13aa2e26d682bf576b26816e4de59859.pdf", "keywords": "['LSTM', 'surface data', 'geometric deep learning', 'numerical simulation']", "id": "BklekANtwr"}, {"number": "2446", "title": "Making Sense of Reinforcement Learning and Probabilistic Inference", "authors": "[\"Brendan O'Donoghue\", 'Ian Osband', 'Catalin Ionescu']", "abstract": "Reinforcement learning (RL) combines a control problem with statistical estimation: The system dynamics are not known to the agent, but can be learned through experience. A recent line of research casts RL as inference and suggests a particular framework to generalize the RL problem as probabilistic inference. Our paper surfaces a key shortcoming in that approach, and clarifies the sense in which RL can be coherently cast as an inference problem. In particular, an RL agent must consider the effects of its actions upon future rewards and observations: The exploration-exploitation tradeoff. In all but the most simple settings, the resulting inference is computationally intractable so that practical RL algorithms must resort to approximation. We demonstrate that the popular RL as inference approximation can perform poorly in even very basic problems. However, we show that with a small modification the framework does yield algorithms that can provably perform well, and we show that the resulting algorithm is equivalent to the recently proposed K-learning, which we further connect with Thompson sampling.\n", "pdf": "/pdf/2f653b1fba689d249ca2d622778d13d1840816eb.pdf", "keywords": "['Reinforcement learning', 'Bayesian inference', 'Exploration']", "id": "S1xitgHtvS"}, {"number": "2049", "title": "A multi-task U-net for segmentation with lazy labels", "authors": "['Rihuan Ke', 'Aur\u00e9lie Bugeau', 'Nicolas Papadakis', 'Peter Schuetz', 'Carola-Bibiane Sch\u00f6nlieb']", "abstract": "The need for labour intensive pixel-wise annotation is a major limitation of many fully supervised learning methods for image segmentation.   In this paper,  we propose a deep convolutional neural network for multi-class segmentation that circumvents this problem by being trainable on coarse data labels combined with only a very small number of images with pixel-wise annotations.  We call this new labelling strategy lazy labels.  Image segmentation is then stratified into three connected tasks: rough detection of class instances, separation of wrongly connected objects without a clear boundary, and pixel-wise segmentation to find the accurate boundaries of each object. These problems are integrated into a multi-task learning framework and the model is trained end-to-end in a semi-supervised fashion. The method is demonstrated on two segmentation datasets, including food microscopy images and histology images of tissues respectively. We show that the model gives accurate segmentation results even if exact boundary labels are missing for a majority of the annotated data.  This allows more flexibility and efficiency for training deep neural networks that are data hungry in a practical setting where manual annotation is expensive, by collecting more lazy (rough) annotations than precisely segmented images. ", "pdf": "/pdf/4eae292daf649f454ce1f0bc1887bfec063c1ca8.pdf", "keywords": "['multi-task learning', 'weak labels', 'semisupervised learning', 'image segmentation']", "id": "r1glygHtDB"}, {"number": "1051", "title": "Visual Interpretability Alone Helps Adversarial Robustness", "authors": "['Akhilan Boopathy', 'Sijia Liu', 'Gaoyuan Zhang', 'Pin-Yu Chen', 'Shiyu Chang', 'Luca Daniel']", "abstract": "Recent works have empirically shown that there exist   adversarial examples that can be hidden from neural network interpretability, and  interpretability is itself susceptible to adversarial attacks. In this paper, we theoretically show  that with the correct measurement of interpretation, it is actually difficult to hide adversarial examples, as confirmed by experiments on MNIST, CIFAR-10 and Restricted ImageNet. Spurred by that, we develop a novel defensive scheme built only on robust interpretation (without resorting to adversarial loss minimization). We show that our defense achieves similar classification robustness to state-of-the-art robust training methods while attaining higher interpretation robustness under various settings of adversarial attacks.", "pdf": "/pdf/acccff40479a296fa1bda080c1bf7a27bb58fd24.pdf", "keywords": "['adversarial robustness', 'visual explanation', 'CNN', 'image classification']", "id": "Hyes70EYDB"}, {"number": "554", "title": "Discourse-Based Evaluation of Language Understanding", "authors": "['Damien Sileo', 'Tim Van-De-Cruys', 'Camille Pradel', 'Philippe Muller']", "abstract": "New models for natural language understanding have made unusual progress recently, leading to claims of universal text representations. However, current benchmarks are predominantly targeting semantic phenomena;  we make the case that discourse and pragmatics need to take center stage in the evaluation of natural language understanding.\nWe introduce DiscEval, a new benchmark for the evaluation of natural language understanding, that unites 11 discourse-focused evaluation datasets. \nDiscEval can be used as supplementary training data in a multi-task learning setup, and is publicly available, alongside the code for gathering and preprocessing the datasets.\nUsing our evaluation suite, we show that natural language inference, a widely used pretraining task, does not result in genuinely universal representations, which opens a new challenge for multi-task learning.", "pdf": "/pdf/e63bf8f10a3917181780d923f26fde60b8d1f5ea.pdf", "keywords": "['Natural Language Understanding', 'Pragmatics', 'Discourse', 'Semantics', 'Evaluation', 'BERT', 'Natural Language Processing']", "id": "B1em8TVtPr"}, {"number": "255", "title": "Keyframing the Future: Discovering Temporal Hierarchy with Keyframe-Inpainter Prediction", "authors": "['Karl Pertsch', 'Oleh Rybkin', 'Jingyun Yang', 'Konstantinos G. Derpanis', 'Kostas Daniilidis', 'Joseph J. Lim', 'Andrew Jaegle']", "abstract": "To flexibly and efficiently reason about temporal sequences, abstract representations that compactly represent the important information in the sequence are needed. One way of constructing such representations is by focusing on the important events in a sequence. In this paper, we propose a model that learns both to discover such key events (or keyframes) as well as to represent the sequence in terms of them.  We do so using a hierarchical Keyframe-Inpainter (KeyIn) model that first generates keyframes and their temporal placement and then inpaints the sequences between keyframes. We propose a fully differentiable formulation for efficiently learning the keyframe placement. We show that KeyIn finds informative keyframes in several datasets with diverse dynamics. When evaluated on a planning task, KeyIn outperforms other recent proposals for learning hierarchical representations.", "pdf": "/pdf/545de03f5bb128edcd4d61688150c053da64b2fa.pdf", "keywords": "['representation learning', 'variational inference', 'video generation', 'temporal hierarchy']", "id": "BklfR3EYDH"}, {"number": "2082", "title": "Attack-Resistant Federated Learning with Residual-based Reweighting", "authors": "['Shuhao Fu', 'Chulin Xie', 'Bo Li', 'Qifeng Chen']", "abstract": "Federated learning has a variety of applications in multiple domains by utilizing private training data stored on different devices. However, the aggregation process in federated learning is highly vulnerable to adversarial attacks so that the global model may behave abnormally under attacks. To tackle this challenge, we present a novel aggregation algorithm with residual-based reweighting to defend federated learning. Our aggregation algorithm combines repeated median regression with the reweighting scheme in iteratively reweighted least squares. Our experiments show that our aggression algorithm outperforms other alternative algorithms in the presence of label-flipping, backdoor, and Gaussian noise attacks. We also provide theoretical guarantees for our aggregation algorithm.\n", "pdf": "/pdf/1ea807b624ecc563e3b617f0948502afeee0ec8c.pdf", "keywords": "['robust federated learning', 'backdoor attacks']", "id": "HkgAJxrYwr"}, {"number": "291", "title": "Robust Local Features for Improving the Generalization of Adversarial Training", "authors": "['Chuanbiao Song', 'Kun He', 'Jiadong Lin', 'Liwei Wang', 'John E. Hopcroft']", "abstract": "Adversarial training has been demonstrated as one of the most effective methods for training robust models to defend against adversarial examples. However, adversarially trained models often lack adversarially robust generalization on unseen testing data. Recent works show that adversarially trained models are more biased towards global structure features. Instead, in this work, we would like to investigate the relationship between the generalization of adversarial training and the robust local features, as the robust local features generalize well for unseen shape variation. To learn the robust local features, we develop a Random Block Shuffle (RBS) transformation to break up the global structure features on normal adversarial examples. We continue to propose a new approach called Robust Local Features for Adversarial Training (RLFAT), which first learns the robust local features by adversarial training on the RBS-transformed adversarial examples, and then transfers the robust local features into the training of normal adversarial examples. To demonstrate the generality of our argument, we implement RLFAT in currently state-of-the-art adversarial training frameworks. Extensive experiments on STL-10, CIFAR-10 and CIFAR-100 show that RLFAT significantly improves both the adversarially robust generalization and the standard generalization of adversarial training. Additionally, we demonstrate that our models capture more local features of the object on the images, aligning better with human perception.", "pdf": "/pdf/dae374e910b43b0c5a6a2693b05b04bc61c5c98f.pdf", "keywords": "['adversarial robustness', 'adversarial training', 'adversarial example', 'deep learning']", "id": "H1lZJpVFvr"}, {"number": "1162", "title": "MANIFOLD FORESTS: CLOSING THE GAP ON NEURAL NETWORKS", "authors": "['Ronan Perry', 'Tyler M. Tomita', 'Jesse Patsolic', 'Benjamin Falk', 'Joshua Vogelstein']", "abstract": "Decision forests (DF), in particular random forests and gradient boosting trees, have  demonstrated state-of-the-art accuracy compared to other methods in many supervised learning scenarios. In particular, DFs dominate other methods in tabular data, that is, when the feature space is unstructured, so that the signal is invariant to permuting feature indices.  However, in structured data lying on a manifold---such as images, text, and speech---neural nets (NN) tend to outperform DFs. We conjecture that at least part of the reason for this is that the input to NN is not simply the feature magnitudes, but also their indices (for example, the convolution operation uses ``feature locality). In contrast, naive DF implementations fail to explicitly consider feature indices. A recently proposed DF approach demonstrates that DFs, for each node, implicitly sample a random matrix from some specific distribution.  Here, we build on that to show that one can choose distributions in a manifold aware fashion. For example, for image classification, rather than randomly selecting pixels, one can randomly select contiguous patches. We demonstrate the empirical performance of  data living on three different manifolds: images, time-series, and a torus. In all three cases, our Manifold Forest (Mf) algorithm empirically dominates other state-of-the-art approaches that ignore feature space structure, achieving a lower classification error on all sample sizes. This dominance extends to the MNIST data set as well. Moreover, both training and test time is significantly faster for manifold forests as compared to deep nets. This approach, therefore, has promise to enable DFs and other machine learning methods to close the gap with deep nets on manifold-valued data. ", "pdf": "/pdf/d886b43b85f5aee5abc86a8963c8f170b6d6f1ca.pdf", "keywords": "['machine learning', 'structured learning', 'projections', 'structured data', 'images', 'classification']", "id": "B1xewR4KvH"}, {"number": "1680", "title": "Amharic Text Normalization with Sequence-to-Sequence Models", "authors": "['Seifedin Shifaw Mohamed', 'Solomon Teferra Abate (PhD)']", "abstract": "All areas of language and speech technology, directly or indirectly, require handling of real text. In addition to ordinary words and names, the real text contains non-standard words (NSWs), including numbers, abbreviations, dates, currency, amounts, and acronyms. Typically, one cannot find NSWs in a dictionary, nor can one find their pronunciation by an application of ordinary letter-to-sound rules. It is desirable to normalize text by replacing such non-standard words with a consistently formatted and contextually appropriate variant in several NLP applications. To address this challenge, in this paper, we model the problem as character-level sequence-to-sequence learning where we map a sequence of input characters to a sequence of output words. It consists of two neural networks, the encoder network, and the decoder network. The encoder maps the input characters to a fixed dimensional vector and the decoder generates the output words. We have achieved an accuracy of 94.8 % which is promising given the resource we use.", "pdf": "/pdf/5311d46af7b43574c73de0993982fe678daa4602.pdf", "keywords": "['Text Normalization', 'Sequence-to-Sequence Model', 'Encoder-Decoder']", "id": "SJe-HkBKDS"}, {"number": "1097", "title": "DBA: Distributed Backdoor Attacks against Federated Learning", "authors": "['Chulin Xie', 'Keli Huang', 'Pin-Yu Chen', 'Bo Li']", "abstract": "Backdoor attacks aim to manipulate a subset of training data by injecting adversarial triggers such that machine learning models trained on the tampered dataset will make arbitrarily (targeted) incorrect prediction on the testset with the same trigger embedded. While federated learning (FL) is capable of aggregating information provided by different parties for training a better model, its distributed learning methodology and inherently heterogeneous data distribution across parties may bring new vulnerabilities. In addition to recent centralized backdoor attacks on FL where each party embeds the same global trigger during training, we propose the distributed backdoor attack (DBA) --- a novel threat assessment framework developed by fully exploiting the distributed nature of FL. DBA decomposes a global trigger pattern into separate local patterns and embed them into the training set of different adversarial parties respectively. Compared to standard centralized backdoors, we show that DBA is substantially more persistent and stealthy against FL on diverse datasets such as finance and image data. We conduct extensive experiments to show that the attack success rate of DBA is significantly higher than centralized backdoors under different settings. Moreover, we find that distributed attacks are indeed more insidious, as DBA can evade two state-of-the-art robust FL algorithms against centralized backdoors. We also provide explanations for the effectiveness of DBA via feature visual interpretation and feature importance ranking.\nTo further explore the properties of DBA, we test the attack performance by varying different trigger factors, including local trigger variations (size, gap, and location), scaling factor in FL, data distribution, and poison ratio and interval. Our proposed DBA and thorough evaluation results shed lights on characterizing the robustness of FL.", "pdf": "/pdf/61dc789b9f12be96506a23ddb7670ac132a51d6d.pdf", "keywords": "['distributed backdoor attack', 'federated learning']", "id": "rkgyS0VFvr"}, {"number": "1978", "title": "RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments", "authors": "['Roberta Raileanu', 'Tim Rockt\u00e4schel']", "abstract": "Exploration in sparse reward environments remains one of the key challenges of model-free reinforcement learning. Instead of solely relying on extrinsic rewards provided by the environment, many state-of-the-art methods use intrinsic rewards to encourage exploration. However, we show that existing methods fall short in procedurally-generated environments where an agent is unlikely to visit a state more than once. We propose a novel type of intrinsic reward which encourages the agent to take actions that lead to significant changes in its learned state representation. We evaluate our method on multiple challenging procedurally-generated tasks in MiniGrid, as well as on tasks with high-dimensional observations used in prior work. Our experiments demonstrate that this approach is more sample efficient than existing exploration methods, particularly for procedurally-generated MiniGrid environments. Furthermore, we analyze the learned behavior as well as the intrinsic reward received by our agent. In contrast to previous approaches, our intrinsic reward does not diminish during the course of training and it rewards the agent substantially more for interacting with objects that it can control.", "pdf": "/pdf/68bc2411f16aa93f68d856590f15a91041d772d2.pdf", "keywords": "['reinforcement learning', 'exploration', 'curiosity']", "id": "rkg-TJBFPB"}, {"number": "2114", "title": "Rethinking deep active learning: Using unlabeled data at model training", "authors": "['Oriane Sim\u00e9oni', 'Mateusz Budnik', 'Yannis Avrithis', 'Guillaume Gravier']", "abstract": "Active learning typically focuses on training a model on few labeled examples alone, while unlabeled ones are only used for acquisition. In this work we depart from this setting by using both labeled and unlabeled data during model training across active learning cycles. We do so by using unsupervised feature learning at the beginning of the active learning pipeline and semi-supervised learning at every active learning cycle, on all available data. The former has not been investigated before in active learning, while the study of latter in the context of deep learning is scarce and recent findings are not conclusive with respect to its benefit. Our idea is orthogonal to acquisition strategies by using more data, much like ensemble methods use more models. By systematically evaluating on a number of popular acquisition strategies and datasets, we find that the use of unlabeled data during model training brings a spectacular accuracy improvement in image classification, compared to the differences between acquisition strategies. We thus explore smaller label budgets, even one label per class. ", "pdf": "/pdf/c9d2f97fdeae9be9a94f12a6b4dfaad4a6dc8038.pdf", "keywords": "['active learning', 'deep learning', 'semi-supervised learning', 'unsupervised feature learning']", "id": "rJehllrtDS"}, {"number": "2070", "title": "Unsupervised Meta-Learning for Reinforcement Learning", "authors": "['Abhishek Gupta', 'Benjamin Eysenbach', 'Chelsea Finn', 'Sergey Levine']", "abstract": "Meta-learning algorithms learn to acquire new tasks more quickly from past experience. In the context of reinforcement learning, meta-learning algorithms can acquire reinforcement learning procedures to solve new problems more efficiently by utilizing experience from prior tasks. The performance of meta-learning algorithms depends on the tasks available for meta-training: in the same way that supervised learning generalizes best to test points drawn from the same distribution as the training points, meta-learning methods generalize best to tasks from the same distribution as the meta-training tasks. In effect, meta-reinforcement learning offloads the design burden from algorithm design to task design. If we can automate the process of task design as well, we can devise a meta-learning algorithm that is truly automated. In this work, we take a step in this direction, proposing a family of unsupervised meta-learning algorithms for reinforcement learning. We motivate and describe a general recipe for unsupervised meta-reinforcement learning, and present an instantiation of this approach. Our conceptual and theoretical contributions consist of formulating the unsupervised meta-reinforcement learning problem and describing how task proposals based on mutual information can in principle be used to train optimal meta-learners. Our experimental results indicate that unsupervised meta-reinforcement learning effectively acquires accelerated reinforcement learning procedures without the need for manual task design and significantly exceeds the performance of learning from scratch.", "pdf": "/pdf/387200792c6faff7ce9633266718be0189bed7c1.pdf", "keywords": "['Meta-Learning', 'Reinforcement Learning']", "id": "S1et1lrtwr"}, {"number": "2294", "title": "Collaborative Inter-agent Knowledge Distillation for Reinforcement Learning", "authors": "['Zhang-Wei Hong', 'Prabhat Nagarajan', 'Guilherme Maeda']", "abstract": "Reinforcement Learning (RL) has demonstrated promising results across several sequential decision-making tasks. However, reinforcement learning struggles to learn efficiently, thus limiting its pervasive application to several challenging problems. A typical RL agent learns solely from its own trial-and-error experiences, requiring many experiences to learn a successful policy. To alleviate this problem, we propose collaborative inter-agent knowledge distillation (CIKD). CIKD is a learning framework that uses an ensemble of RL agents to execute different policies in the environment while sharing knowledge amongst agents in the ensemble. Our experiments demonstrate that CIKD improves upon state-of-the-art RL methods in sample efficiency and performance on several challenging MuJoCo benchmark tasks. Additionally, we present an in-depth investigation on how CIKD leads to performance improvements.\n", "pdf": "/pdf/70cb22581b3971586edcfe24cd1ddd308c0be0e3.pdf", "keywords": "['Reinforcement learning', 'distillation']", "id": "BkeYSlrYwH"}, {"number": "480", "title": "GAT: Generative Adversarial Training for Adversarial Example Detection and Robust Classification", "authors": "['Xuwang Yin', 'Soheil Kolouri', 'Gustavo K Rohde']", "abstract": "The vulnerabilities of deep neural networks against adversarial examples have become a significant concern for deploying these models in sensitive domains. Devising a definitive defense against such attacks is proven to be challenging, and the methods relying on detecting adversarial samples are only valid when the attacker is oblivious to the detection mechanism. In this paper we propose a principled adversarial example detection method that can withstand norm-constrained white-box attacks. Inspired by one-versus-the-rest classification, in a K class classification problem, we train K binary classifiers where the i-th binary classifier is used to distinguish between clean data of class i and adversarially perturbed samples of other classes. At test time, we first use a trained classifier to get the predicted label (say k) of the input, and then use the k-th binary classifier to determine whether the input is a clean sample (of class k) or an adversarially perturbed example (of other classes). We further devise a generative approach to detecting/classifying adversarial examples by interpreting each binary classifier as an unnormalized density model of the class-conditional data. We provide comprehensive evaluation of the above adversarial example detection/classification methods, and demonstrate their competitive performances and compelling properties. Code is available at https://github.com/xuwangyin/GAT-Generative-Adversarial-Training", "pdf": "/pdf/d5c437c5244b0e98f3b52cbfb19586cc75f73e10.pdf", "keywords": "['adversarial example detection', 'adversarial examples classification', 'robust optimization', 'ML security', 'generative modeling', 'generative classification']", "id": "SJeQEp4YDH"}, {"number": "136", "title": "Understanding and Improving Transformer From a Multi-Particle Dynamic System Point of View", "authors": "['Yiping Lu', 'Zhuohan Li', 'Di He', 'Zhiqing Sun', 'Bin Dong', 'Tao Qin', 'Liwei Wang', 'Tie-Yan Liu']", "abstract": "The Transformer architecture is widely used in natural language processing. Despite its success, the design principle of the Transformer remains elusive. In this paper, we provide a novel perspective towards understanding the architecture: we show that the Transformer can be mathematically interpreted as a numerical Ordinary Differential Equation (ODE) solver for a convection-diffusion equation in a multi-particle dynamic system. In particular, how words in a sentence are abstracted into contexts by passing through the layers of the Transformer can be interpreted as approximating multiple particles' movement in the space using the Lie-Trotter splitting scheme and the Euler's method. Given this ODE's perspective, the rich literature of numerical analysis can be brought to guide us in designing effective structures beyond the Transformer. As an example, we propose to replace the Lie-Trotter splitting scheme by the Strang-Marchuk splitting scheme, a scheme that is more commonly used and with much lower local truncation errors. The Strang-Marchuk splitting scheme suggests that the self-attention and position-wise feed-forward network (FFN) sub-layers should not be treated equally. Instead, in each layer, two position-wise FFN sub-layers should be used, and the self-attention sub-layer is placed in between. This leads to a brand new architecture. Such an FFN-attention-FFN layer is 'Macaron-like', and thus we call the network with this new architecture the Macaron Net. Through extensive experiments, we show that the Macaron Net is superior to the Transformer on both supervised and unsupervised learning tasks. The reproducible code can be found on http://anonymized", "pdf": "/pdf/d9320f3ed1c87d959f984d0d50a600863bbc4723.pdf", "keywords": "['Transformer', 'Ordinary Differential Equation', 'Multi-Particle Dynamic System', 'Natural Language Processing']", "id": "SJl1o2NFwS"}, {"number": "1936", "title": "Global Adversarial Robustness Guarantees for Neural Networks", "authors": "['Luca Laurenti', 'Andrea Patane', 'Matthew Wicker', 'Luca Bortolussi', 'Luca Cardelli', 'Marta Kwiatkowska']", "abstract": "We investigate global adversarial robustness guarantees for machine learning models.  Specifically, given a trained model we consider the problem of computing the probability that its prediction at any point sampled from the (unknown) input distribution is susceptible to adversarial attacks.  Assuming continuity of the model, we prove measurability for a selection of local robustness properties used in the literature. We then show how concentration inequalities can be employed to compute global robustness with estimation error upper-bounded by $\\epsilon$, for any $\\epsilon > 0$ selected a priori. We utilise the methods to provide statistically sound analysis of the robustness/accuracy trade-off for a variety of neural networks architectures and training methods on MNIST, Fashion-MNIST and CIFAR. We empirically observe that robustness and accuracy tend to be negatively correlated for networks trained via stochastic gradient descent and with iterative pruning techniques, while a positive trend is observed between them in Bayesian settings.", "pdf": "/pdf/3e085754b51207497453960ffddf8b38211a4119.pdf", "keywords": "['Adversarial Robustness', 'Statistical Guarantees', 'Deep Neural Networks', 'Bayesian Neural Networks']", "id": "BJgyn1BFwS"}, {"number": "816", "title": "Task-Based Top-Down Modulation Network for Multi-Task-Learning Applications", "authors": "['Hila Levi', 'Shimon Ullman']", "abstract": "A general problem that received considerable recent attention is how to perform multiple tasks in the same network, maximizing both efficiency and prediction accuracy. A popular approach consists of a multi-branch architecture on top of a\nshared backbone, jointly trained on a weighted sum of losses. However, in many cases, the shared representation results in non-optimal performance, mainly due to an interference between conflicting gradients of uncorrelated tasks. Recent approaches address this problem by a channel-wise modulation of the feature-maps along the shared backbone, with task specific vectors, manually or dynamically tuned. Taking this approach a step further, we propose a novel architecture which\nmodulate the recognition network channel-wise, as well as spatial-wise, with an efficient top-down image-dependent computation scheme. Our architecture uses no task-specific branches, nor task specific modules. Instead, it uses a top-down modulation network that is shared between all of the tasks. We show the effectiveness of our scheme by achieving on par or better results than alternative approaches on both correlated and uncorrelated sets of tasks. We also demonstrate our advantages in terms of model size, the addition of novel tasks and interpretability. \nCode will be released.", "pdf": "/pdf/8134a60dd6eb2e9f685ea17ce7ff74c74c170147.pdf", "keywords": "['deep learning', 'multi-task learning']", "id": "BklBp6EYvB"}, {"number": "695", "title": "Disentangling Improves VAEs' Robustness to Adversarial Attacks", "authors": "['Matthew Willetts', 'Alexander Camuto', 'Stephen Roberts', 'Chris Holmes']", "abstract": "This paper is concerned with the robustness of VAEs to adversarial attacks. We highlight that conventional VAEs are brittle under attack but that methods recently introduced for disentanglement such as -TCVAE (Chen et al., 2018) improve robustness, as demonstrated through a variety of previously proposed adversarial attacks (Tabacof et al. (2016); Gondim-Ribeiro et al. (2018); Kos et al.(2018)). This motivated us to develop Seatbelt-VAE, a new hierarchical disentangled VAE that is designed to be significantly more robust to adversarial attacks than existing approaches, while retaining high quality reconstructions.", "pdf": "/pdf/f04841bcdca53a40a72609d4f255e236160817e9.pdf", "keywords": "[]", "id": "rkeZ9a4Fwr"}, {"number": "2221", "title": "AdvectiveNet: An Eulerian-Lagrangian Fluidic Reservoir for Point Cloud Processing     ", "authors": "['Xingzhe He', 'Helen Lu Cao', 'Bo Zhu']", "abstract": "This paper presents a novel physics-inspired deep learning approach for point cloud processing motivated by the natural flow phenomena in fluid mechanics.  Our learning architecture jointly defines data in an Eulerian world space, using a static background grid, and a Lagrangian material space, using moving particles. By introducing this Eulerian-Lagrangian representation, we are able to naturally evolve and accumulate particle features using flow velocities generated from a generalized, high-dimensional force field.  We demonstrate the efficacy of this system by solving various point cloud classification and segmentation problems with state-of-the-art performance. The entire geometric reservoir and data flow mimic the pipeline of the classic PIC/FLIP scheme in modeling natural flow, bridging the disciplines of geometric machine learning and physical simulation.", "pdf": "/pdf/ed964d2fea5030138e3f09a86b61ad5272f3d315.pdf", "keywords": "['Point Cloud Processing', 'Physical Reservoir Learning', 'Eulerian-Lagrangian Method', 'PIC/FLIP']", "id": "H1eqQeHFDS"}, {"number": "1582", "title": "Adaptive Adversarial Imitation Learning", "authors": "['Yiren Lu', 'Jonathan Tompson', 'Sergey Levine']", "abstract": "We present the ADaptive Adversarial Imitation Learning (ADAIL) algorithm for learning adaptive policies that can be transferred between environments of varying dynamics, by imitating a small number of demonstrations collected from a single source domain. This problem is important in robotic learning because in real world scenarios 1) reward functions are hard to obtain, 2) learned policies from one domain are difficult to deploy in another due to varying source to target domain statistics, 3) collecting expert demonstrations in multiple environments where the dynamics are known and controlled is often infeasible. We address these constraints by building upon recent advances in adversarial imitation learning; we condition our policy on a learned dynamics embedding and we employ a domain-adversarial loss to learn a dynamics-invariant discriminator. The effectiveness of our method is demonstrated on simulated control tasks with varying environment dynamics and the learned adaptive agent outperforms several recent baselines.", "pdf": "/pdf/7a36ed0c2931e2e1aec318aded4384faad0af11d.pdf", "keywords": "['Imitation Learning', 'Reinforcement Learning']", "id": "HklvMJSYPB"}, {"number": "1659", "title": "Plug and Play Language Models: A Simple Approach to Controlled Text Generation", "authors": "['Sumanth Dathathri', 'Andrea Madotto', 'Janice Lan', 'Jane Hung', 'Eric Frank', 'Piero Molino', 'Jason Yosinski', 'Rosanne Liu']", "abstract": "Large transformer-based language models (LMs) trained on huge text corpora have shown unparalleled generation capabilities. However, controlling attributes of the generated language (e.g. switching topic or sentiment) is difficult without modifying the model architecture or fine-tuning on attribute-specific data and entailing the significant cost of retraining. We propose a simple alternative: the Plug and Play Language Model (PPLM) for controllable language generation, which combines a pretrained LM with one or more simple attribute classifiers that guide text generation without any further training of the LM. In the canonical scenario we present, the attribute models are simple classifiers consisting of a user-specified bag of words or a single learned layer with 100,000 times fewer parameters than the LM. Sampling entails a forward and backward pass in which gradients from the attribute model push the LM's hidden activations and thus guide the generation. Model samples demonstrate control over a range of topics and sentiment styles, and extensive automated and human annotated evaluations show attribute alignment and fluency. PPLMs are flexible in that any combination of differentiable attribute models may be used to steer text generation, which will allow for diverse and creative applications beyond the examples given in this paper.", "pdf": "/pdf/e5bf5d6bd5aa1cbd71c4bb0632cdee0bd9e2b130.pdf", "keywords": "['controlled text generation', 'generative models', 'conditional generative models', 'language modeling', 'transformer']", "id": "H1edEyBKDS"}, {"number": "1758", "title": "Fairness with Wasserstein Adversarial Networks", "authors": "['serrurier Mathieu', 'Loubes Jean-Michel', 'Edouard Pauwels']", "abstract": "Quantifying, enforcing and implementing fairness emerged as a major topic in machine learning. We investigate these questions in the context of deep learning. Our main algorithmic and theoretical tool is the computational estimation of similarities between probability, ``\\`a la Wasserstein'', using adversarial networks. This idea is flexible enough to investigate different fairness constrained learning tasks, which we model by specifying properties of the underlying data generative process. The first setting considers bias in the generative model which should be filtered out. The second model is related to the presence of nuisance variables in the observations producing an unwanted bias for the learning task.  For both models, we devise a learning algorithm based on approximation of Wasserstein distances using adversarial networks. We provide formal arguments describing the fairness enforcing properties of these algorithm in relation with the underlying fairness generative processes. Finally we perform experiments, both on synthetic and real world data, to demonstrate empirically the superiority of our approach compared to state of the art fairness algorithms as well as concurrent GAN type adversarial architectures based on Jensen divergence.", "pdf": "/pdf/121658d37bbc5d736ccc2413a01661d806031e49.pdf", "keywords": "[]", "id": "BkeGPJrtwB"}, {"number": "809", "title": "Last-iterate convergence rates for min-max optimization", "authors": "['Jacob Abernethy', 'Kevin A. Lai', 'Andre Wibisono']", "abstract": "While classic work in convex-concave min-max optimization relies on average-iterate convergence results, the emergence of nonconvex applications such as training Generative Adversarial Networks has led to renewed interest in last-iterate convergence guarantees. Proving last-iterate convergence is challenging because many natural algorithms, such as Simultaneous Gradient Descent/Ascent, provably diverge or cycle even in simple convex-concave min-max settings, and previous work on global last-iterate convergence rates has been limited to the bilinear and convex-strongly concave settings. In this work, we show that the Hamiltonian Gradient Descent (HGD) algorithm achieves linear convergence in a variety of more general settings, including convex-concave problems that satisfy a sufficiently bilinear condition. We also prove similar convergence rates for some parameter settings of the Consensus Optimization (CO) algorithm of Mescheder et al. 2017.", "pdf": "/pdf/6f72820a437b2f6c98d2a204229acc0e5dfa4486.pdf", "keywords": "['min-max optimization', 'zero-sum game', 'saddle point', 'last-iterate convergence', 'non-asymptotic convergence', 'global rates', 'Hamiltonian', 'sufficiently bilinear']", "id": "SylGpT4FPS"}, {"number": "1048", "title": "End-to-end named entity recognition and relation extraction using pre-trained language models", "authors": "['John Giorgi', 'Xindi Wang', 'Nicola Sahar', 'Won Young Shin', 'Gary Bader', 'Bo Wang']", "abstract": "Named entity recognition (NER) and relation extraction (RE) are two important tasks in information extraction and retrieval (IE & IR). Recent work has demonstrated that it is beneficial to learn these tasks jointly, which avoids the propagation of error inherent in pipeline-based systems and improves performance. However, state-of-the-art joint models typically rely on external natural language processing (NLP) tools, such as dependency parsers, limiting their usefulness to domains (e.g. news) where those tools perform well. The few neural, end-to-end models that have been proposed are trained almost completely from scratch. In this paper, we propose a neural, end-to-end model for jointly extracting entities and their relations which does not rely on external NLP tools and which integrates a large, pre-trained language model. Because the bulk of our model's parameters are pre-trained and we eschew recurrence for self-attention, our model is fast to train. On 5 datasets across 3 domains, our model matches or exceeds state-of-the-art performance, sometimes by a large margin.", "pdf": "/pdf/1462260f8feb38efc3c3c6a48383eeb9d679c3c9.pdf", "keywords": "['named entity recognition', 'relation extraction', 'information extraction', 'information retrival', 'transfer learning', 'multi-task learning', 'BERT', 'transformers', 'language models']", "id": "rkgqm0VKwB"}, {"number": "2453", "title": "Optimal Unsupervised Domain Translation", "authors": "['Emmanuel de B\u00e9zenac', 'Ibrahim Ayed', 'Patrick Gallinari']", "abstract": "Unsupervised Domain Translation~(UDT) consists in finding meaningful correspondences between two domains, without access to explicit pairings between them. Following the seminal work of \\textit{CycleGAN}, many variants and extensions of this model have been applied successfully to a wide range of applications. However, these methods remain poorly understood, and lack convincing theoretical guarantees. In this work, we define UDT in a rigorous, non-ambiguous manner, explore the implicit biases present in the approach and demonstrate the limits of theses approaches. Specifically, we show that mappings produced by these methods are  biased towards \\textit{low energy} transformations, leading us to cast UDT into an Optimal Transport~(OT) framework by making this implicit bias explicit. This not only allows us to provide theoretical guarantees for existing methods, but also to solve UDT problems where previous methods fail. Finally, making the link between the dynamic formulation of OT and CycleGAN, we propose a simple approach to solve UDT, and illustrate its properties in two distinct settings.", "pdf": "/pdf/c6ebef8a42571bbd6deb8ec2d4a72539e4da3709.pdf", "keywords": "['Unsupervised Domain Translation', 'CycleGAN', 'Optimal Transport']", "id": "H1eRYxHYPB"}, {"number": "2444", "title": "Improved Training of Certifiably Robust Models", "authors": "['Chen Zhu', 'Renkun Ni', 'Ping-yeh Chiang', 'Hengduo Li', 'Furong Huang', 'Tom Goldstein']", "abstract": "Convex relaxations are effective for training and certifying neural networks against norm-bounded adversarial attacks, but they leave a large gap between certifiable and empirical (PGD) robustness. In principle, relaxation can provide tight bounds if the convex relaxation solution is feasible for the original non-relaxed problem. Therefore, we propose two regularizers that can be used to train neural networks that yield convex relaxations with tighter bounds. In all of our experiments, the proposed regularizations result in tighter certification bounds than non-regularized baselines. ", "pdf": "/pdf/e86def7fa712ad4b63a8830c3251edddb66701cd.pdf", "keywords": "['Convex Relaxation', 'Certified Robustness', 'Regularization']", "id": "HygqFlBtPS"}, {"number": "1434", "title": "DeepSFM: Structure From Motion Via Deep Bundle Adjustment", "authors": "['Xingkui Wei', 'Yinda Zhang', 'Zhuwen Li', 'Yanwei Fu', 'Xiangyang Xue']", "abstract": "Structure from motion (SfM) is an essential computer vision problem which has not been well handled by deep learning. One of the promising trends is to apply explicit structural constraint, e.g. 3D cost volume, into the network. In this work, we design a physical driven architecture, namely DeepSFM, inspired by traditional Bundle Adjustment (BA), which consists of two cost volume based architectures for depth and pose estimation respectively, iteratively running  to improve both. In each cost volume, we encode not only photo-metric consistency across multiple input images, but also geometric consistency to ensure that depths from multiple views agree with each other. The explicit constraints on both depth (structure) and pose (motion), when combined with the learning components, bring the merit from both traditional BA and emerging deep learning technology. Extensive experiments on various datasets show that our model achieves the state-of-the-art performance on both depth and pose estimation with superior robustness against less number of inputs and the noise in initialization.\n", "pdf": "/pdf/4bb765d5042c2258e700c38a0be76f6c6ceb70ef.pdf", "keywords": "['Computer Vision', 'Bundle Ajustment', 'Structure from Motion']", "id": "SyeD0RVtvS"}, {"number": "191", "title": "Classification Attention for Chinese NER", "authors": "['Yuchen Ge', 'FanYang', 'PeiYang']", "abstract": "The character-based model, such as BERT, has achieved remarkable success in Chinese named entity recognition (NER). However, such model would likely miss the overall information of the entity words. In this paper, we propose to combine priori entity information with BERT. Instead of relying on additional lexicons or pre-trained word embeddings, our model has generated entity classification embeddings directly on the pre-trained BERT, having the merit of increasing model practicability and avoiding OOV problem. Experiments show that our model has achieved state-of-the-art results on 3 Chinese NER datasets.", "pdf": "/pdf/c4df8bbf5593032c160b6e31ed084b4a73f3daba.pdf", "keywords": "['Chinese NER', 'NER', 'tagging', 'deeplearning', 'nlp']", "id": "B1gUn24tPr"}, {"number": "1671", "title": "Improving Federated Learning Personalization via Model Agnostic Meta Learning", "authors": "['Yihan Jiang', 'Jakub Kone\u010dn\u00fd', 'Keith Rush', 'Sreeram Kannan']", "abstract": "Federated Learning (FL) refers to learning a high quality global model based on decentralized data storage, without ever copying the raw data. A natural scenario arises with data created on mobile phones by the activity of their users. Given the typical data heterogeneity in such situations, it is natural to ask how can the global model be personalized for every such device, individually. In this work, we point out that the setting of Model Agnostic Meta Learning (MAML), where one optimizes for a fast, gradient-based, few-shot adaptation to a heterogeneous distribution of tasks, has a number of similarities with the objective of personalization for FL. We present FL as a natural source of practical applications for MAML algorithms, and make the following observations. 1) The popular FL algorithm, Federated Averaging, can be interpreted as a meta learning algorithm. 2) Careful fine-tuning can yield a global model with higher accuracy, which is at the same time easier to personalize. However, solely optimizing for the global model accuracy yields a weaker personalization result. 3) A model trained using a standard datacenter optimization method is much harder to personalize, compared to one trained using Federated Averaging, supporting the first claim. These results raise new questions for FL, MAML, and broader ML research.", "pdf": "/pdf/2c4b713b2c09c0749c1b5b884c91a403d28e2436.pdf", "keywords": "['Federated Learning', 'Model Agnostic Meta Learning', 'Personalization']", "id": "BkeaEyBYDB"}, {"number": "1908", "title": "Learning with Social Influence through  Interior Policy Differentiation", "authors": "['Hao Sun', 'Bo Dai', 'Jiankai Sun', 'Zhenghao Peng', 'Guodong Xu', 'Dahua Lin', 'Bolei Zhou']", "abstract": "Animals develop novel skills not only through the interaction with the environment but also from the influence of the others. In this work we model the social influence into the scheme of reinforcement learning, enabling the agents to learn both from the environment and from their peers. Specifically, we first define a metric to measure the distance between policies then quantitatively derive the definition of uniqueness. Unlike previous precarious joint optimization approaches, the social uniqueness motivation in our work is imposed as a constraint to encourage the agent to learn a policy different from the existing agents while still solve the primal task. The resulting algorithm, namely Interior Policy Differentiation (IPD), brings about performance improvement as well as a collection of policies that solve a given task with distinct behaviors", "pdf": "/pdf/20a767f95694a120790228f788596a55ad4e8c1c.pdf", "keywords": "['Reinforcement Learning', 'Social Uniqueness', 'Policy Differentiation']", "id": "SJeQi1HKDH"}, {"number": "1454", "title": "Convolutional Tensor-Train LSTM for Long-Term Video Prediction", "authors": "['Jiahao Su', 'Wonmin Byeon', 'Furong Huang', 'Jan Kautz', 'Animashree Anandkumar']", "abstract": "Long-term video prediction is highly challenging since it entails simultaneously capturing spatial and temporal information across a long range of image frames.Standard recurrent models are ineffective since they are prone to error propagation and cannot effectively capture higher-order correlations. A potential solution is to extend to higher-order spatio-temporal recurrent models. However, such a model requires  a  large number of parameters and operations, making it intractable  to learn in practice and is prone to overfitting. In this work, we propose convolutional tensor-train LSTM (Conv-TT-LSTM), which  learns higher-orderConvolutional LSTM (ConvLSTM) efficiently using convolutional  tensor-train decomposition (CTTD). Our proposed model naturally incorporates higher-order spatio-temporal information at a small cost of memory and computation by using efficient low-rank tensor representations. We evaluate our model on Moving-MNIST and KTH datasets and show improvements over standard ConvLSTM and better/comparable results to other ConvLSTM-based approaches, but with much fewer parameters.", "pdf": "/pdf/921c7a245bef64ed33d4cc827be4db59c547fbac.pdf", "keywords": "['Tensor decomposition', 'Video prediction']", "id": "Hkee1JBKwB"}, {"number": "797", "title": "Hamiltonian Generative Networks", "authors": "['Peter Toth', 'Danilo J. Rezende', 'Andrew Jaegle', 'S\u00e9bastien Racani\u00e8re', 'Aleksandar Botev', 'Irina Higgins']", "abstract": "The Hamiltonian formalism plays a central role in classical and quantum physics. Hamiltonians are the main tool for modelling the continuous time evolution of systems with conserved quantities, and they come equipped with many useful properties, like time reversibility and smooth interpolation in time. These properties are important for many machine learning problems - from sequence prediction to reinforcement learning and density modelling - but are not typically provided out of the box by standard tools such as recurrent neural networks. In this paper, we introduce the Hamiltonian Generative Network (HGN), the first approach capable of consistently learning Hamiltonian dynamics from high-dimensional observations (such as images) without restrictive domain assumptions. Once trained, we can use HGN to sample new trajectories, perform rollouts both forward and backward in time, and even speed up or slow down the learned dynamics. We demonstrate how a simple modification of the network architecture turns HGN into a powerful normalising flow model, called Neural Hamiltonian Flow (NHF), that uses Hamiltonian dynamics to model expressive densities. Hence, we hope that our work serves as a first practical demonstration of the value that the Hamiltonian formalism can bring to machine learning. More results and video evaluations are available at: http://tiny.cc/hgn", "pdf": "/pdf/aff7b5eb43963e39c8330cd2fb8c9054c72286c7.pdf", "keywords": "['Hamiltonian dynamics', 'normalising flows', 'generative model', 'physics']", "id": "HJenn6VFvB"}, {"number": "2156", "title": "Progressive Compressed Records: Taking a Byte Out of Deep Learning Data", "authors": "['Michael Kuchnik', 'George Amvrosiadis', 'Virginia Smith']", "abstract": "Deep learning training accesses vast amounts of data at high velocity, posing challenges for datasets retrieved over commodity networks and storage devices. We introduce a way to dynamically reduce the overhead of fetching and transporting training data with a method we term Progressive Compressed Records (PCRs). PCRs deviate from previous formats by leveraging progressive compression to split each training example into multiple examples of increasingly higher fidelity, without adding to the total data size. Training examples of similar fidelity are grouped together, which reduces both the system overhead and data bandwidth needed to train a model. We show that models can be trained on aggressively compressed representations of the training data and still retain high accuracy, and that PCRs can enable a 2x speedup on average over baseline formats using JPEG compression. Our results hold across deep learning architectures for a wide range of datasets: ImageNet, HAM10000, Stanford Cars, and CelebA-HQ.", "pdf": "/pdf/e28989ea5e11ee2e03007933b6fc61345e1f3fda.pdf", "keywords": "['Deep Learning', 'Storage', 'Bandwidth', 'Compression']", "id": "S1e0ZlHYDB"}, {"number": "217", "title": "Neural Architecture Search in Embedding Space", "authors": "['chun-ting liu']", "abstract": "The neural architecture search (NAS) algorithm with reinforcement learning can be a powerful and novel framework for the automatic discovering process of neural architectures. However, its application is restricted by noncontinuous and high-dimensional search spaces, which result in difficulty in optimization. To resolve these problems, we proposed NAS in embedding space (NASES), which is a novel framework. Unlike other NAS with reinforcement learning approaches that search over a discrete and high-dimensional architecture space, this approach enables reinforcement learning to search in an embedding space by using architecture encoders and decoders. The current experiment demonstrated that the performance of the final architecture network using the NASES procedure is comparable with that of other popular NAS approaches for the image classification task on CIFAR-10. The beneficial-performance and effectiveness of NASES was impressive even when only the architecture-embedding searching and pre-training controller were applied without other NAS tricks such as parameter sharing. Specifically, considerable reduction in searches was achieved by reducing the average number of searching to < 100 architectures to achieve a final architecture for the NASES procedure.", "pdf": "/pdf/bae56aaca50c310a698df1eaf5c6bc2fef8cc51d.pdf", "keywords": "['neural architecture search', 'nas', 'automl']", "id": "HylWahVtwB"}, {"number": "836", "title": "Gradientless Descent: High-Dimensional Zeroth-Order Optimization", "authors": "['Daniel Golovin', 'John Karro', 'Greg Kochanski', 'Chansoo Lee', 'Xingyou Song', 'Qiuyi Zhang']", "abstract": "Zeroth-order optimization is the process of minimizing an objective $f(x)$, given oracle access to evaluations at adaptively chosen inputs $x$. In this paper, we present two simple yet powerful GradientLess Descent (GLD) algorithms that do not rely on an underlying gradient estimate and are numerically stable. We analyze our algorithm from a novel geometric perspective and we show that for {\\it any monotone transform} of a smooth and strongly convex objective with latent dimension $k \\ge n$, we present a novel analysis that shows convergence within an $\\epsilon$-ball of the optimum in $O(kQ\\log(n)\\log(R/\\epsilon))$ evaluations, where the input dimension is $n$, $R$ is the diameter of the input space and $Q$ is the condition number. Our rates are the first of its kind to be both 1) poly-logarithmically dependent on dimensionality and 2) invariant under monotone transformations. We further leverage our geometric perspective to show that our analysis is optimal. Both monotone invariance and its ability to utilize a low latent dimensionality are key to the empirical success of our algorithms, as demonstrated on synthetic and MuJoCo benchmarks.\n", "pdf": "/pdf/1a15c326711e247f5d5d99721aa7a6333c7c12b5.pdf", "keywords": "['Zeroth Order Optimization']", "id": "Skep6TVYDB"}, {"number": "1262", "title": "Dual-module Inference for Efficient Recurrent Neural Networks", "authors": "['Liu Liu', 'Lei Deng', 'Shuangchen Li', 'Jingwei Zhang', 'Yihua Yang', 'Zhenyu Gu', 'Yufei Ding', 'Yuan Xie']", "abstract": "Using Recurrent Neural Networks (RNNs) in sequence modeling tasks is promising in delivering high-quality results but challenging to meet stringent latency requirements because of the memory-bound execution pattern of RNNs. We propose a big-little dual-module inference to dynamically skip unnecessary memory access and computation to speedup RNN inference. Leveraging the error-resilient feature of nonlinear activation functions used in RNNs, we propose to use a lightweight little module that approximates the original RNN layer, which is referred to as the big module, to compute activations of the insensitive region that are more error-resilient. The expensive memory access and computation of the big module can be reduced as the results are only used in the sensitive region. Our method can reduce the overall memory access by 40% on average and achieve 1.54x to 1.75x speedup on CPU-based server platform with negligible impact on model quality.", "pdf": "/pdf/bbba08e21d980106cb1a43ea05a49ca113bc3fd3.pdf", "keywords": "['memory-efficient RNNs', 'dynamic execution', 'computation skipping']", "id": "SJe3KCNKPr"}, {"number": "114", "title": "Stagnant zone segmentation with U-net", "authors": "['Selam Waktola', 'Laurent Babout', 'Krzysztof Grudzien']", "abstract": "Silo discharging and monitoring the process for\nindustrial or research application depend on computerized\nsegmentation of different parts of images such as stagnant and\nflowing zones which is the toughest task. X-ray Computed\nTomography (CT) is one of a powerful non-destructive technique\nfor cross-sectional images of a 3D object based on X-ray\nabsorption. CT is the most proficient for investigating different\ngranular flow phenomena and segmentation of the stagnant zone\nas compared to other imaging techniques. In any case, manual\nsegmentation is tiresome and erroneous for further investigations.\nHence, automatic and precise strategies are required. In the\npresent work, a U-net architecture is used for segmenting the\nstagnant zone during silo discharging process. This proposed\nimage segmentation method provides fast and effective outcomes\nby exploiting a convolutional neural networks technique with an\naccuracy of 97 percent", "pdf": "/pdf/05690c946260cec59300fcbbda9e5406ba109e01.pdf", "keywords": "[]", "id": "H1eH9hNtwr"}, {"number": "1808", "title": "Accelerated Variance Reduced Stochastic Extragradient Method for Sparse Machine Learning Problems", "authors": "['Fanhua Shang', 'Lin Kong', 'Yuanyuan Liu', 'Hua Huang', 'Hongying Liu']", "abstract": "Recently, many stochastic gradient descent algorithms with variance reduction have been proposed. Moreover, their proximal variants such as Prox-SVRG can effectively solve non-smooth problems, which makes that they are widely applied in many machine learning problems. However, the introduction of proximal operator will result in the error of the optimal value. In order to address this issue, we introduce the idea of extragradient and propose a novel accelerated variance reduced stochastic extragradient descent (AVR-SExtraGD) algorithm, which inherits the advantages of Prox-SVRG and momentum acceleration techniques. Moreover, our  theoretical analysis shows that AVR-SExtraGD enjoys the best-known convergence rates and oracle complexities of stochastic first-order algorithms such as Katyusha for both strongly convex and non-strongly convex problems. Finally, our experimental results show that for ERM problems and robust face recognition via sparse representation, our AVR-SExtraGD can yield the improved performance compared with Prox-SVRG and Katyusha. The asynchronous variant of AVR-SExtraGD outperforms KroMagnon and ASAGA, which are the asynchronous variants of SVRG and SAGA, respectively.", "pdf": "/pdf/88630807d5977ce9f20b16c35df88a84dd59c177.pdf", "keywords": "['non-smooth optimization', 'SVRG', 'proximal operator', 'extragradient descent', 'momentum acceleration']", "id": "BklDO1HYPS"}, {"number": "953", "title": "NESTED LEARNING FOR MULTI-GRANULAR TASKS", "authors": "['Rapha\u00ebl Achddou', 'J. Matias Di Martino', 'Guillermo Sapiro']", "abstract": "Standard deep neural networks (DNNs) used for classification are trained in an end-to-end fashion for very specific tasks - object recognition, face identification, character recognition, etc. This specificity often leads to overconfident models that generalize poorly to samples that are not from the original training distribution. Moreover, they do not allow to leverage information from heterogeneously annotated data, where for example, labels may be provided with different levels of granularity. Finally, standard DNNs do not produce results with simultaneous different levels of confidence for different levels of detail, they are most commonly an all or nothing approach. To address these challenges, we introduce the problem of nested learning: how to obtain a hierarchical representation of the input such that a coarse label can be extracted first, and sequentially refine this representation to obtain successively refined predictions, all of them with the corresponding confidence. We explicitly enforce this behaviour by creating a sequence of nested information bottlenecks. Looking at the problem of nested learning from an in formation theory perspective, we design a network topology with two important properties. First, a sequence of low dimensional (nested) feature embeddings are enforced. Then we show how the explicit combination of nested outputs can improve both robustness and finer predictions. Experimental results on CIFAR-10, MNIST, and FASHION-MNIST demonstrate that nested learning outperforms the same network trained in the standard end-to-end fashion. Since the network can be naturally trained with mixed data labeled at different levels of nested details, we also study what is the most efficient way of annotating data, when a fixed training budget is given and the cost of labels increases with the levels in the nested hierarchy.", "pdf": "/pdf/11f08f8e506ed4972802ee27f73d6e9536de337e.pdf", "keywords": "['Nested learning']", "id": "Byxl-04KvH"}, {"number": "1201", "title": "Attention Interpretability Across NLP Tasks", "authors": "['Shikhar Vashishth', 'Shyam Upadhyay', 'Gaurav Singh Tomar', 'Manaal Faruqui']", "abstract": "The attention layer in a neural network model provides insights into the models reasoning behind its prediction, which are usually criticized for being opaque. Recently, seemingly contradictory viewpoints have emerged about the interpretability of attention weights (Jain & Wallace, 2019; Vig & Belinkov, 2019). Amid such confusion arises the need to understand attention mechanism more systematically. In this work, we attempt to fill this gap by giving a comprehensive explanation which justifies both kinds of observations (i.e., when is attention interpretable and when it is not). Through a series of experiments on diverse NLP tasks, we validate our observations and reinforce our claim of interpretability of attention through manual evaluation.", "pdf": "/pdf/2d62995b00384077cf6a3811bc6ac2ba08b7c0a5.pdf", "keywords": "['Attention', 'NLP', 'Interpretability']", "id": "BJe-_CNKPH"}, {"number": "952", "title": "Scalable Model Compression by Entropy Penalized Reparameterization", "authors": "['Deniz Oktay', 'Johannes Ball\u00e9', 'Saurabh Singh', 'Abhinav Shrivastava']", "abstract": "We describe a simple and general neural network weight compression approach, in which the network parameters (weights and biases) are represented in a latent space, amounting to a reparameterization. This space is equipped with a learned probability model, which is used to impose an entropy penalty on the parameter representation during training, and to compress the representation using a simple arithmetic coder after training. Classification accuracy and model compressibility is maximized jointly, with the bitrateaccuracy trade-off specified by a hyperparameter. We evaluate the method on the MNIST, CIFAR-10 and ImageNet classification benchmarks using six distinct model architectures. Our results show that state-of-the-art model compression can be achieved in a scalable and general way without requiring complex procedures such as multi-stage training.", "pdf": "/pdf/53fae83d46c6eae9e5149c6fa256a101b082e93a.pdf", "keywords": "['deep learning', 'model compression', 'computer vision', 'information theory']", "id": "HkgxW0EYDS"}, {"number": "2340", "title": "Qgraph-bounded Q-learning: Stabilizing Model-Free Off-Policy Deep Reinforcement Learning", "authors": "['Sabrina Hoppe', 'Marc Toussaint']", "abstract": "In state of the art model-free off-policy deep reinforcement learning (RL), a replay memory is used to store past experience and derive all network updates. Even if both state and action spaces are continuous, the replay memory only holds a finite number of transitions.  We represent these transitions in a data graph and link its structure to soft divergence. By selecting a subgraph with a favorable structure, we construct a simple Markov Decision Process (MDP) for which exact Q-values can be computed efficiently as more data comes in - resulting in a Qgraph. We show that the Q-value for each transition in the simplified MDP is a lower bound of the Q-value for the same transition in the original continuous Q-learning problem. By using these lower bounds in TD learning, our method is less prone to soft divergence and exhibits increased sample efficiency while being more robust to hyperparameters. Qgraphs also retain information from transitions that have already been overwritten in the replay memory, which can decrease the algorithm's sensitivity to the replay memory capacity.\n", "pdf": "/pdf/f68a27754ceb28198a6bc5348f9b2d7509c3759d.pdf", "keywords": "['deep learning', 'reinforcement learning', 'model-free reinforcement learning', 'Q-learning', 'DDPG']", "id": "HygTUxHKwH"}, {"number": "630", "title": "NAS evaluation is frustratingly hard", "authors": "['Antoine Yang', 'Pedro M. Esperan\u00e7a', 'Fabio M. Carlucci']", "abstract": "Neural Architecture Search (NAS) is an exciting new field which promises to be as much as a game-changer as Convolutional Neural Networks were in 2012. Despite many great works leading to substantial improvements on a variety of tasks, comparison between different methods is still very much an open issue. While most algorithms are tested on the same datasets, there is no shared experimental protocol followed by all. As such, and due to the under-use of ablation studies, there is a lack of clarity regarding why certain methods are more effective than others. Our first contribution is a benchmark of 8 NAS methods on 5 datasets. To overcome the hurdle of comparing methods with different search spaces, we propose using a methods relative improvement over the randomly sampled average architecture, which effectively removes advantages arising from expertly engineered search spaces or training protocols. Surprisingly, we find that many NAS techniques struggle to significantly beat the average architecture baseline. We perform further experiments with the commonly used DARTS search space in order to understand the contribution of each component in the NAS pipeline. These experiments highlight that: (i) the use of tricks in the evaluation protocol has a predominant impact on the reported performance of architectures; (ii) the cell-based search space has a very narrow accuracy range, such that the seed has a considerable impact on architecture rankings; (iii) the hand-designed macrostructure (cells) is more important than the searched micro-structure (operations); and (iv) the depth-gap is a real phenomenon, evidenced by the change in rankings between 8 and 20 cell architectures. To conclude, we suggest best practices, that we hope will prove useful for the community and help mitigate current NAS pitfalls, e.g. difficulties in reproducibility and comparison of search methods. The\ncode used is available at https://github.com/antoyang/NAS-Benchmark.", "pdf": "/pdf/2d0d2643d5295b6885c025c9313be38f0d3ce47c.pdf", "keywords": "['neural architecture search', 'nas', 'benchmark', 'reproducibility', 'harking']", "id": "HygrdpVKvr"}, {"number": "1409", "title": "COMBINED FLEXIBLE ACTIVATION FUNCTIONS FOR DEEP NEURAL NETWORKS", "authors": "['Renlong Jie', 'Junbin Gao', 'Andrey Vasnev', 'Minh-Ngoc Tran']", "abstract": "Activation in deep neural networks is fundamental to achieving non-linear mappings. Traditional studies mainly focus on finding fixed activations for a particular set of learning tasks or model architectures. The research on flexible activation is quite limited in both designing philosophy and application scenarios. In this study, we propose a general combined form of flexible activation functions as well as three principles of choosing flexible activation component. Based on this, we develop two novel flexible activation functions that can be implemented in LSTM cells and auto-encoder layers. Also two new regularisation terms based on assumptions as prior knowledge are proposed. We find that LSTM and auto-encoder models with proposed flexible activations provides significant improvements on time series forecasting and image compressing tasks, while layer-wise regularization can improve the performance of CNN (LeNet-5) models with RPeLu activation in image classification tasks.", "pdf": "/pdf/7ec95c63b73a04a810e869813edcae63688b8b3d.pdf", "keywords": "['Flexible', 'Activation Functions', 'Deep Learning', 'Regularization']", "id": "r1lh6C4FDr"}, {"number": "1313", "title": "Adversarial training with perturbation generator networks", "authors": "['Hyeungill Lee', 'Sungyeob Han', 'Jungwoo Lee']", "abstract": "Despite the remarkable development of recent deep learning techniques, neural networks are still vulnerable to adversarial attacks, i.e., methods that fool the neural networks with perturbations that are too small for human eyes to perceive. Many adversarial training methods were introduced as to solve this problem, using adversarial examples as a training data. However, these adversarial attack methods used in these techniques are fixed, making the model stronger only to attacks used in training, which is widely known as an overfitting problem. In this paper, we suggest a novel adversarial training approach. In addition to the classifier, our method adds another neural network that generates the most effective adversarial perturbation by finding the weakness of the classifier. This perturbation generator network is trained to produce perturbations that maximize the loss function of the classifier, and these adversarial examples train the classifier with a true label. In short, the two networks compete with each other, performing a minimax game. In this scenario, attack patterns created by the generator network are adaptively altered to the classifier, mitigating the overfitting problem mentioned above. We theoretically proved that our minimax optimization problem is equivalent to minimizing the adversarial loss after all. Beyond this, we proposed an evaluation method that could accurately compare a wide-range of adversarial algorithms. Experiments with various datasets show that our method outperforms conventional adversarial algorithms. ", "pdf": "/pdf/2b0d1bf7a636aa5137e020fa00b8ff68335b4f8a.pdf", "keywords": "['Adversarial training', 'Generative model', 'Adaptive perturbation generator', 'Robust optimization']", "id": "S1xXiREKDB"}, {"number": "598", "title": "Confidence Scores Make Instance-dependent Label-noise Learning Possible", "authors": "['Antonin Berthon', 'Bo Han', 'Gang Niu', 'Tongliang Liu', 'Masashi Sugiyama']", "abstract": "Learning with noisy labels has drawn a lot of attention. In this area, most of recent works only consider class-conditional noise, where the label noise is independent of its input features. This noise model may not be faithful to many real-world applications. Instead, few pioneer works have studied instance-dependent noise, but these methods are limited to strong assumptions on noise models. To alleviate this issue, we introduce confidence-scored instance-dependent noise (CSIDN), where each instance-label pair is associated with a confidence score. The confidence scores are sufficient to estimate the noise functions of each instance with minimal assumptions. Moreover, such scores can be easily and cheaply derived during the construction of the dataset through crowdsourcing or automatic annotation. To handle CSIDN, we design a benchmark algorithm termed instance-level forward correction. Empirical results on synthetic and real-world datasets demonstrate the utility of our proposed method.", "pdf": "/pdf/6cf5fa437aa8ad33e715e1ec525ca5a140387a35.pdf", "keywords": "['Instance-dependent label noise', 'Deep learning']", "id": "SyevDaVYwr"}, {"number": "730", "title": "Neural networks are a priori biased towards Boolean functions with low entropy", "authors": "['Chris Mingard', 'Joar Skalse', 'Guillermo Valle-P\u00e9rez', 'David Mart\u00ednez-Rubio', 'Vladimir Mikulik', 'Ard A. Louis']", "abstract": "Understanding the inductive bias of neural networks is critical to explaining their ability to generalise.  Here,  \nfor one of the simplest neural networks -- a single-layer perceptron with $n$ input neurons,  one output neuron, and no threshold bias term -- we prove that upon random initialisation of weights, the a priori probability  $P(t)$ that it represents a Boolean function that classifies $t$ points in $\\{0,1\\}^n$ as $1$ has a remarkably simple form: $\nP(t) = 2^{-n} \\,\\, {\\rm for} \\,\\, 0\\leq t < 2^n$.\nSince a perceptron can express far fewer Boolean functions with small or large values of $t$ (low 'entropy') than with intermediate values of $t$ (high 'entropy') there is, on average, a strong intrinsic a-priori bias towards individual functions with low entropy. Furthermore, within a class of functions with fixed $t$, we often observe a further intrinsic bias towards functions of lower complexity.\nFinally, we prove that, regardless of the distribution of inputs, the bias towards low entropy becomes monotonically stronger upon adding ReLU layers, and empirically show that increasing the variance of the bias term has a similar effect.", "pdf": "/pdf/dee69b9601aeeffbc32192a42da2a7a54b51af41.pdf", "keywords": "['class imbalance', 'perceptron', 'inductive bias', 'simplicity bias', 'initialization']", "id": "Skgeip4FPr"}, {"number": "1783", "title": "OPTIMAL BINARY QUANTIZATION FOR DEEP NEURAL NETWORKS", "authors": "['Hadi Pouransari', 'Oncel Tuzel']", "abstract": "Quantizing weights and activations of deep neural networks results in significant improvement in inference efficiency at the cost of lower accuracy. A source of the accuracy gap between full precision and quantized models is the quantization error.\nIn this work, we focus on the binary quantization, in which values are mapped to -1 and 1. We introduce several novel quantization algorithms: optimal 2-bits, optimal ternary, and greedy. Our quantization algorithms can be implemented efficiently on the hardware using bitwise operations. We present proofs to show that our proposed methods are optimal, and also provide empirical error analysis. We conduct experiments on the ImageNet dataset and show a reduced accuracy gap when using the proposed optimal quantization algorithms.", "pdf": "/pdf/2cc6fcf48c3200eaecbee011ccdecbfebef85dc4.pdf", "keywords": "['Binary Neural Networks', 'Quantization']", "id": "S1gTwJSKvr"}, {"number": "449", "title": "Effective Use of Variational Embedding Capacity in Expressive End-to-End Speech Synthesis", "authors": "['Eric Battenberg', 'Soroosh Mariooryad', 'Daisy Stanton', 'RJ Skerry-Ryan', 'Matt Shannon', 'David Kao', 'Tom Bagby']", "abstract": "Recent work has explored sequence-to-sequence latent variable models for expressive speech synthesis (supporting control and transfer of prosody and style), but has not presented a coherent framework for understanding the trade-offs between the competing methods. In this paper, we propose embedding capacity (the amount of information the embedding contains about the data) as a unified method of analyzing the behavior of latent variable models of speech, comparing existing heuristic (non-variational) methods to variational methods that are able to explicitly constrain capacity using an upper bound on representational mutual information. In our proposed model (Capacitron), we show that by adding conditional dependencies to the variational posterior such that it matches the form of the true posterior, the same model can be used for high-precision prosody transfer, text-agnostic style transfer, and generation of natural-sounding prior samples. For multi-speaker models, Capacitron is able to preserve target speaker identity during inter-speaker prosody transfer and when drawing samples from the latent prior. Lastly, we introduce a method for decomposing embedding capacity hierarchically across two sets of latents, allowing a portion of the latent variability to be specified and the remaining variability sampled from a learned prior. Audio examples are available on the web.", "pdf": "/pdf/0a942da1c282c59a59efbbab057e5d95e8f53f32.pdf", "keywords": "['Speech Synthesis', 'Deep Generative Models', 'Latent Variable Models', 'Unsupervised Representation Learning']", "id": "SJgBQaVKwH"}, {"number": "477", "title": "Global Concavity and Optimization in a Class of Dynamic Discrete Choice Models", "authors": "['Yiding Feng', 'Ekaterina Khmelnitskaya', 'Denis Nekipelov']", "abstract": "Discrete choice models with unobserved heterogeneity are commonly used Econometric models for dynamic Economic behavior which have been adopted in practice to predict behavior of individuals and firms from schooling and job choices to strategic decisions in market competition. These models  feature optimizing agents who choose among a finite set of options in a sequence of periods and receive choice-specific payoffs that depend on both variables that are observed by the agent and recorded in the data and variables that are only observed by the agent but not recorded in the data. Existing work in Econometrics assumes that optimizing agents are fully rational and requires finding a functional fixed point to find the optimal policy. We show that in an important class of discrete choice models the value function is globally concave in the policy. That means that simple algorithms that do not require fixed point computation, such as the policy gradient algorithm, globally converge to the optimal policy. This finding can both be used to relax behavioral assumption regarding the optimizing agents and to facilitate Econometric analysis of dynamic behavior. In particular, we demonstrate significant computational advantages in using a simple implementation policy gradient algorithm over existing 'nested fixed point' algorithms used in Econometrics.", "pdf": "/pdf/d2ce83832ed7661ac0fb21e31172ff69498abf48.pdf", "keywords": "['Reinforcement learning', 'Policy Gradient', 'Global Concavity', 'Dynamic Discrete Choice Model']", "id": "H1efEp4Yvr"}, {"number": "356", "title": "Contrastive Learning of Structured World Models", "authors": "['Thomas Kipf', 'Elise van der Pol', 'Max Welling']", "abstract": "A structured understanding of our world in terms of objects, relations, and hierarchies is an important component of human cognition. Learning such a structured world model from raw sensory data remains a challenge. As a step towards this goal, we introduce Contrastively-trained Structured World Models (C-SWMs). C-SWMs utilize a contrastive approach for representation learning in environments with compositional structure. We structure each state embedding as a set of object representations and their relations, modeled by a graph neural network. This allows objects to be discovered from raw pixel observations without direct supervision as part of the learning process. We evaluate C-SWMs on compositional environments involving multiple interacting objects that can be manipulated independently by an agent, simple Atari games, and a multi-object physics simulation. Our experiments demonstrate that C-SWMs can overcome limitations of models based on pixel reconstruction and outperform typical representatives of this model class in highly structured environments, while learning interpretable object-based representations.", "pdf": "/pdf/9358897ed5bc9ee514546d3e76b158e0bdb4da56.pdf", "keywords": "['state representation learning', 'graph neural networks', 'model-based reinforcement learning', 'relational learning', 'object discovery']", "id": "H1gax6VtDB"}, {"number": "1139", "title": "Oblique Decision Trees from Derivatives of ReLU Networks", "authors": "['Guang-He Lee', 'Tommi S. Jaakkola']", "abstract": "We show how neural models can be used to realize piece-wise constant functions such as decision trees. The proposed architecture, which we call locally constant networks, builds on ReLU networks that are piece-wise linear and hence their associated gradients with respect to the inputs are locally constant. We formally establish the equivalence between the classes of locally constant networks and decision trees. Moreover, we highlight several advantageous properties of locally constant networks, including how they realize decision trees with parameter sharing across branching / leaves. Indeed, only $M$ neurons suffice to implicitly model an oblique decision tree with $2^M$ leaf nodes. The neural representation also enables us to adopt many tools developed for deep networks (e.g., DropConnect (Wan et al., 2013)) while implicitly training decision trees. We demonstrate that our method outperforms alternative techniques for training oblique decision trees in the context of molecular property classification and regression tasks. ", "pdf": "/pdf/4be2fc47fc1d018292995db8b286af2469c91b53.pdf", "keywords": "['oblique decision trees', 'ReLU networks']", "id": "Bke8UR4FPB"}, {"number": "2132", "title": "Decoupling Hierarchical Recurrent Neural Networks With Locally Computable Losses", "authors": "['Asier Mujika', 'Felix Weissenberger', 'Angelika Steger']", "abstract": "Learning long-term dependencies is a key long-standing challenge of recurrent neural networks (RNNs). Hierarchical recurrent neural networks (HRNNs) have been considered a promising approach as long-term dependencies are resolved through shortcuts up and down the hierarchy. Yet, the memory requirements of Truncated Backpropagation Through Time (TBPTT) still prevent training them on very long sequences. In this paper, we empirically show that in (deep) HRNNs, propagating gradients back from higher to lower levels can be replaced by locally computable losses, without harming the learning capability of the network, over a wide range of tasks. This decoupling by local losses reduces the memory requirements of training by a factor exponential in the depth of the hierarchy in comparison to standard TBPTT.", "pdf": "/pdf/922765b34628d839e74aaf5dd9a54ce01d9ccde5.pdf", "keywords": "[]", "id": "S1lNWertDr"}, {"number": "1636", "title": "Guiding Program Synthesis by Learning to Generate Examples", "authors": "['Larissa Laich', 'Pavol Bielik', 'Martin Vechev']", "abstract": "A key challenge of existing program synthesizers is ensuring that the synthesized program generalizes well. This can be difficult to achieve as the specification provided by the end user is often limited, containing as few as one or two input-output examples. In this paper we address this challenge via an iterative approach that finds ambiguities in the provided specification and learns to resolve these by generating additional input-output examples. The main insight is to reduce the problem of selecting which program generalizes well to the simpler task of deciding which output is correct. As a result, to train our probabilistic models, we can take advantage of the large amounts of data in the form of program outputs, which are often much easier to obtain than the corresponding ground-truth programs.", "pdf": "/pdf/e38826be42dfd8f83e0dd46f45c4225c5274bf01.pdf", "keywords": "['program synthesis', 'programming by examples']", "id": "BJl07ySKvS"}, {"number": "493", "title": "Learning Boolean Circuits with Neural Networks", "authors": "['Eran Malach', 'Shai Shalev-Shwartz']", "abstract": "Training neural-networks is computationally hard. However, in practice they are trained efficiently using gradient-based algorithms, achieving remarkable performance on natural data. To bridge this gap, we observe the property of local correlation: correlation between small patterns of the input and the target label. We focus on learning deep neural-networks with a variant of gradient-descent, when the target function is a tree-structured Boolean circuit. We show that in this case, the existence of correlation between the gates of the circuit and the target label determines whether the optimization succeeds or fails. Using this result, we show that neural-networks can learn the (log n)-parity problem for most product distributions. These results hint that local correlation may play an important role in differentiating between distributions that are hard or easy to learn.", "pdf": "/pdf/f5011a40e008b37f6017a96ba57311228529b6d8.pdf", "keywords": "['neural-networks', 'deep learning theory']", "id": "BkxtNaEYDr"}, {"number": "703", "title": "Deep RL for Blood Glucose Control: Lessons, Challenges, and Opportunities", "authors": "['Ian Fox', 'Joyce Lee', 'Rodica Busui', 'Jenna Wiens']", "abstract": "Individuals with type 1 diabetes (T1D) lack the ability to produce the insulin their bodies need. As a result, they must continually make decisions about how much insulin to self-administer in order to adequately control their blood glucose levels. Longitudinal data streams captured from wearables, like continuous glucose monitors, can help these individuals manage their health, but currently the majority of the decision burden remains on the user. To relieve this burden, researchers are working on closed-loop solutions that combine a continuous glucose monitor and an insulin pump with a control algorithm in an `artificial pancreas.' Such systems aim to estimate and deliver the appropriate amount of insulin. Here, we develop reinforcement learning (RL) techniques for automated blood glucose control. Through a series of experiments, we compare the performance of different deep RL approaches to non-RL approaches. We highlight the flexibility of RL approaches, demonstrating how they can adapt to new individuals with little additional data. On over 21k hours of simulated data across 30 patients, RL approaches outperform baseline control algorithms (increasing time spent in normal glucose range from 71% to 75%) without requiring meal announcements. Moreover, these approaches are adept at leveraging latent behavioral patterns (increasing time in range from 58% to 70%). This work demonstrates the potential of deep RL for controlling complex physiological systems with minimal expert knowledge. ", "pdf": "/pdf/d814d32e297195a9b7c4f368e2e79bc551ca2264.pdf", "keywords": "['Deep Reinforcement Learning', 'Diabetes', 'Artificial Pancreas', 'Control']", "id": "ryeN5aEYDH"}, {"number": "615", "title": "Ridge Regression: Structure, Cross-Validation, and Sketching", "authors": "['Sifan Liu', 'Edgar Dobriban']", "abstract": "We study the following three fundamental problems about ridge regression: (1) what is the structure of the estimator? (2) how to correctly use cross-validation to choose the regularization parameter? and (3) how to accelerate computation without losing too much accuracy? We consider the three problems in a unified large-data linear model. We give a precise representation of ridge regression as a covariance matrix-dependent linear combination of the true parameter and the noise. \nWe study the bias of $K$-fold cross-validation for choosing the regularization parameter, and propose a simple bias-correction. We analyze the accuracy of primal and dual sketching for ridge regression, showing they are surprisingly accurate. Our results are illustrated by simulations and by analyzing empirical data.", "pdf": "/pdf/455671549ea589bd0c09c5457c52062150923fca.pdf", "keywords": "['ridge regression', 'sketching', 'random matrix theory', 'cross-validation', 'high-dimensional asymptotics']", "id": "HklRwaEKwB"}, {"number": "1169", "title": "Rigging the Lottery: Making All Tickets Winners", "authors": "['Utku Evci', 'Erich Elsen', 'Pablo Castro', 'Trevor Gale']", "abstract": "Sparse neural networks have been shown to yield computationally efficient networks with improved inference times.  There is a large body of work on training dense networks to yield sparse networks for inference (Molchanov et al., 2017;Zhu & Gupta, 2018; Louizos et al., 2017; Li et al., 2016; Guo et al., 2016).  This limits the size of the largest trainable sparse model to that of the largest trainable dense model. In this paper we introduce a method to train sparse neural networks with a fixed parameter count and a fixed computational cost throughout training, without sacrificing accuracy relative to existing dense-to-sparse training methods. Our method updates the topology of the network during training by using parameter magnitudes and infrequent gradient calculations. We show that this approach requires less floating-point operations (FLOPs) to achieve a given level of accuracy compared to prior techniques. We demonstrate state-of-the-art sparse training results with ResNet-50, MobileNet v1 and MobileNet v2 on the ImageNet-2012 dataset. Finally,  we  provide  some  insights  into  why  allowing  the  topology  to change during the optimization can overcome local minima encountered when the topology remains static.", "pdf": "/pdf/ff9c4f7d184a224e903a9b7a10be1ad832f1383f.pdf", "keywords": "['sparse training', 'sparsity', 'pruning', 'lottery tickets', 'imagenet', 'resnet', 'mobilenet', 'efficiency', 'optimization', 'local minima']", "id": "ryg7vA4tPB"}, {"number": "413", "title": "VideoFlow: A Conditional Flow-Based Model for Stochastic Video Generation", "authors": "['Manoj Kumar', 'Mohammad Babaeizadeh', 'Dumitru Erhan', 'Chelsea Finn', 'Sergey Levine', 'Laurent Dinh', 'Durk Kingma']", "abstract": "Generative models that can model and predict sequences of future events can, in principle, learn to capture complex real-world phenomena, such as physical interactions. However, a central challenge in video prediction is that the future is highly uncertain: a sequence of past observations of events can imply many possible futures. Although a number of recent works have studied probabilistic models that can represent uncertain futures, such models are either extremely expensive computationally as in the case of pixel-level autoregressive models, or do not directly optimize the likelihood of the data. To our knowledge, our work is the first to propose multi-frame video prediction with normalizing flows, which allows for direct optimization of the data likelihood, and produces high-quality stochastic predictions. We describe an approach for modeling the latent space dynamics, and demonstrate that flow-based generative models offer a viable and competitive approach to generative modeling of video.", "pdf": "/pdf/f0048f33cb4788f547460b93e23a9fa5253a59ac.pdf", "keywords": "['Video generation', 'flow-based generative models', 'stochastic video prediction']", "id": "rJgUfTEYvH"}, {"number": "2149", "title": "Meta Reinforcement Learning with Autonomous Inference of Subtask Dependencies", "authors": "['Sungryull Sohn', 'Hyunjae Woo', 'Jongwook Choi', 'Honglak Lee']", "abstract": "We propose and address a novel few-shot RL problem, where a task is characterized by a subtask graph which describes a set of subtasks and their dependencies that are unknown to the agent. The agent needs to quickly adapt to the task over few episodes during adaptation phase to maximize the return in the test phase. Instead of directly learning a meta-policy, we develop a Meta-learner with Subtask Graph Inference (MSGI), which infers the latent parameter of the task by interacting with the environment and maximizes the return given the latent parameter. To facilitate learning, we adopt an intrinsic reward inspired by upper confidence bound (UCB) that encourages efficient exploration. Our experiment results on two grid-world domains and StarCraft II environments show that the proposed method is able to accurately infer the latent task parameter, and to adapt more efficiently than existing meta RL and hierarchical RL methods.", "pdf": "/pdf/15fd85cbcd18cf2efbbee5bc401fe4b7b2be9849.pdf", "keywords": "['Meta reinforcement learning', 'subtask graph']", "id": "HkgsWxrtPB"}, {"number": "892", "title": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning", "authors": "['Ruqi Zhang', 'Chunyuan Li', 'Jianyi Zhang', 'Changyou Chen', 'Andrew Gordon Wilson']", "abstract": "The posteriors over neural network weights are high dimensional and multimodal. Each mode typically characterizes a meaningfully different representation of the data. We develop Cyclical Stochastic Gradient MCMC (SG-MCMC) to automatically explore such distributions. In particular, we propose a cyclical stepsize schedule, where larger steps discover new modes, and smaller steps characterize each mode. We prove non-asymptotic convergence theory of our proposed algorithm. Moreover, we provide extensive experimental results, including ImageNet, to demonstrate the effectiveness of cyclical SG-MCMC in learning complex multimodal distributions, especially for fully Bayesian inference with modern deep neural networks.", "pdf": "/pdf/faffe100c21426695486861801522350e9587630.pdf", "keywords": "[]", "id": "rkeS1RVtPS"}, {"number": "1931", "title": "Intrinsically Motivated Discovery of Diverse Patterns in Self-Organizing Systems", "authors": "['Chris Reinke', 'Mayalen Etcheverry', 'Pierre-Yves Oudeyer']", "abstract": "In many complex dynamical systems, artificial or natural, one can observe self-organization of patterns emerging from local rules. Cellular automata, like the Game of Life (GOL), have been widely used as abstract models enabling the study of various aspects of self-organization and morphogenesis, such as the emergence of spatially localized patterns. However, findings of self-organized patterns in such models have so far relied on manual tuning of parameters and initial states, and on the human eye to identify interesting patterns. In this paper, we formulate the problem of automated discovery of diverse self-organized patterns in such high-dimensional complex dynamical systems, as well as a framework for experimentation and evaluation. Using a continuous GOL as a testbed, we show that recent intrinsically-motivated machine learning algorithms (POP-IMGEPs), initially developed for learning of inverse models in robotics, can be transposed and used in this novel application area. These algorithms combine intrinsically-motivated goal exploration and unsupervised learning of goal space representations. Goal space representations describe the interesting features of patterns for which diverse variations should be discovered. In particular, we compare various approaches to define and learn goal space representations from the perspective of discovering diverse spatially localized patterns. Moreover, we introduce an extension of a state-of-the-art POP-IMGEP algorithm which incrementally learns a goal representation using a deep auto-encoder, and the use of CPPN primitives for generating initialization parameters. We show that it is more efficient than several baselines and equally efficient as a system pre-trained on a hand-made database of patterns identified by human experts.", "pdf": "/pdf/bb2cff5de2f13ce19f25a957f363b530b7a63f59.pdf", "keywords": "['deep learning', 'unsupervised Learning', 'self-organization', 'game-of-life']", "id": "rkg6sJHYDr"}, {"number": "1506", "title": "Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing", "authors": "['Dinghuai Zhang*', 'Mao Ye*', 'Chengyue Gong*', 'Zhanxing Zhu', 'Qiang Liu']", "abstract": "Randomized classifiers have been shown to provide a promising approach for achieving certified robustness against adversarial attacks in deep learning. However, most existing methods only leverage Gaussian smoothing noise and only work for $\\ell_2$ perturbation. We propose a general framework of adversarial certification with non-Gaussian noise and for more general types of attacks, from a unified functional optimization perspective. Our new framework allows us to identify a key trade-off between accuracy and robustness via designing smoothing distributions, helping to design two new families of non-Gaussian smoothing distributions that work more efficiently for $\\ell_2$ and $\\ell_\\infty$ attacks, respectively. Our proposed methods achieve better results than previous works and provide a new perspective on randomized smoothing certification.", "pdf": "/pdf/5430ccda33560b7029405730fa6562adde7517ec.pdf", "keywords": "['Adversarial Certification', 'Randomized Smoothing', 'Functional Optimization']", "id": "Skg8gJBFvr"}, {"number": "817", "title": "Stochastic Conditional Generative Networks with Basis Decomposition", "authors": "['Ze Wang', 'Xiuyuan Cheng', 'Guillermo Sapiro', 'Qiang Qiu']", "abstract": "While generative adversarial networks (GANs) have revolutionized machine learning, a number of open questions remain to fully understand them and exploit their power. One of these questions is how to efficiently achieve proper diversity and sampling of the multi-mode data space. To address this, we introduce BasisGAN, a stochastic conditional multi-mode image generator. By exploiting the observation that a convolutional filter can be well approximated as a linear combination of a small set of basis elements, we learn a plug-and-played basis generator to stochastically generate basis elements, with just a few hundred of parameters, to fully embed stochasticity into convolutional filters. By sampling basis elements instead of filters, we dramatically reduce the cost of modeling the parameter space with no sacrifice on either image diversity or fidelity. To illustrate this proposed plug-and-play framework, we construct variants of BasisGAN based on state-of-the-art conditional image generation networks, and train the networks by simply plugging in a basis generator, without additional auxiliary components, hyperparameters, or training objectives. The experimental success is complemented with theoretical results indicating how the perturbations introduced by the proposed sampling of basis elements can propagate to the appearance of generated images.", "pdf": "/pdf/8e4c7efd2555c085a449a3d1db3bff1bac0c4e59.pdf", "keywords": "[]", "id": "S1lSapVtwS"}, {"number": "2541", "title": "XD: Cross-lingual Knowledge Distillation for Polyglot Sentence Embeddings", "authors": "['Maksym Del', 'Mark Fishel']", "abstract": "Current state-of-the-art results in multilingual natural language inference (NLI) are based on tuning XLM (a pre-trained polyglot language model) separately for each language involved, resulting in multiple models. We reach significantly higher NLI results with a single model for all languages via multilingual tuning. Furthermore, we introduce cross-lingual knowledge distillation (XD), where the same polyglot model is used both as teacher and student across languages to improve its sentence representations without using the end-task labels. When used alone, XD beats multilingual tuning for some languages and the combination of them both results in a new state-of-the-art of 79.2% on the XNLI dataset, surpassing the previous result by absolute 2.5%. The models and code for reproducing our experiments will be made publicly available after de-anonymization.", "pdf": "/pdf/39ab0112530dbc00d00e18757b8d859a2d0fe563.pdf", "keywords": "['cross-lingual transfer', 'sentence embeddings', 'polyglot language models', 'knowledge distillation', 'natural language inference', 'embedding alignment', 'embedding mapping']", "id": "BkePneStwH"}, {"number": "1509", "title": "Power up! Robust Graph Convolutional Network based on Graph Powering", "authors": "['Ming Jin', 'Heng Chang', 'Wenwu Zhu', 'Somayeh Sojoudi']", "abstract": "Graph convolutional networks (GCNs) are powerful tools for graph-structured data. However, they have been recently shown to be vulnerable to topological attacks. To enhance adversarial robustness, we go beyond spectral graph theory to robust graph theory. By challenging the classical graph Laplacian, we propose a new convolution operator that is provably robust in the spectral domain and is incorporated in the GCN architecture to improve expressivity and interpretability. By extending the original graph to a sequence of graphs, we also propose a robust training paradigm that encourages transferability across graphs that span a range of spatial and spectral characteristics. The proposed approaches are demonstrated in extensive experiments to {simultaneously} improve performance in both benign and adversarial situations. ", "pdf": "/pdf/e1fc93c11f21fa399f0fc9184f912e50448516f3.pdf", "keywords": "['graph mining', 'graph neural network', 'adversarial robustness']", "id": "BkxDxJHFDr"}, {"number": "1060", "title": "Neural networks with motivation", "authors": "['Sergey A. Shuvaev', 'Ngoc B. Tran', 'Marcus Stephenson-Jones', 'Bo Li', 'Alexei A. Koulakov']", "abstract": "How can animals behave effectively in conditions involving different motivational contexts? Here, we propose how reinforcement learning neural networks can learn optimal behavior for dynamically changing motivational salience vectors. First, we show that Q-learning neural networks with motivation can navigate in environment with dynamic rewards. Second, we show that such networks can learn complex behaviors simultaneously directed towards several goals distributed in an environment. Finally, we show that in Pavlovian conditioning task, the responses of the neurons in our model resemble the firing patterns of neurons in the ventral pallidum (VP), a basal ganglia structure involved in motivated behaviors. We show that, similarly to real neurons, recurrent networks with motivation are composed of two oppositely-tuned classes of neurons, responding to positive and negative rewards. Our model generates predictions for the VP connectivity. We conclude that networks with motivation can rapidly adapt their behavior to varying conditions without changes in synaptic strength when expected reward is modulated by motivation. Such networks may also provide a mechanism for how hierarchical reinforcement learning is implemented in the brain.", "pdf": "/pdf/1fabdce118618555e3465ca67c4ea771bfe83d14.pdf", "keywords": "['neuroscience', 'brain', 'motivation', 'learning', 'reinforcement learning', 'recurrent neural network', 'deep learning']", "id": "BJlJVCEYDB"}, {"number": "2401", "title": "Closed loop deep Bayesian inversion:  Uncertainty driven acquisition for fast MRI", "authors": "['Thomas Sanchez', 'Igor Krawczuk', 'Zhaodong Sun', 'Volkan Cevher']", "abstract": "This work proposes a closed-loop, uncertainty-driven adaptive sampling frame- work (CLUDAS) for accelerating magnetic resonance imaging (MRI) via deep Bayesian inversion. By closed-loop, we mean that our samples adapt in real- time to the incoming data. To our knowledge, we demonstrate the first genera- tive adversarial network (GAN) based framework for posterior estimation over a continuum sampling rates of an inverse problem. We use this estimator to drive the sampling for accelerated MRI. Our numerical evidence demonstrates that the variance estimate strongly correlates with the expected MSE improvement for dif- ferent acceleration rates even with few posterior samples. Moreover, the resulting masks bring improvements to the state-of-the-art fixed and active mask designing approaches across MSE, posterior variance and SSIM on real undersampled MRI scans.", "pdf": "/pdf/f21d6310fc06d55d2ea6318a69930d33cb43723c.pdf", "keywords": "['Deep Bayesian Inversion', 'accelerated MRI', 'uncertainty quantification', 'sampling mask design']", "id": "BJlPOlBKDB"}, {"number": "512", "title": "Deep Network Classification by Scattering and Homotopy Dictionary Learning", "authors": "['John Zarka', 'Louis Thiry', 'Tomas Angles', 'Stephane Mallat']", "abstract": "We introduce a sparse scattering deep convolutional neural network, which provides a simple model to analyze properties of deep representation learning for classification. Learning a single dictionary matrix with a classifier yields a higher classification accuracy than AlexNet over the ImageNet 2012 dataset. The network first applies a scattering transform that linearizes variabilities due to geometric transformations such as translations and small deformations.\nA sparse $\\ell^1$ dictionary coding reduces intra-class variability while preserving class separation through projections over unions of linear spaces. It is implemented in a deep convolutional network with a homotopy algorithm having an exponential convergence. A convergence proof is given in a general framework that includes ALISTA. Classification results are analyzed on ImageNet.", "pdf": "/pdf/e6235a059a0929ea35206c487924a1f355bb8c7d.pdf", "keywords": "['dictionary learning', 'scattering transform', 'sparse coding', 'imagenet']", "id": "SJxWS64FwH"}, {"number": "1974", "title": "``'Best-of-Many-Samples' Distribution Matching", "authors": "['Apratim Bhattacharyya', 'Mario Fritz', 'Bernt Schiele']", "abstract": "Generative Adversarial Networks (GANs) can achieve state-of-the-art sample quality in generative modelling tasks but suffer from the mode collapse problem. Variational Autoencoders (VAE) on the other hand explicitly maximize a reconstruction-based data log-likelihood forcing it to cover all modes, but suffer from poorer sample quality. Recent works have proposed hybrid VAE-GAN frameworks which integrate a GAN-based synthetic likelihood to the VAE objective to address both the mode collapse and sample quality issues, with limited success. This is because the VAE objective forces a trade-off between the data log-likelihood and divergence to the latent prior. The synthetic likelihood ratio term also shows instability during training. We propose a novel objective with a ``'Best-of-Many-Samples' reconstruction cost and a stable direct estimate of the synthetic likelihood. This enables our hybrid VAE-GAN framework to achieve high data log-likelihood and low divergence to the latent prior at the same time and shows significant improvement over both hybrid VAE-GANS and plain GANs in mode coverage and quality.", "pdf": "/pdf/4bc3077bb44c606fda33ddd4f51c5f233ff7a032.pdf", "keywords": "['Distribution Matching', 'Generative Adversarial Networks', 'Variational Autoencoders']", "id": "S1lk61BtvB"}, {"number": "2246", "title": "Towards Certified Defense for Unrestricted Adversarial Attacks", "authors": "['Shengjia Zhao', 'Yang Song', 'Stefano Ermon']", "abstract": "Certified defenses against adversarial examples are very important in safety-critical applications of machine learning. However, existing certified defense strategies only safeguard against perturbation-based adversarial attacks, where the attacker is only allowed to modify normal data points by adding small perturbations. In this paper, we provide certified defenses under the more general threat model of unrestricted adversarial attacks. We allow the attacker to generate arbitrary inputs to fool the classifier, and assume the attacker knows everything except the classifiers' parameters and the training dataset used to learn it. Lack of knowledge about the classifiers parameters prevents an attacker from generating adversarial examples successfully. Our defense draws inspiration from differential privacy, and is based on intentionally adding noise to the classifier's outputs to limit the attacker's knowledge about the parameters. We prove concrete bounds on the minimum number of queries required for any attacker to generate a successful adversarial attack. For a simple linear classifiers we prove that the bound is asymptotically optimal up to a constant by exhibiting an attack algorithm that achieves this lower bound. We empirically show the success of our defense strategy against strong black box attack algorithms.", "pdf": "/pdf/fdd11f45bd1e780ba8741516809efa2109bf9cc1.pdf", "keywords": "['Adversarial Defense', 'Certified Defense', 'Adversarial Examples']", "id": "S1lBVgHYvr"}, {"number": "60", "title": "X-Forest: Approximate Random Projection Trees for Similarity Measurement", "authors": "['Yikai Zhao', 'Peiqing Chen', 'Zidong Zhao', 'Tong Yang', 'Jie Jiang', 'Bin Cui', 'Gong Zhang', 'Steve Uhlig']", "abstract": "Similarity measurement plays a central role in various data mining and machine learning tasks. Generally, a similarity measurement solution should, in an ideal state, possess the following three properties: accuracy, efficiency and independence from prior knowledge. Yet unfortunately, vital as similarity measurements are, no previous works have addressed all of them. In this paper, we propose X-Forest, consisting of a group of approximate Random Projection Trees, such that all three targets mentioned above are tackled simultaneously. Our key techniques are as follows. First, we introduced RP Trees into the tasks of similarity measurement such that accuracy is improved. In addition, we enforce certain layers in each tree to share identical projection vectors, such that exalted efficiency is achieved. Last but not least, we introduce randomness into partition to eliminate its reliance on prior knowledge.   We conduct experiments on three real-world datasets, whose results demonstrate that our model, X-Forest, reaches an efficiency of up to 3.5 times higher than RP Trees with negligible compromising on its accuracy, while also being able to outperform traditional Euclidean distance-based similarity metrics by as much as 20% with respect to clustering tasks.   We have released codes in github anonymously so as to meet the demand of reproducibility.", "pdf": "/pdf/2907d4f441292d83e15ff606e48318aef12db63a.pdf", "keywords": "[]", "id": "S1lAOhEKPS"}, {"number": "28", "title": "On the Decision Boundaries of Deep Neural Networks: A Tropical Geometry Perspective", "authors": "['Motasem Alfarra', 'Adel Bibi', 'Hasan Hammoud', 'Mohamed Gaafar', 'Bernard Ghanem']", "abstract": "This work tackles the problem of characterizing and understanding the decision boundaries of neural networks with piece-wise linear non-linearity activations. We use tropical geometry, a new development in the area of algebraic geometry, to provide a characterization of the decision boundaries of a simple neural network of the form (Affine, ReLU, Affine). Specifically, we show that the decision boundaries are a subset of a tropical hypersurface, which is intimately related to a polytope formed by the convex hull of two zonotopes. The generators of the zonotopes are precise functions of the neural network parameters. We utilize this geometric characterization to shed light and new perspective on three tasks. In doing so, we propose a new tropical perspective for the lottery ticket hypothesis, where we see the effect of different initializations on the tropical geometric representation of the decision boundaries. Also, we leverage this characterization as a new set of tropical regularizers, which  deal directly  with the decision boundaries of a network. We investigate the use of these regularizers  in neural network pruning (removing network parameters that do not contribute to the tropical geometric representation of the decision boundaries) and in generating adversarial input attacks (with input perturbations explicitly perturbing the decision boundaries geometry to change the network prediction of the input). ", "pdf": "/pdf/34a5dd2db7c3d59680cac9599213046e68e8f7c4.pdf", "keywords": "['Decision boundaries', 'Neural Network', 'Tropical Geometry', 'Network Pruning', 'Adversarial Attacks', 'Lottery Ticket Hypothesis']", "id": "BylldnNFwS"}, {"number": "2254", "title": "The Differentiable Cross-Entropy Method", "authors": "['Brandon Amos', 'Denis Yarats']", "abstract": "We study the Cross-Entropy Method (CEM) for the non-convex optimization of a continuous and parameterized objective function and introduce a differentiable variant (DCEM) that enables us to differentiate the output of CEM with respect to the objective function's parameters. In the machine learning setting this brings CEM inside of the end-to-end learning pipeline in cases this has otherwise been impossible. We show applications in a synthetic energy-based structured prediction task and in non-convex continuous control. In the control setting we show on the simulated cheetah and walker tasks that we can embed their optimal action sequences with DCEM and then use policy optimization to fine-tune components of the controller as a step towards combining model-based and model-free RL.", "pdf": "/pdf/797146043f1ef167cdf8a892ccd77bed492208d2.pdf", "keywords": "['machine learning', 'differentiable optimization', 'control', 'reinforcement learning']", "id": "HJluEeHKwH"}, {"number": "1156", "title": "A Base Model Selection Methodology for Efficient Fine-Tuning", "authors": "['Yosuke Ueno', 'Masaaki Kondo']", "abstract": "While the accuracy of image classification achieves significant improvement with deep Convolutional Neural Networks (CNN), training a deep CNN is a time-consuming task because it requires a large amount of labeled data and takes a long time to converge even with high performance computing resources.\nFine-tuning, one of the transfer learning methods, is effective in decreasing time and the amount of data necessary for CNN training. It is known that fine-tuning can be performed efficiently if the source and the target tasks have high relativity.\nHowever, the technique to evaluate the relativity or transferability of trained models quantitatively from their parameters has not been established. In this paper, we propose and evaluate several metrics to estimate the transferability of pre-trained CNN models for a given target task by featuremaps of the last convolutional layer.\nWe found that some of the proposed metrics are good predictors of fine-tuned accuracy, but their effectiveness depends on the structure of the network. Therefore, we also propose to combine two metrics to get a generally applicable indicator. \nThe experimental results reveal that one of the combined metrics is well correlated with fine-tuned accuracy in a variety of network structure and our method has a good potential to reduce the burden of CNN training.", "pdf": "/pdf/51b88569ba9c74fd4cf67b41220c53934418a521.pdf", "keywords": "['transfer learning', 'fine-tuning', 'parameter transfer']", "id": "BylT8RNKPH"}, {"number": "805", "title": "From English to Foreign Languages: Transferring Pre-trained Language Models", "authors": "['Ke Tran']", "abstract": "Pre-trained models have demonstrated their effectiveness in many downstream natural language processing (NLP) tasks. The availability of multilingual pre-trained models enables zero-shot transfer of NLP tasks from high resource languages to low resource ones. However, recent research in improving pre-trained models focuses heavily on English. While it is possible to train the latest neural architectures for other languages from scratch, it is undesirable due to the required amount of compute. In this work, we tackle the problem of transferring an existing pre-trained model from English to other languages under a limited computational budget. With a single GPU, our approach can obtain a foreign BERT-base model within a day and a foreign BERT-large within two days. Furthermore, evaluating our models on six languages, we demonstrate that our models are better than multilingual BERT on two zero-shot tasks: natural language inference and dependency parsing.", "pdf": "/pdf/e8d3036658a184a016b5b819a825f13c93e7c56f.pdf", "keywords": "['pretrained language model', 'zero-shot transfer', 'parsing', 'natural language inference']", "id": "Bkle6T4YvB"}, {"number": "1729", "title": "Meta-Learning by Hallucinating Useful Examples", "authors": "['Yu-Xiong Wang', 'Yuki Uchiyama', 'Martial Hebert', 'Karteek Alahari']", "abstract": "Learning to hallucinate additional examples has recently been shown as a promising direction to address few-shot learning tasks, which aim to learn novel concepts from very few examples. The hallucination process, however, is still far from generating effective samples for learning. In this work, we investigate two important requirements for the hallucinator --- (i) precision: the generated examples should lead to good classifier performance, and (ii) collaboration: both the hallucinator and the classification component need to be trained jointly. By integrating these requirements as novel loss functions into a general meta-learning with hallucination framework, our model-agnostic PrecisE Collaborative hAlluciNator (PECAN) facilitates data hallucination to improve the performance of new classification tasks. Extensive experiments demonstrate state-of-the-art performance on competitive miniImageNet and ImageNet based few-shot benchmarks in various scenarios.", "pdf": "/pdf/c5c53a6e6cefd1a495a582b3f2c1f7723d513b8b.pdf", "keywords": "['few-shot learning', 'meta-learning']", "id": "rJx8I1rFwr"}, {"number": "933", "title": "Learning Heuristics for Quantified Boolean Formulas through Reinforcement Learning", "authors": "['Gil Lederman', 'Markus Rabe', 'Sanjit Seshia', 'Edward A. Lee']", "abstract": "We demonstrate how to learn efficient heuristics for automated reasoning algorithms for quantified Boolean formulas through deep reinforcement learning. We focus on a backtracking search algorithm, which can already solve formulas of impressive size - up to hundreds of thousands of variables. The main challenge is to find a representation of these formulas that lends itself to making predictions in a scalable way. For a family of challenging problems, we learned a heuristic that solves significantly more formulas compared to the existing handwritten heuristics.", "pdf": "/pdf/e8010fd156b78b981729127692c4ba3543c87ab7.pdf", "keywords": "['Logic', 'QBF', 'Logical Reasoning', 'SAT', 'Graph', 'Reinforcement Learning', 'GNN']", "id": "BJluxREKDB"}, {"number": "2171", "title": "The Frechet Distance of training and test distribution predicts the generalization gap", "authors": "['Julian Zilly', 'Hannes Zilly', 'Oliver Richter', 'Roger Wattenhofer', 'Andrea Censi', 'Emilio Frazzoli']", "abstract": "Learning theory tells us that more data is better when minimizing the generalization error of identically distributed training and test sets. However, when training and test distribution differ, this distribution shift can have a significant effect. With a novel perspective on function transfer learning, we are able to lower bound the change of performance when transferring from training to test set with the Wasserstein distance between the embedded training and test set distribution. We find that there is a trade-off affecting performance between how invariant a function is to changes in training and test distribution and how large this shift in distribution is. Empirically across several data domains, we substantiate this viewpoint by showing that test performance correlates strongly with the distance in data distributions between training and test set. Complementary to the popular belief that more data is always better, our results highlight the utility of also choosing a training data distribution that is close to the test data distribution when the learned function is not invariant to such changes.", "pdf": "/pdf/09cc6c1edd3ef4dd318eee08de43fafed57765ef.pdf", "keywords": "['Generalization', 'Transfer learning', 'Frechet distance', 'Optimal transport', 'Domain adaptation', 'Distribution shift', 'Invariance']", "id": "SJgSflHKDr"}, {"number": "94", "title": "Unsupervised Learning of Node Embeddings by Detecting Communities", "authors": "['Chi Thang Duong', 'Dung Hoang', 'Truong Giang Le Ba', 'Thanh Le Cong', 'Hongzhi Yin', 'Matthias Weidlich', 'Quoc Viet Hung Nguyen', 'Karl Aberer']", "abstract": "We present Deep MinCut (DMC), an unsupervised approach to learn node embeddings for graph-structured data. It derives node representations based on their membership in communities. As such, the embeddings directly provide interesting insights into the graph structure, so that the separate node clustering step of existing methods is no longer needed. DMC learns both, node embeddings and communities, simultaneously by minimizing the mincut loss, which captures the number of connections between communities. Striving for high scalability, we also propose a training process for DMC based on minibatches. We provide empirical evidence that the communities learned by DMC are meaningful and that the node embeddings are competitive in different node classification benchmarks.", "pdf": "/pdf/0d016dc74c3f07ca2df564481b337ea353d6265f.pdf", "keywords": "['Unsupervised Learning', 'Graph Embedding', 'Community Detection', 'Mincut', 'Normalized cut', 'Deep Learning']", "id": "Byl3K2VtwB"}, {"number": "1523", "title": "Emergent Tool Use From Multi-Agent Autocurricula", "authors": "['Bowen Baker', 'Ingmar Kanitscheider', 'Todor Markov', 'Yi Wu', 'Glenn Powell', 'Bob McGrew', 'Igor Mordatch']", "abstract": "Through multi-agent competition, the simple objective of hide-and-seek, and standard reinforcement learning algorithms at scale, we find that agents create a self-supervised autocurriculum inducing multiple distinct rounds of emergent strategy, many of which require sophisticated tool use and coordination. We find clear evidence of six emergent phases in agent strategy in our environment, each of which creates a new pressure for the opposing team to adapt; for instance, agents learn to build multi-object shelters using moveable boxes which in turn leads to agents discovering that they can overcome obstacles using ramps. We further provide evidence that multi-agent competition may scale better with increasing environment complexity and leads to behavior that centers around far more human-relevant skills than other self-supervised reinforcement learning methods such as intrinsic motivation. Finally, we propose transfer and fine-tuning as a way to quantitatively evaluate targeted capabilities, and we compare hide-and-seek agents to both intrinsic motivation and random initialization baselines in a suite of domain-specific intelligence tests.", "pdf": "/pdf/9296b021ee5071e8a5433b6255270e0e20d8f532.pdf", "keywords": "[]", "id": "SkxpxJBKwS"}, {"number": "810", "title": "GENESIS: Generative Scene Inference and Sampling with Object-Centric Latent Representations", "authors": "['Martin Engelcke', 'Adam R. Kosiorek', 'Oiwi Parker Jones', 'Ingmar Posner']", "abstract": "Generative latent-variable models are emerging as promising tools in robotics and reinforcement learning. Yet, even though tasks in these domains typically involve distinct objects, most state-of-the-art generative models do not explicitly capture the compositional nature of visual scenes. Two recent exceptions, MONet and IODINE, decompose scenes into objects in an unsupervised fashion. Their underlying generative processes, however, do not account for component interactions. Hence, neither of them allows for principled sampling of novel scenes. Here we present GENESIS, the first  object-centric generative model of 3D visual scenes capable of both decomposing and generating scenes by capturing relationships between scene components. GENESIS parameterises a spatial GMM over images which is decoded from a set of object-centric latent variables that are either inferred sequentially in an amortised fashion or sampled from an autoregressive prior. We train GENESIS on several publicly available datasets and evaluate its performance on scene generation, decomposition, and semi-supervised learning.", "pdf": "/pdf/fd0ce812b32b925e134e0c6c2244f5d5ff8d711c.pdf", "keywords": "['Generative modelling', 'object-centric representations', 'scene generation', 'variational inference']", "id": "BkxfaTVFwH"}, {"number": "2544", "title": "Conditional generation of molecules from disentangled representations", "authors": "['Amina Mollaysa', 'Brooks Paige', 'Alexandros  Kalousis']", "abstract": "Though machine learning approaches have shown great success in estimating properties of small molecules, the inverse problem of generating molecules with desired properties remains challenging. This difficulty is in part because the set of molecules which have a given property is structurally very diverse. Treating this inverse problem as a conditional distribution estimation task, we draw upon work in learning disentangled representations to learn a conditional distribution over molecules given a desired property, where the molecular structure is encoded in a continuous latent random variable. By including property information as an input factor independent from the structure representation, one can perform conditional molecule generation via a ``style transfer'' process, in which we explicitly set the property to a desired value at generation time. In contrast to existing approaches, we disentangle the latent factors from the property factors using a regularization term which constrains the generated molecules to have the property provided to the  generation network, no matter how the latent factor changes.", "pdf": "/pdf/5d7bc200c3e279b46ae12c6638d90bb8c43fc801.pdf", "keywords": "['molecule generation', 'disentangling']", "id": "BkxthxHYvr"}, {"number": "2344", "title": "Collaborative Training of Balanced Random Forests for Open Set Domain Adaptation", "authors": "['Jongbin Ryu', 'Jiun Bae', 'Jongwoo Lim']", "abstract": "In this paper, we introduce a collaborative training algorithm of balanced random forests for domain adaptation tasks which can avoid the overfitting problem. In real scenarios, most domain adaptation algorithms face the challenges from noisy, insufficient training data. Moreover in open set categorization, unknown or misaligned source and target categories adds difficulty. In such cases, conventional methods suffer from overfitting and fail to successfully transfer the knowledge of the source to the target domain. To address these issues, the following two techniques are proposed. First, we introduce the optimized decision tree construction method, in which the data at each node are split into equal sizes while maximizing the information gain. Compared to the conventional random forests, it generates larger and more balanced decision trees due to the even-split constraint, which contributes to enhanced discrimination power and reduced overfitting. Second, to tackle the domain misalignment problem, we propose the domain alignment loss which penalizes uneven splits of the source and target domain data. By collaboratively optimizing the information gain of the labeled source data as well as the entropy of unlabeled target data distributions, the proposed CoBRF algorithm achieves significantly better performance than the state-of-the-art methods. The proposed algorithm is extensively evaluated in various experimental setups in challenging domain adaptation tasks with noisy and small training data as well as open set domain adaptation problems, for two backbone networks of AlexNet and ResNet-50.", "pdf": "/pdf/0b9cfb123ef467704ea8381ee6539b391ba14028.pdf", "keywords": "[]", "id": "SkeJPertPS"}, {"number": "795", "title": "Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection", "authors": "['Michael Tsang', 'Dehua Cheng', 'Hanpeng Liu', 'Xue Feng', 'Eric Zhou', 'Yan Liu']", "abstract": "Recommendation is a prevalent application of machine learning that affects many users; therefore, it is important for recommender models to be accurate and interpretable. In this work, we propose a method to both interpret and augment the predictions of black-box recommender systems. In particular, we propose to interpret feature interactions from a source recommender model and explicitly encode these interactions in a target recommender model, where both source and target models are black-boxes. By not assuming the structure of the recommender system, our approach can be used in general settings. In our experiments, we focus on a prominent use of machine learning recommendation: ad-click prediction. We found that our interaction interpretations are both informative and predictive, e.g., significantly outperforming existing recommender models. What's more, the same approach to interpret interactions can provide new insights into domains even beyond recommendation, such as text and image classification.", "pdf": "/pdf/92ef1a91a48f542fa2a673a944c268a080d1745a.pdf", "keywords": "['Feature Interaction', 'Interpretability', 'Black Box', 'AutoML']", "id": "BkgnhTEtDS"}, {"number": "1034", "title": "Deep Imitative Models for Flexible Inference, Planning, and Control", "authors": "['Nicholas Rhinehart', 'Rowan McAllister', 'Sergey Levine']", "abstract": "Imitation Learning (IL) is an appealing approach to learn desirable autonomous behavior. However, directing IL to achieve arbitrary goals is difficult. In contrast, planning-based algorithms use dynamics models and reward functions to achieve goals. Yet, reward functions that evoke desirable behavior are often difficult to specify. In this paper, we propose 'Imitative Models' to combine the benefits of IL and goal-directed planning. Imitative Models are probabilistic predictive models of desirable behavior able to plan interpretable expert-like trajectories to achieve specified goals. We derive families of flexible goal objectives, including constrained goal regions, unconstrained goal sets, and energy-based goals. We show that our method can use these objectives to successfully direct behavior. Our method substantially outperforms six IL approaches and a planning-based approach in a dynamic simulated autonomous driving task, and is efficiently learned from expert demonstrations without online data collection.  We also show our approach is robust to poorly-specified goals, such as goals on the wrong side of the road.", "pdf": "/pdf/a0ea230e9b98f012c909e5d99c6ccf04797d5447.pdf", "keywords": "['imitation learning', 'planning', 'autonomous driving']", "id": "Skl4mRNYDr"}, {"number": "597", "title": "Gap-Aware Mitigation of Gradient Staleness", "authors": "['Saar Barkai', 'Ido Hakimi', 'Assaf Schuster']", "abstract": "Cloud computing is becoming increasingly popular as a platform for distributed training of deep neural networks. Synchronous stochastic gradient descent (SSGD) suffers from substantial slowdowns due to stragglers if the environment is non-dedicated, as is common in cloud computing. Asynchronous SGD (ASGD) methods are immune to these slowdowns but are scarcely used due to gradient staleness, which encumbers the convergence process. Recent techniques have had limited success mitigating the gradient staleness when scaling up to many workers (computing nodes).  In this paper we define the Gap as a measure of gradient staleness and propose Gap-Aware (GA), a novel asynchronous-distributed method that penalizes stale gradients linearly to the Gap and performs well even when scaling to large numbers of workers. Our evaluation on the CIFAR, ImageNet, and WikiText-103 datasets shows that GA outperforms the currently acceptable gradient penalization method, in final test accuracy. We also provide convergence rate proof for GA. Despite prior beliefs, we show that if GA is applied, momentum becomes beneficial in asynchronous environments, even when the number of workers scales up.", "pdf": "/pdf/55a4070120074571a7669811775bfb58717bc1ed.pdf", "keywords": "['distributed', 'asynchronous', 'large scale', 'gradient staleness', 'staleness penalization', 'sgd', 'deep learning', 'neural networks', 'optimization']", "id": "B1lLw6EYwB"}, {"number": "1864", "title": "Learning robust visual representations using data augmentation invariance", "authors": "['Alex Hernandez-Garcia', 'Peter K\u00f6nig', 'Tim C. Kietzmann']", "abstract": "Deep convolutional neural networks trained for image object categorization have shown remarkable similarities with representations found across the primate ventral visual stream. Yet, artificial and biological networks still exhibit important differences. Here we investigate one such property: increasing invariance to identity-preserving image transformations found along the ventral stream. Despite theoretical evidence that invariance should emerge naturally from the optimization process, we present empirical evidence that the activations of convolutional neural networks trained for object categorization are not robust to identity-preserving image transformations commonly used in data augmentation. As a solution, we propose data augmentation invariance, an unsupervised learning objective which improves the robustness of the learned representations by promoting the similarity between the activations of augmented image samples. Our results show that this approach is a simple, yet effective and efficient (10 % increase in training time) way of increasing the invariance of the models while obtaining similar categorization performance.", "pdf": "/pdf/c3452f12152bf0d39742b0342098a86cec0757b3.pdf", "keywords": "['deep neural networks', 'visual cortex', 'invariance', 'data augmentation']", "id": "B1elqkrKPH"}, {"number": "1432", "title": "Uncertainty-guided Continual Learning with Bayesian Neural Networks", "authors": "['Sayna Ebrahimi', 'Mohamed Elhoseiny', 'Trevor Darrell', 'Marcus Rohrbach']", "abstract": "Continual learning aims to learn new tasks without forgetting previously learned ones. This is especially challenging when one cannot access data from previous tasks and when the model has a fixed capacity. Current regularization-based continual learning algorithms  need an external representation and extra computation to measure the parameters' \\textit{importance}. In contrast, we propose Uncertainty-guided Continual Bayesian Neural Networks (UCB), where the learning rate adapts according to the uncertainty defined in the probability distribution of the weights in  networks. Uncertainty is a natural way to identify \\textit{what to remember} and \\textit{what to change} as we continually learn,  and thus mitigate catastrophic forgetting. We also show a variant of our model, which uses uncertainty for weight pruning \nand retains task performance after pruning by saving binary masks per tasks. We evaluate our UCB approach extensively on diverse object classification datasets with short and long sequences of tasks and report superior or on-par performance compared to existing approaches. Additionally, we show that our model does not necessarily need task information at test time, i.e. it does not presume knowledge of which task a sample belongs to.", "pdf": "/pdf/8ccdcfeb98a76b5cd86b24aac86dad75b579af1a.pdf", "keywords": "['continual learning', 'catastrophic forgetting']", "id": "HklUCCVKDB"}, {"number": "2427", "title": "Learning to Move with Affordance Maps", "authors": "['William Qi', 'Ravi Teja Mullapudi', 'Saurabh Gupta', 'Deva Ramanan']", "abstract": "The ability to autonomously explore and navigate a physical space is a fundamental requirement for virtually any mobile autonomous agent, from household robotic vacuums to autonomous vehicles. Traditional SLAM-based approaches for exploration and navigation largely focus on leveraging scene geometry, but fail to model dynamic objects (such as other agents) or semantic constraints (such as wet floors or doorways). Learning-based RL agents are an attractive alternative because they can incorporate both semantic and geometric information, but are notoriously sample inefficient, difficult to generalize to novel settings, and are difficult to interpret. In this paper, we combine the best of both worlds with a modular approach that {\\em learns} a spatial representation of a scene that is trained to be effective when coupled with traditional geometric planners. Specifically, we design an agent that learns to predict a spatial affordance map that elucidates what parts of a scene are navigable through active self-supervised experience gathering. In contrast to most simulation environments that assume a static world, we evaluate our approach in the VizDoom simulator, using large-scale randomly-generated maps containing a variety of dynamic actors and hazards. We show that learned affordance maps can be used to augment traditional approaches for both exploration and navigation, providing significant improvements in performance.", "pdf": "/pdf/ce58284ea0813c14cf1c563bf0fbefe6a736158b.pdf", "keywords": "['navigation', 'exploration']", "id": "BJgMFxrYPB"}, {"number": "31", "title": "Accelerated Information Gradient flow", "authors": "['Yifei Wang', 'Wuchen Li']", "abstract": "We present a systematic framework for the Nesterov's accelerated gradient flows in the spaces of probabilities embedded with information metrics. Here two metrics are considered, including both the Fisher-Rao metric and the Wasserstein-$2$ metric. For the Wasserstein-$2$ metric case, we prove the convergence properties of the accelerated gradient flows, and introduce their formulations in Gaussian families. Furthermore, we propose a practical discrete-time algorithm in particle implementations with an adaptive restart technique.  We formulate a novel bandwidth selection method, which learns the Wasserstein-$2$ gradient direction from Brownian-motion samples. Experimental results including Bayesian inference show the strength of the current method compared with the state-of-the-art.", "pdf": "/pdf/8898485c7f9f40f0bfe944c6ce3cd9bb7e2e034b.pdf", "keywords": "['Optimal transport', 'Information geometry', 'Nesterov accelerated gradient method']", "id": "BJe-unNYPr"}, {"number": "1420", "title": "Cross-lingual Alignment vs Joint Training: A Comparative Study and A Simple Unified Framework", "authors": "['Zirui Wang*', 'Jiateng Xie*', 'Ruochen Xu', 'Yiming Yang', 'Graham Neubig', 'Jaime G. Carbonell']", "abstract": "Learning multilingual representations of text has proven a successful method for many cross-lingual transfer learning tasks. There are two main paradigms for learning such representations: (1) alignment, which maps different independently trained monolingual representations into a shared space, and (2) joint training, which directly learns unified multilingual representations using monolingual and cross-lingual objectives jointly. In this paper, we first conduct direct comparisons of representations learned using both of these methods across diverse cross-lingual tasks. Our empirical results reveal a set of pros and cons for both methods, and show that the relative performance of alignment versus joint training is task-dependent. Stemming from this analysis, we propose a simple and novel framework that combines these two previously mutually-exclusive approaches. Extensive experiments demonstrate that our proposed framework alleviates limitations of both approaches, and outperforms existing methods on the MUSE bilingual lexicon induction (BLI) benchmark. We further show that this framework can generalize to contextualized representations such as Multilingual BERT, and produces state-of-the-art results on the CoNLL cross-lingual NER benchmark.", "pdf": "/pdf/74382652cfb47255e102a6e4b626e03a9271ff30.pdf", "keywords": "['Cross-lingual Representation']", "id": "S1l-C0NtwS"}, {"number": "207", "title": "An Empirical Study on Post-processing Methods for Word Embeddings", "authors": "['Shuai Tang', 'Mahta Mousavi', 'Virginia R. de Sa']", "abstract": "Word embeddings learnt from large corpora have been adopted in various applications in natural language processing and served as the general input representations to learning systems. Recently, a series of post-processing methods have been proposed to boost the performance of word embeddings on similarity comparison and analogy retrieval tasks, and some have been adapted to compose sentence representations. The general hypothesis behind these methods is that by enforcing the embedding space to be more isotropic, the similarity between words can be better expressed. We view these methods as an approach to shrink the covariance/gram matrix, which is estimated by learning word vectors, towards a scaled identity matrix. By optimising an objective in the semi-Riemannian manifold with Centralised Kernel Alignment (CKA), we are able to search for the optimal shrinkage parameter, and provide a post-processing method to smooth the spectrum of learnt word vectors which yields improved performance on downstream tasks.", "pdf": "/pdf/7baab4cf3bf0310a1bab41fb8913383ded82a097.pdf", "keywords": "['word vectors', 'post-processing method', 'centralised kernel alignment', 'shrinkage']", "id": "Byla224KPr"}, {"number": "1868", "title": "Spectral Nonlocal Block for Neural Network", "authors": "['Lei Zhu', 'Qi She', 'Lidan Zhang', 'Ping guo']", "abstract": "The nonlocal network is designed for capturing long-range spatial-temporal dependencies in several computer vision tasks. Although having shown excellent performances, it needs an elaborate preparation for both the number and position of the building blocks. In this paper, we propose a new formulation of the nonlocal block and interpret it from the general graph signal processing perspective, where we view it as a fully-connected graph filter approximated by Chebyshev polynomials. The proposed nonlocal block is more efficient and robust, which is a generalized form of existing nonlocal blocks (e.g. nonlocal block, nonlocal stage). Moreover, we give the stable hypothesis and show that the steady-state of the deeper nonlocal structure should meet with it. Based on the stable hypothesis,  a full-order approximation of the nonlocal block is derived for consecutive connections. Experimental results illustrate the clear-cut improvement and practical applicability of the generalized nonlocal block on both image and video classification tasks.", "pdf": "/pdf/a81df1eeb55212939c043c14bab928bb9f0b8aca.pdf", "keywords": "['Nonlocal Neural Network', 'Image Classification', 'Action Recgonition']", "id": "rkgb9kSKwS"}, {"number": "324", "title": "Towards Understanding the Regularization of Adversarial Robustness on Neural Networks", "authors": "['Yuxin Wen', 'Shuai Li', 'Kui Jia']", "abstract": "  The problem of adversarial examples has shown that modern Neural Network (NN) models could be rather fragile. Among the most promising techniques to solve the problem, one is to require the model to be {\\it $\\epsilon$-adversarially robust} (AR); that is, to require the model not to change predicted labels when any given input examples are perturbed within a certain range. However, it is widely observed that such methods would lead to standard performance degradation, i.e., the degradation on natural examples.  In this work, we study the degradation through the regularization perspective.  We identify quantities from generalization analysis of NNs; with the identified quantities we empirically find that AR is achieved by regularizing/biasing NNs towards less confident solutions by making the changes in the feature space (induced by changes in the instance space) of most layers smoother uniformly in all directions; so to a certain extent, it prevents sudden change in prediction w.r.t.  perturbations. However, the end result of such smoothing concentrates samples around decision boundaries, resulting in less confident solutions, and leads to worse standard performance.  Our studies suggest that one might consider ways that build AR into NNs in a gentler way to avoid the problematic regularization.\n", "pdf": "/pdf/5109cf6af39021a094ead15a16ac9d8e3172da47.pdf", "keywords": "['Adversarial robustness', 'Statistical Learning', 'Regularization']", "id": "BJlkgaNKvr"}, {"number": "300", "title": "Learning Disentangled Representations for CounterFactual Regression", "authors": "['Negar Hassanpour', 'Russell Greiner']", "abstract": "We consider the challenge of estimating treatment effects from observational data; and point out that, in general, only some factors based on the observed covariates X contribute to selection of the treatment T, and only some to determining the outcomes Y. We model this by considering three underlying sources of {X, T, Y} and show that explicitly modeling these sources offers great insight to guide designing models that better handle selection bias. This paper is an attempt to conceptualize this line of thought and provide a path to explore it further.\nIn this work, we propose an algorithm to (1) identify disentangled representations of the above-mentioned underlying factors from any given observational dataset D and (2) leverage this knowledge to reduce, as well as account for, the negative impact of selection bias on estimating the treatment effects from D. Our empirical results show that the proposed method achieves state-of-the-art performance in both individual and population based evaluation measures.", "pdf": "/pdf/54d0a6652b7bda521ab2dacf16831ec895f095b2.pdf", "keywords": "['Counterfactual Regression', 'Causal Effect Estimation', 'Selection Bias', 'Off-policy Learning']", "id": "HkxBJT4YvB"}, {"number": "1384", "title": "A closer look at network resolution for efficient network design", "authors": "['Taojiannan Yang', 'Sijie Zhu', 'Yan Shen', 'Mi Zhang', 'Andrew Willis', 'Chen Chen']", "abstract": "There is growing interest in designing lightweight neural networks for mobile and embedded vision applications. Previous works typically reduce computations from the structure level. For example, group convolution based methods reduce computations by factorizing a vanilla convolution into depth-wise and point-wise convolutions. Pruning based methods prune redundant connections in the network structure. In this paper, we explore the importance of network input for achieving optimal accuracy-efficiency trade-off. Reducing input scale is a simple yet effective way to reduce computational cost. It does not require careful network module design, specific hardware optimization and network retraining after pruning. Moreover, different input scales contain different representations to learn. We propose a framework to mutually learn from different input resolutions and network widths. With the shared knowledge, our framework is able to find better width-resolution balance and capture multi-scale representations. It achieves consistently better ImageNet top-1 accuracy over US-Net under different computation constraints, and outperforms the best compound scale model of EfficientNet by 1.5%. The superiority of our framework is also validated on COCO object detection and instance segmentation as well as transfer learning.", "pdf": "/pdf/1e1e44bba4a2d87611044de048cc6745a58af38e.pdf", "keywords": "['deep learning', 'computer vision', 'efficient network design', 'dynamic neural networks']", "id": "H1x-pANtDB"}, {"number": "2033", "title": "Gradient $\\ell_1$ Regularization for Quantization Robustness", "authors": "['Milad Alizadeh', 'Arash Behboodi', 'Mart van Baalen', 'Christos Louizos', 'Tijmen Blankevoort', 'Max Welling']", "abstract": "We analyze the effect of quantizing weights and activations of neural networks on their loss and derive a simple regularization scheme that improves robustness against post-training quantization. By training quantization-ready networks, our approach enables storing a single set of weights that can be quantized on-demand to different bit-widths as energy and memory requirements of the application change. Unlike quantization-aware training using the straight-through estimator that only targets a specific bit-width and requires access to training data and pipeline, our regularization-based method paves the way for ``on the fly'' post-training quantization to various bit-widths. We show that by modeling quantization as a $\\ell_\\infty$-bounded perturbation, the first-order term in the loss expansion can be regularized using the $\\ell_1$-norm of gradients. We experimentally validate our method on different vision architectures on CIFAR-10 and ImageNet datasets and show that the regularization of a neural network using our method improves robustness against quantization noise.", "pdf": "/pdf/d03bbe7b1da14a73044d4c4c991c83cdb3d7929e.pdf", "keywords": "['quantization', 'regularization', 'robustness', 'gradient regularization']", "id": "ryxK0JBtPr"}, {"number": "631", "title": "Robust Domain Randomization for Reinforcement Learning", "authors": "['Reda Bahi Slaoui', 'William R. Clements', 'Jakob N. Foerster', 'S\u00e9bastien Toth']", "abstract": "Producing agents that can generalize to a wide range of environments is a significant challenge in reinforcement learning. One method for overcoming this issue is domain randomization, whereby at the start of each training episode some parameters of the environment are randomized so that the agent is exposed to many possible variations. However, domain randomization is highly inefficient and may lead to policies with high variance across domains. In this work, we formalize the domain randomization problem, and show that minimizing the policy's Lipschitz constant with respect to the randomization parameters leads to low variance in the learned policies. We propose a method where the agent only needs to be trained on one variation of the environment, and its learned state representations are regularized during training to minimize this constant. We conduct experiments that demonstrate that our technique leads to more efficient and robust learning than standard domain randomization, while achieving equal generalization scores.", "pdf": "/pdf/d5a9e9284b336861ff1800009177422806e03741.pdf", "keywords": "['reinforcement learning', 'domain randomization', 'domain adaptation']", "id": "H1xSOTVtvH"}, {"number": "662", "title": "Adversarially Robust Representations with Smooth Encoders", "authors": "['Taylan Cemgil', 'Sumedh Ghaisas', 'Krishnamurthy (Dj) Dvijotham', 'Pushmeet Kohli']", "abstract": "This paper studies the undesired phenomena of over-sensitivity of representations learned by deep networks to semantically-irrelevant changes in data. We identify a cause for this shortcoming in the classical Variational Auto-encoder (VAE) objective, the evidence lower bound (ELBO). We show that the ELBO fails to control the behaviour of the encoder out of the support of the empirical data distribution and this behaviour of the VAE can lead to extreme errors in the learned representation. This is a key hurdle in the effective use of representations for data-efficient learning and transfer. To address this problem, we propose to augment the data with specifications that enforce insensitivity of the representation with respect to families of transformations. To incorporate these specifications, we propose a regularization method that is based on a selection mechanism that creates a fictive data point by explicitly perturbing an observed true data point. For certain choices of parameters, our formulation naturally leads to the minimization of the entropy regularized Wasserstein distance between representations. We illustrate our approach on standard datasets and experimentally show that significant improvements in the downstream adversarial accuracy can be achieved by learning robust representations completely in an unsupervised manner, without a reference to a particular downstream task and without a costly supervised adversarial training procedure. \n", "pdf": "/pdf/028b6b32416c54e7f696c014e41d55866a6752a6.pdf", "keywords": "['Adversarial Learning', 'Robust Representations', 'Variational AutoEncoder', 'Wasserstein Distance', 'Variational Inference']", "id": "H1gfFaEYDS"}, {"number": "510", "title": "Continuous Adaptation in Multi-agent Competitive Environments", "authors": "['Kuei-Tso Lee', 'Sheng-Jyh Wang']", "abstract": "In a multi-agent competitive environment, we would expect an agent who can quickly adapt to environmental changes may have a higher probability to survive and beat other agents. In this paper, to discuss whether the adaptation capability can help a learning agent to improve its competitiveness in a multi-agent environment, we construct a simplified baseball game scenario to develop and evaluate the adaptation capability of learning agents. Our baseball game scenario is modeled as a two-player zero-sum stochastic game with only the final reward. We purpose a modified Deep CFR algorithm to learn a strategy that approximates the Nash equilibrium strategy. We also form several teams, with different teams adopting different playing strategies, trying to analyze (1) whether an adaptation mechanism can help in increasing the winning percentage and (2) what kind of initial strategies can help a team to get a higher winning percentage. The experimental results show that the learned Nash-equilibrium strategy is very similar to real-life baseball game strategy. Besides, with the proposed strategy adaptation mechanism, the winning percentage can be increased for the team with a Nash-equilibrium initial strategy. Nevertheless, based on the same adaptation mechanism, those teams with deterministic initial strategies actually become less competitive.", "pdf": "/pdf/f52ea026c6f2d702c23348c0554562bc545a59a2.pdf", "keywords": "['multi-agent environment', 'continuous adaptation', 'Nash equilibrium', 'deep counterfactual regret minimization', 'reinforcement learning', 'stochastic game', 'baseball']", "id": "BkllBpEKDH"}, {"number": "2195", "title": "Disentangling Trainability and Generalization in Deep Learning", "authors": "['Lechao Xiao', 'Jeffrey Pennington', 'Sam Schoenholz']", "abstract": "A fundamental goal in deep learning is the characterization of trainability and generalization of neural networks as a function of their architecture and hyperparameters. In this paper, we discuss these challenging issues in the context of wide neural networks at large depths where we will see that the situation simplifies considerably. To do this, we leverage recent advances that have separately shown: (1) that in the wide network limit, random networks before training are Gaussian Processes governed by a kernel known as the Neural Network Gaussian Process (NNGP) kernel, (2) that at large depths the spectrum of the NNGP kernel simplifies considerably and becomes ``weakly data-dependent'', and (3) that gradient descent training of wide neural networks is described by a kernel called the Neural Tangent Kernel (NTK) that is related to the NNGP. Here we show that by combining the in the large depth limit the spectrum of the NTK simplifies in much the same way as that of the NNGP kernel. By analyzing this spectrum, we arrive at a precise characterization of trainability and generalization across a range of architectures including Fully Connected Networks (FCNs) and Convolutional Neural Networks (CNNs). We find that there are large regions of hyperparameter space where networks will train but will fail to generalize, in contrast with several recent results. By comparing CNNs with- and without-global average pooling, we show that CNNs without average pooling have very nearly identical learning dynamics to FCNs while CNNs with pooling contain a correction that alters its generalization performance. We perform a thorough empirical investigation of these theoretical results and finding excellent agreement on real datasets.", "pdf": "/pdf/0b050b4d3abc9c7e35c427bb9dc5989d85eea855.pdf", "keywords": "['NTK', 'NNGP', 'mean field theory', 'CNN', 'trainability and generalization', 'Gaussian process']", "id": "Bkx1mxSKvB"}, {"number": "569", "title": "Compressive Recovery Defense: A Defense Framework for $\\ell_0, \\ell_2$ and $\\ell_\\infty$ norm attacks.", "authors": "['Jasjeet Dhaliwal', 'Kyle Hambrook']", "abstract": "We provide recovery guarantees for compressible signals that have been corrupted with noise and extend the framework introduced in \\cite{bafna2018thwarting} to defend neural networks against $\\ell_0$, $\\ell_2$, and $\\ell_{\\infty}$-norm attacks. In the case of $\\ell_0$-norm noise, we provide recovery guarantees for Iterative Hard Thresholding (IHT) and Basis Pursuit (BP). For $\\ell_2$-norm bounded noise, we provide recovery guarantees for BP, and for the case of $\\ell_\\infty$-norm bounded noise, we provide recovery guarantees for Dantzig Selector (DS). These guarantees theoretically bolster the defense framework introduced in \\cite{bafna2018thwarting} for defending neural networks against adversarial inputs. Finally, we experimentally demonstrate the effectiveness of this defense framework against an array of $\\ell_0$, $\\ell_2$ and $\\ell_\\infty$-norm attacks.   ", "pdf": "/pdf/4afdb3539972a76c50b7e3195242e6e87bcfa928.pdf", "keywords": "['adversarial input', 'adversarial machine learning', 'neural networks', 'compressive sensing.']", "id": "B1x9ITVYDr"}, {"number": "1076", "title": "Generalized Clustering by Learning to Optimize Expected Normalized Cuts", "authors": "['Azade Nazi', 'Will Hang', 'Anna Goldie', 'Sujith Ravi', 'Azalia Mirhoseini']", "abstract": "We introduce a novel end-to-end approach for learning to cluster in the absence of labeled examples. Our clustering objective is based on optimizing normalized cuts, a criterion which measures both intra-cluster similarity as well as inter-cluster dissimilarity. We define a differentiable loss function equivalent to the expected normalized cuts. Unlike much of the work in unsupervised deep learning, our trained model directly outputs final cluster assignments, rather than embeddings that need further processing to be usable. Our approach generalizes to unseen datasets across a wide variety of domains, including text, and image. Specifically, we achieve state-of-the-art results on popular unsupervised clustering benchmarks (e.g., MNIST, Reuters, CIFAR-10, and CIFAR-100), outperforming the strongest baselines by up to 10.9%. Our generalization results are superior (by up to 21.9%) to the recent top-performing clustering approach with the ability to generalize.", "pdf": "/pdf/1e742261bdc1e2f57bdca799882d60dd30a1fbf7.pdf", "keywords": "['Clustering', 'Normalized cuts', 'Generalizability']", "id": "BklLVAEKvH"}, {"number": "698", "title": "Multi-Task Learning via Scale Aware Feature Pyramid Networks and Effective Joint Head", "authors": "['Feng Ni']", "abstract": "As a concise and classic framework for object detection and instance segmentation, Mask R-CNN achieves promising performance in both two tasks. However, considering stronger feature representation for Mask R-CNN fashion framework, there is room for improvement from two aspects. On the one hand, performing multi-task prediction needs more credible feature extraction and multi-scale features integration to handle objects with varied scales. In this paper, we address this problem by using a novel neck module called SA-FPN (Scale Aware Feature Pyramid Networks). With the enhanced feature representations, our model can accurately detect and segment the objects of multiple scales. On the other hand, in Mask R-CNN framework, isolation between parallel detection branch and instance segmentation branch exists, causing the gap between training and testing processes. To narrow this gap, we propose a unified head module named EJ-Head (Effective Joint Head) to combine two branches into one head, not only realizing the interaction between two tasks, but also enhancing the effectiveness of multi-task learning. Comprehensive experiments show that our proposed methods bring noticeable gains for object detection and instance segmentation. In particular, our model outperforms the original Mask R-CNN by 1~2 percent AP in both object detection and instance segmentation task on MS-COCO benchmark. Code will be available soon.", "pdf": "/pdf/63b8b7be773d30672c2843506aecc167fa3fac5b.pdf", "keywords": "['Multi-Task Learning', 'Object Detection', 'Instance Segmentation']", "id": "r1ezqaEFPr"}, {"number": "2193", "title": "Functional Regularisation for  Continual Learning with Gaussian Processes", "authors": "['Michalis K. Titsias', 'Jonathan Schwarz', 'Alexander G. de G. Matthews', 'Razvan Pascanu', 'Yee Whye Teh']", "abstract": "We introduce a framework for Continual Learning (CL) based on Bayesian inference over the function space rather than the parameters of a deep neural network. This method, referred to as functional regularisation for Continual Learning, avoids forgetting a previous task by constructing and memorising an approximate posterior belief over the underlying task-specific function. To achieve this we rely on a Gaussian process obtained by treating the weights of the last layer of a neural network as random and Gaussian distributed. Then, the training algorithm sequentially encounters tasks and constructs posterior beliefs over the task-specific functions by using inducing point sparse Gaussian process methods. At each step a new task is first learnt and then a summary is constructed consisting of (i) inducing inputs  a fixed-size subset of the task inputs selected such that it optimally represents the task  and (ii) a posterior distribution over the function values at these inputs. This summary then regularises learning of future tasks, through Kullback-Leibler regularisation terms. Our method thus unites approaches focused on (pseudo-)rehearsal with those derived from a sequential Bayesian inference perspective in a principled way, leading to strong results on accepted benchmarks.", "pdf": "/pdf/71078be0f0f1886bbfc8f485c61b5fd434452161.pdf", "keywords": "['Continual Learning', 'Gaussian Processes', 'Lifelong learning', 'Incremental Learning']", "id": "HkxCzeHFDB"}, {"number": "820", "title": "Estimating counterfactual treatment outcomes over time through adversarially balanced representations", "authors": "['Ioana Bica', 'Ahmed M Alaa', 'James Jordon', 'Mihaela van der Schaar']", "abstract": "Identifying when to give treatments to patients and how to select among multiple treatments over time are important medical problems with a few existing solutions. In this paper, we introduce the Counterfactual Recurrent Network (CRN), a novel sequence-to-sequence model that leverages the increasingly available patient observational data to estimate treatment effects over time and answer such medical questions. To handle the bias from time-varying confounders, covariates affecting the treatment assignment policy in the observational data, CRN uses domain adversarial training to build balancing representations of the patient history. At each timestep, CRN constructs a treatment invariant representation which removes the association between patient history and treatment assignments and thus can be reliably used for making counterfactual predictions. On a simulated model of tumour growth, with varying degree of time-dependent confounding, we show how our model achieves lower error in estimating counterfactuals and in choosing the correct treatment and timing of treatment than current state-of-the-art methods.", "pdf": "/pdf/de9e86ae52b212dbcec69624e5dbce9c46844fe6.pdf", "keywords": "['treatment effects over time', 'causal inference', 'counterfactual estimation']", "id": "BJg866NFvB"}, {"number": "544", "title": "Model Ensemble-Based Intrinsic Reward for Sparse Reward Reinforcement Learning", "authors": "['Giseung Park', 'Whiyoung Jung', 'Sungho Choi', 'Youngchul Sung']", "abstract": "In this paper, a new intrinsic reward generation method for sparse-reward reinforcement learning is proposed based on an ensemble of dynamics models. In the proposed method, the mixture of multiple dynamics models is used to approximate the true unknown transition probability, and the intrinsic reward is designed as the minimum of the surprise seen from each dynamics model to the mixture of the dynamics models. In order to show the effectiveness of the proposed intrinsic reward generation method, a working algorithm is constructed by combining the proposed intrinsic reward generation method with the proximal policy optimization (PPO) algorithm. Numerical results show that for representative locomotion tasks, the proposed model-ensemble-based intrinsic reward generation method outperforms the previous methods based on a single dynamics model.", "pdf": "/pdf/8d207505858d7fca7c3e906382eb6563e104659e.pdf", "keywords": "['Reinforcement Learning', 'Intrinsic Reward', 'Dynamics Model', 'Ensemble']", "id": "SyxJU64twr"}, {"number": "437", "title": "Collaborative Generated Hashing for Market Analysis and Fast Cold-start Recommendation", "authors": "['Yan Zhang', 'Ivor W. Tsang', 'Lixin Duan', 'Guowu Yang']", "abstract": "Cold-start and efficiency issues of the Top-k recommendation are critical to large-scale recommender systems. Previous hybrid recommendation methods are effective to deal with the cold-start issues by extracting real latent factors of cold-start items(users) from side information, but they still suffer low efficiency in online recommendation caused by the expensive similarity search in real latent space. This paper presents a collaborative generated hashing (CGH) to improve the efficiency by denoting users and items as binary codes, which applies to various settings: cold-start users, cold-start items and warm-start ones. Specifically, CGH is designed to learn hash functions of users and items through the Minimum Description Length (MDL) principle; thus, it can deal with various recommendation settings. In addition, CGH initiates a new marketing strategy through mining potential users by a generative step. To reconstruct effective users, the MDL principle is used to learn compact and informative binary codes from the content data. Extensive experiments on two public datasets show the advantages for recommendations in various settings over competing baselines and analyze the feasibility of the application in marketing.", "pdf": "/pdf/b8a2c3083c13e8abc2afeebea61322a1ba00d076.pdf", "keywords": "['Recommender system', 'generated model', 'market analysis', 'hash', 'cold start']", "id": "HJel76NYPS"}, {"number": "2241", "title": "Multichannel Generative Language Models", "authors": "['Harris Chan', 'Jamie Kiros', 'William Chan']", "abstract": "A channel corresponds to a viewpoint or transformation of an underlying meaning. A pair of parallel sentences in English and French express the same underlying meaning but through two separate channels corresponding to their languages. In this work, we present Multichannel Generative Language Models (MGLM), which models the joint distribution over multiple channels, and all its decompositions using a single neural network. MGLM can be trained by feeding it k way parallel-data, bilingual data, or monolingual data across pre-determined channels. MGLM is capable of both conditional generation and unconditional sampling. For conditional generation, the model is given a fully observed channel, and generates the k-1 channels in parallel. In the case of machine translation, this is akin to giving it one source, and the model generates k-1 targets. MGLM can also do partial conditional sampling, where the channels are seeded with prespecified words, and the model is asked to infill the rest. Finally, we can sample from MGLM unconditionally over all k channels. Our experiments on the Multi30K dataset containing English, French, Czech, and German languages suggest that the multitask training with the joint objective leads to improvements in bilingual translations. We provide a quantitative analysis of the quality-diversity trade-offs for different variants of the multichannel model for conditional generation, and a measurement of self-consistency during unconditional generation. We provide qualitative examples for parallel greedy decoding across languages and sampling from the joint distribution of the 4 languages.", "pdf": "/pdf/db58d3ed2153df0d6efed04a621cca3305d92e36.pdf", "keywords": "['text generation', 'generative language models', 'natural language processing']", "id": "r1xQNlBYPS"}, {"number": "435", "title": "DDSP: Differentiable Digital Signal Processing", "authors": "['Jesse Engel', 'Lamtharn (Hanoi) Hantrakul', 'Chenjie Gu', 'Adam Roberts']", "abstract": "Most generative models of audio directly generate samples in one of two domains: time or frequency. While sufficient to express any signal, these representations are inefficient, as they do not utilize existing knowledge of how sound is generated and perceived. A third approach (vocoders/synthesizers) successfully incorporates strong domain knowledge of signal processing and perception, but has been less actively researched due to limited expressivity and difficulty integrating with modern auto-differentiation-based machine learning methods. In this paper, we introduce the Differentiable Digital Signal Processing (DDSP) library, which enables direct integration of classic signal processing elements with deep learning methods. Focusing on audio synthesis, we achieve high-fidelity generation without the need for large autoregressive models or adversarial losses, demonstrating that DDSP enables utilizing strong inductive biases without losing the expressive power of neural networks. Further, we show that combining interpretable modules permits manipulation of each separate model component, with applications such as independent control of pitch and loudness, realistic extrapolation to pitches not seen during training, blind dereverberation of room acoustics, transfer of extracted room acoustics to new environments, and transformation of timbre between disparate sources. In short, DDSP enables an interpretable and modular approach to generative modeling, without sacrificing the benefits of deep learning. The library will is available at https://github.com/magenta/ddsp and we encourage further contributions from the community and domain experts.\n", "pdf": "/pdf/bd8d353bca498f66f2bf5db02c5fda8135120349.pdf", "keywords": "['dsp', 'audio', 'music', 'nsynth', 'wavenet', 'wavernn', 'vocoder', 'synthesizer', 'sound', 'signal', 'processing', 'tensorflow', 'autoencoder', 'disentanglement']", "id": "B1x1ma4tDr"}, {"number": "2264", "title": "GQ-Net: Training Quantization-Friendly Deep Networks", "authors": "['Rundong Li', 'Rui Fan']", "abstract": "Network quantization is a model compression and acceleration technique that has become essential to neural network deployment. Most quantization methods per- form fine-tuning on a pretrained network, but this sometimes results in a large loss in accuracy compared to the original network. We introduce a new technique to train quantization-friendly networks, which can be directly converted to an accurate quantized network without the need for additional fine-tuning. Our technique allows quantizing the weights and activations of all network layers down to 4 bits, achieving high efficiency and facilitating deployment in practical settings. Com- pared to other fully quantized networks operating at 4 bits, we show substantial improvements in accuracy, for example 66.68% top-1 accuracy on ImageNet using ResNet-18, compared to the previous state-of-the-art accuracy of 61.52% Louizos et al. (2019) and a full precision reference accuracy of 69.76%. We performed a thorough set of experiments to test the efficacy of our method and also conducted ablation studies on different aspects of the method and techniques to improve training stability and accuracy. Our codebase and trained models are available on GitHub.", "pdf": "/pdf/a415430b9af0601430b3126a8d4a63d309f9988a.pdf", "keywords": "['Network quantization', 'Efficient deep learning']", "id": "Hkx3ElHYwS"}, {"number": "79", "title": "RL-LIM: Reinforcement Learning-based Locally Interpretable Modeling", "authors": "['Jinsung Yoon', 'Sercan O. Arik', 'Tomas Pfister']", "abstract": "Understanding black-box machine learning models is important towards their widespread adoption. However, developing globally interpretable models that explain the behavior of the entire model is challenging. An alternative approach is to explain black-box models through explaining individual prediction using a locally interpretable model. In this paper, we propose a novel method for locally interpretable modeling -- Reinforcement Learning-based Locally Interpretable Modeling (RL-LIM). RL-LIM employs reinforcement learning to select a small number of samples and distill the black-box model prediction into a low-capacity locally interpretable model. Training is guided with a reward that is obtained directly by measuring agreement of the predictions from the locally interpretable model with the black-box model. RL-LIM near-matches the overall prediction performance of black-box models while yielding human-like interpretability, and significantly outperforms state of the art locally interpretable models in terms of overall prediction performance and fidelity. ", "pdf": "/pdf/68a6714c215283300d832f6ed1add443d1d850c2.pdf", "keywords": "['Interpretability', 'Explanable AI', 'Explanability']", "id": "BJx8Fh4KPB"}, {"number": "304", "title": "Thwarting finite difference adversarial attacks with output randomization", "authors": "['Haidar Khan', 'Dan Park', 'Azer Khan', 'B\u00fclent Yener']", "abstract": "  Adversarial input poses a critical problem to deep neural networks (DNN). This problem is more severe in the 'black box' setting where an adversary only needs to repeatedly query a DNN to estimate the gradients required to create adversarial examples. Current defense techniques against attacks in this setting are not effective. Thus, in this paper, we present a novel defense technique based on randomization applied to a DNN's output layer. While effective as a defense technique, this approach introduces a trade off between accuracy and robustness. We show that for certain types of randomization, we can bound the probability of introducing errors by carefully setting distributional parameters. For the particular case of finite difference black box attacks, we quantify the error introduced by the defense in the finite difference estimate of the gradient. Lastly, we show empirically that the defense can thwart three adaptive black box adversarial attack algorithms. ", "pdf": "/pdf/3adbb854ce84c2fe77880ee65bc31c67d524f1a9.pdf", "keywords": "['black box adversarial attacks', 'adversarial examples', 'defense', 'deep learning']", "id": "S1lDkaEFwS"}, {"number": "2169", "title": "Selective sampling for accelerating  training of deep neural networks", "authors": "['Berry Weinstein', 'Shai Fine', 'Yacov Hel-Or']", "abstract": "We present a selective sampling method designed to accelerate the training of deep neural networks. To this end,  we introduce a novel measurement,  the {\\it minimal margin score} (MMS), which measures the minimal amount of displacement an input should take until its predicted classification is switched.   For multi-class linear classification,  the MMS measure is a natural generalization of the margin-based selection criterion, which was thoroughly studied in the binary classification setting.  In addition, the MMS measure provides an interesting insight into the progress of the training process and can be useful for designing and monitoring new training regimes. Empirically we demonstrate a substantial acceleration when training commonly used deep neural network architectures for popular image classification tasks.  The efficiency of our method is compared against the standard training procedures, and against commonly used selective sampling alternatives: Hard negative mining selection, and Entropy-based selection.\nFinally, we demonstrate an additional speedup when we adopt a more aggressive learning-drop regime while using the MMS selective sampling method.", "pdf": "/pdf/2f6172635fd4b5b82ca61b88cfca796fee570ab6.pdf", "keywords": "[]", "id": "SJxNzgSKvH"}, {"number": "1271", "title": "Removing the Representation Error of GAN Image Priors Using the Deep Decoder", "authors": "['Max Daniels', 'Reinhard Heckel', 'Paul Hand']", "abstract": "Generative models, such as GANs, have demonstrated impressive performance as natural image priors for solving inverse problems such as image restoration and compressive sensing. Despite this performance, they can exhibit substantial representation error for both in-distribution and out-of-distribution images, because they maintain explicit low-dimensional learned representations of a natural signal class. In this paper, we demonstrate a method for removing the representation error of a GAN when used as a prior in inverse problems by modeling images as the linear combination of a GAN with a Deep Decoder. The deep decoder is an underparameterized and most importantly unlearned natural signal model similar to the Deep Image Prior.  No knowledge of the specific inverse problem is needed in the training of the GAN underlying our method.  For compressive sensing and image superresolution, our hybrid model exhibits consistently higher PSNRs than both the GAN priors and Deep Decoder separately, both on in-distribution and out-of-distribution images.  This model provides a method for extensibly and cheaply leveraging both the benefits of learned and unlearned image recovery priors in inverse problems.", "pdf": "/pdf/56299323b2e5f0c8e7f4d71399a49fccc8259f71.pdf", "keywords": "['deep decoder', 'deep image prior', 'GAN', 'inverse problems']", "id": "rkegcC4YvS"}, {"number": "1837", "title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": "['Jin-Young  Kim', 'Sung-Bae Cho']", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "keywords": "['variational autoencoder', 'latent space', 'basis', 'disentangled representation']", "id": "S1gEFkrtvH"}, {"number": "1497", "title": "UWGAN: UNDERWATER GAN FOR REAL-WORLD UNDERWATER COLOR RESTORATION AND DEHAZING", "authors": "['Nan Wang', 'Yabin Zhou', 'Fenglei Han', 'Lichao Wan', 'Haitao Zhu', 'Yaojing Zheng']", "abstract": "In real-world underwater environment, exploration of seabed resources, underwater archaeology, and underwater fishing rely on a variety of sensors, vision sensor is the most important one due to its high information content, non-intrusive, and passive nature. However, wavelength-dependent light attenuation and back-scattering result in color distortion and haze effect, which degrade the visibility of images. To address this problem, firstly, we proposed an unsupervised generative adversarial network (GAN) for generating realistic underwater images (color distortion and haze effect simulation) from in-air image and depth map pairs. Secondly, U-Net, which is trained efficiently using synthetic underwater dataset, is adopted for color restoration and de-hazing. Our model directly reconstructs underwater clear images using end-to-end autoencoder networks, while maintaining scene content structural similarity. The results obtained by our method were compared with existing methods qualitatively and quantitatively. Experimental results on open real-world underwater datasets demonstrate that the presented method performs well on different actual underwater scenes, and the processing speed can reach up to 125FPS on images running on one NVIDIA 1060 GPU.", "pdf": "/pdf/f71080dccef9ab4aa1c2e97f320d7f52fa560edc.pdf", "keywords": "['underwater image', 'image restoration', 'image enhancement', 'GAN', 'CNNs']", "id": "HkgMxkHtPH"}, {"number": "614", "title": "Hindsight Trust Region Policy Optimization", "authors": "['Hanbo Zhang', 'Site Bai', 'Xuguang Lan', 'Nanning Zheng']", "abstract": "As reinforcement learning continues to drive machine intelligence beyond its conventional boundary, unsubstantial practices in sparse reward environment severely limit further applications in a broader range of advanced fields. Motivated by the demand for an effective deep reinforcement learning algorithm that accommodates sparse reward environment, this paper presents Hindsight Trust Region Policy Optimization (HTRPO), a method that efficiently utilizes interactions in sparse reward conditions to optimize policies within trust region and, in the meantime, maintains learning stability. Firstly, we theoretically adapt the TRPO objective function, in the form of the expected return of the policy, to the distribution of hindsight data generated from the alternative goals. Then, we apply Monte Carlo with importance sampling to estimate KL-divergence between two policies, taking the hindsight data as input. Under the condition that the distributions are sufficiently close, the KL-divergence is approximated by another f-divergence. Such approximation results in the decrease of variance and alleviates the instability during policy update.  Experimental results on both discrete and continuous benchmark tasks demonstrate that HTRPO converges significantly faster than previous policy gradient methods. It achieves effective performances and high data-efficiency for training policies in sparse reward environments.", "pdf": "/pdf/502553557152a6aa563737f058aa15c350f1d5cd.pdf", "keywords": "['Hindsight', 'Sparse Reward', 'Reinforcement Learning', 'Policy Gradients']", "id": "rylCP6NFDB"}, {"number": "1863", "title": "A Simple Dynamic Learning Rate Tuning Algorithm For Automated Training of DNNs", "authors": "['Koyel Mukherjee', 'Alind Khare', 'Yogish Sabharwal', 'Ashish Verma']", "abstract": "Training neural networks on image datasets generally require extensive experimentation to find the optimal learning rate regime. Especially, for the cases of adversarial training or for training a newly synthesized model, one would not know the best learning rate regime beforehand. We propose an automated algorithm for determining the learning rate trajectory, that works across datasets and models for both natural and adversarial training, without requiring any dataset/model specific tuning. It is a stand-alone, parameterless, adaptive approach with no computational overhead. We theoretically discuss the algorithm's convergence behavior. We empirically validate our algorithm extensively. Our results show that our proposed approach \\emph{consistently} achieves top-level accuracy compared to SOTA baselines in the literature in natural training, as well as in adversarial training.", "pdf": "/pdf/4d0102d98c8084fc76dce764e0651f74c4781226.pdf", "keywords": "['adaptive LR tuning algorithm', 'generalization']", "id": "rJxyqkSYDH"}, {"number": "2208", "title": "Unsupervised Learning of Graph Hierarchical Abstractions with Differentiable Coarsening and Optimal Transport", "authors": "['Tengfei Ma', 'Jie Chen']", "abstract": "Hierarchical abstractions are a methodology for solving large-scale graph problems in various disciplines. Coarsening is one such approach: it generates a pyramid of graphs whereby the one in the next level is a structural summary of the prior one. With a long history in scientific computing, many coarsening strategies were developed based on mathematically driven heuristics. Recently, resurgent interests exist in deep learning to design hierarchical methods learnable through differentiable parameterization. These approaches are paired with downstream tasks for supervised learning. In this work, we propose an unsupervised approach, coined \\textsc{OTCoarsening}, with the use of optimal transport. Both the coarsening matrix and the transport cost matrix are parameterized, so that an optimal coarsening strategy can be learned and tailored for a given set of graphs. We demonstrate that the proposed approach produces meaningful coarse graphs and yields competitive performance compared with supervised methods for graph classification.", "pdf": "/pdf/480a1e2a2459842b0b1b1a67109715498481b832.pdf", "keywords": "['Unsupervised learning', 'hierarchical representation learning', 'graph neural networks']", "id": "Bkf4XgrKvS"}, {"number": "366", "title": "Stochastic Gradient Descent with Biased but Consistent Gradient Estimators", "authors": "['Jie Chen', 'Ronny Luss']", "abstract": "Stochastic gradient descent (SGD), which dates back to the 1950s, is one of the most popular and effective approaches for performing stochastic optimization. Research on SGD resurged recently in machine learning for optimizing convex loss functions and training nonconvex deep neural networks. The theory assumes that one can easily compute an unbiased gradient estimator, which is usually the case due to the sample average nature of empirical risk minimization. There exist, however, many scenarios (e.g., graphs) where an unbiased estimator may be as expensive to compute as the full gradient because training examples are interconnected. Recently, Chen et al. (2018) proposed using a consistent gradient estimator as an economic alternative. Encouraged by empirical success, we show, in a general setting, that consistent estimators result in the same convergence behavior as do unbiased ones. Our analysis covers strongly convex, convex, and nonconvex objectives. We verify the results with illustrative experiments on synthetic and real-world data. This work opens several new research directions, including the development of more efficient SGD updates with consistent estimators and the design of efficient training algorithms for large-scale graphs.\n", "pdf": "/pdf/6b3dd605321313b868dc08505fd4ddd1df6cca31.pdf", "keywords": "['Stochastic optimization', 'biased gradient estimator', 'graph convolutional networks']", "id": "rygMWT4twS"}, {"number": "1233", "title": "Amortized Nesterov's Momentum: Robust and Lightweight  Momentum for Deep Learning", "authors": "['Kaiwen Zhou', 'Yanghua Jin', 'Qinghua Ding', 'James Cheng']", "abstract": "Stochastic Gradient Descent (SGD) with Nesterov's momentum is a widely used optimizer in deep learning, which is observed to have excellent generalization performance. However, due to the large stochasticity, SGD with Nesterov's momentum is not robust, i.e., its performance may deviate significantly from the expectation. In this work, we propose Amortized Nesterov's Momentum, a special variant of Nesterov's momentum which has more robust iterates, faster convergence in the early stage and higher efficiency. Our experimental results show that this new momentum achieves similar (sometimes better) generalization performance with little-to-no tuning. In the convex case, we provide optimal convergence rates for our new methods and discuss how the theorems explain the empirical results. ", "pdf": "/pdf/b3a9c490fedc2454fde4cb11353b711c479bacc1.pdf", "keywords": "['momentum', 'nesterov', 'optimization', 'deep learning', 'neural networks']", "id": "S1xJFREKvB"}, {"number": "619", "title": "Scalable Neural Methods for Reasoning With a Symbolic Knowledge   Base", "authors": "['William W. Cohen', 'Haitian Sun', 'R. Alex Hofer', 'Matthew Siegler']", "abstract": "We describe a novel way of representing a symbolic knowledge base (KB) called a sparse-matrix reified KB.  This representation enables neural modules that are fully differentiable, faithful to the original semantics of the KB, expressive enough to model multi-hop inferences, and scalable enough to use with realistically large KBs. The sparse-matrix reified KB can be distributed across multiple GPUs, can scale to tens of millions of entities and facts, and is orders of magnitude faster than naive sparse-matrix implementations.  The reified KB enables very simple end-to-end architectures to obtain competitive performance on several benchmarks representing two families of tasks: KB completion, and learning semantic parsers from denotations.", "pdf": "/pdf/0a0b8ae9915a6c580db0233edb49d0b07e5b4a82.pdf", "keywords": "['question-answering', 'knowledge base completion', 'neuro-symbolic reasoning', 'multihop reasoning']", "id": "BJlguT4YPr"}, {"number": "1876", "title": "Rotation-invariant clustering of neuronal responses in primary visual cortex", "authors": "['Ivan Ustyuzhaninov', 'Santiago A. Cadena', 'Emmanouil Froudarakis', 'Paul G. Fahey', 'Edgar Y. Walker', 'Erick Cobos', 'Jacob Reimer', 'Fabian H. Sinz', 'Andreas S. Tolias', 'Matthias Bethge', 'Alexander S. Ecker']", "abstract": "Similar to a convolutional neural network (CNN), the mammalian retina encodes visual information into several dozen nonlinear feature maps, each formed by one ganglion cell type that tiles the visual space in an approximately shift-equivariant manner. Whether such organization into distinct cell types is maintained at the level of cortical image processing is an open question. Predictive models building upon convolutional features have been shown to provide state-of-the-art performance, and have recently been extended to include rotation equivariance in order to account for the orientation selectivity of V1 neurons. However, generally no direct correspondence between CNN feature maps and groups of individual neurons emerges in these models, thus rendering it an open question whether V1 neurons form distinct functional clusters. Here we build upon the rotation-equivariant representation of a CNN-based V1 model and propose a methodology for clustering the representations of neurons in this model to find functional cell types independent of preferred orientations of the neurons. We apply this method to a dataset of 6000 neurons and visualize the preferred stimuli of the resulting clusters. Our results highlight the range of non-linear computations in mouse V1.", "pdf": "/pdf/8047d6ef874c09100bca5cd5dcaf81258fbd5bcd.pdf", "keywords": "['computational neuroscience', 'neural system identification', 'functional cell types', 'deep learning', 'rotational equivariance']", "id": "rklr9kHFDB"}, {"number": "1470", "title": "Learning in Confusion: Batch Active Learning with Noisy Oracle", "authors": "['Gaurav Gupta', 'Anit Kumar Sahu', 'Wan-Yi Lin']", "abstract": "We study the problem of training machine learning models incrementally using active learning with access to imperfect or noisy oracles. We specifically consider the setting of batch active learning, in which multiple samples are selected as opposed to a single sample as in classical settings so as to reduce the training overhead. Our approach bridges between uniform randomness and score based importance sampling of clusters when selecting a batch of new samples. Experiments on\nbenchmark image classification datasets (MNIST, SVHN, and CIFAR10) shows improvement over existing active learning strategies. We introduce an extra denoising layer to deep networks to make active learning robust to label noises and show significant improvements.\n", "pdf": "/pdf/8740f822938dd32907511cac542103fd2a1ee79d.pdf", "keywords": "['Active Learning', 'Noisy Oracle', 'Model Uncertainty', 'Image classification']", "id": "SJxIkkSKwB"}, {"number": "1662", "title": "Learning Good Policies By Learning Good Perceptual Models", "authors": "['Yilun Du', 'Phillip Isola']", "abstract": "    Reinforcement learning (RL) has led to increasingly complex looking behavior in recent years. However, such complexity can be misleading and hides over-fitting. We find that visual representations may be a useful metric of complexity, and both correlates well objective optimization and causally effects reward optimization. We then propose curious representation learning (CRL) which allows us to use better visual representation learning algorithms to correspondingly increase visual representation in policy through an intrinsic objective on both simulated environments and transfer to real images. Finally, we show better visual representations induced by CRL allows us to obtain better performance on Atari without any reward than other curiosity objectives.", "pdf": "/pdf/f7a56aa406d3dbc9410c542ac8d13f917e9c99ca.pdf", "keywords": "['visual representation learning', 'reinforcement learning', 'curiosity']", "id": "HkgYEyrFDr"}, {"number": "481", "title": "Generative Latent Flow", "authors": "['Zhisheng Xiao', 'Qing Yan', 'Yali Amit']", "abstract": "In this work, we propose the Generative Latent Flow (GLF), an algorithm for generative modeling of the data distribution. GLF uses an Auto-encoder (AE) to learn latent representations of the data, and a normalizing flow to map the distribution of the latent variables to that of simple i.i.d noise. In contrast to some other Auto-encoder based generative models, which use various regularizers that encourage the encoded latent distribution to match the prior distribution, our model explicitly constructs a mapping between these two distributions, leading to better density matching while avoiding over regularizing the latent variables. We compare our model with several related techniques, and show that it has many relative advantages including fast convergence, single stage training and minimal reconstruction trade-off. We also study the relationship between our model and its stochastic counterpart, and show that our model can be viewed as a vanishing noise limit of VAEs with flow prior.  Quantitatively, under standardized evaluations, our method achieves state-of-the-art sample quality and diversity among AE based models on commonly used datasets, and is competitive with GANs' benchmarks. ", "pdf": "/pdf/0f05c66caacf515cab4ab7dae0d957f3bbc2c56b.pdf", "keywords": "['Generative Model', 'Auto-encoder', 'Normalizing Flow']", "id": "Syg7VaNYPB"}, {"number": "2182", "title": "Few-Shot One-Class Classification via Meta-Learning", "authors": "['Ahmed Frikha', 'Denis Krompa\u00df', 'Hans-Georg Koepken', 'Volker Tresp']", "abstract": "Although  few-shot  learning  and  one-class  classification have been separately well studied,  their intersection remains rather unexplored.  Our work addresses the few-shot one-class classification problem and presents a meta-learning approach that requires only few data examples from only one class to adapt to unseen tasks.  The proposed method builds upon the model-agnostic meta-learning (MAML) algorithm (Finn et al., 2017) and explicitly trains for few-shot class-imbalance learning, aiming to learn a model initialization that is particularly suited for learning one-class classification tasks after observing only a few examples of one class.  Experimental results on datasets from the image domain and the time-series domain show that our model substantially outperforms the baselines, including MAML, and demonstrate the ability to learn new tasks from only few majority class samples.  Moreover, we successfully learn anomaly detectors for a real world application involving sensor readings recorded during industrial manufacturing of workpieces with a CNC milling machine using only few examples from the normal class.", "pdf": "/pdf/05bf5ccc333537a17034cc20ed3680d9efa50034.pdf", "keywords": "['meta-learning', 'few-shot learning', 'one-class classification', 'class-imbalance learning']", "id": "B1ltfgSYwS"}, {"number": "1315", "title": "The Sooner The Better: Investigating Structure of Early Winning Lottery Tickets", "authors": "['Shihui Yin', 'Kyu-Hyoun Kim', 'Jinwook Oh', 'Naigang Wang', 'Mauricio Serrano', 'Jae-Sun Seo', 'Jungwook Choi']", "abstract": "The recent success of the lottery ticket hypothesis by Frankle & Carbin (2018) suggests that small, sparsified neural networks can be trained as long as the network is initialized properly. Several follow-up discussions on the initialization of the sparsified model have discovered interesting characteristics such as the necessity of rewinding (Frankle et al. (2019)), importance of sign of the initial weights (Zhou et al. (2019)), and the transferability of the winning lottery tickets (S. Morcos et al. (2019)). In contrast, another essential aspect of the winning ticket, the structure of the sparsified model, has been little discussed. To find the lottery ticket, unfortunately, all the prior work still relies on computationally expensive iterative pruning. \n\nIn this work, we conduct an in-depth investigation of the structure of winning lottery tickets. Interestingly, we discover that there exist many lottery tickets that can achieve equally good accuracy much before the regular training schedule even finishes. We provide insights into the structure of these early winning tickets with supporting evidence. 1) Under stochastic gradient descent optimization, lottery ticket emerges when weight magnitude of a model saturates; 2) Pruning before the saturation of a model causes the loss of capability in learning complex patterns, resulting in the accuracy degradation. We employ the memorization capacity analysis to quantitatively confirm it, and further explain why gradual pruning can achieve better accuracy over the one-shot pruning. Based on these insights, we discover the early winning tickets for various ResNet architectures on both CIFAR10 and ImageNet, achieving state-of-the-art accuracy at a high pruning rate without expensive iterative pruning. In the case of ResNet50 on ImageNet, this comes to the winning ticket of 75:02% Top-1 accuracy at 80% pruning rate in only 22% of the total epochs for iterative pruning.", "pdf": "/pdf/94ea0ed4f8eee193bcc9a9fb5e2f20890aa69d35.pdf", "keywords": "['pruning', 'lottery ticket hypothesis', 'deep neural network', 'compression', 'image classification']", "id": "BJlNs0VYPB"}, {"number": "923", "title": "CAQL: Continuous Action Q-Learning", "authors": "['Moonkyung Ryu', 'Yinlam Chow', 'Ross Anderson', 'Christian Tjandraatmadja', 'Craig Boutilier']", "abstract": "Reinforcement learning (RL) with value-based methods (e.g., Q-learning) has shown success in a variety of domains such as\ngames and recommender systems (RSs). When the action space is finite, these algorithms implicitly finds a policy by learning the optimal value function, which are often very efficient. \nHowever, one major challenge of extending Q-learning to tackle continuous-action RL problems is that obtaining optimal Bellman backup requires solving a continuous action-maximization (max-Q) problem. While it is common to restrict the parameterization of the Q-function to be concave in actions to simplify the max-Q problem, such a restriction might lead to performance degradation. Alternatively, when the Q-function is parameterized with a generic feed-forward neural network (NN), the max-Q problem can be NP-hard. In this work, we propose the CAQL method which minimizes the Bellman residual using Q-learning with one of several plug-and-play action optimizers. In particular, leveraging the strides of optimization theories in deep NN, we show that max-Q problem can be solved optimally with mixed-integer programming (MIP)---when the Q-function has sufficient representation power, this MIP-based optimization induces better policies and is more robust than counterparts, e.g., CEM or GA, that approximate the max-Q solution. To speed up training of CAQL, we develop three techniques, namely (i) dynamic tolerance, (ii) dual filtering, and (iii) clustering.\nTo speed up inference of CAQL, we introduce the action function that concurrently learns the optimal policy.\nTo demonstrate the efficiency of CAQL we compare it with state-of-the-art RL algorithms on benchmark continuous control problems that have different degrees of action constraints and show that CAQL significantly outperforms policy-based methods in heavily constrained environments.", "pdf": "/pdf/49cfb54fa89345e85f991893706d894f0d953510.pdf", "keywords": "['Reinforcement learning (RL)', 'DQN', 'Continuous control', 'Mixed-Integer Programming (MIP)']", "id": "BkxXe0Etwr"}, {"number": "1087", "title": "Switched linear projections and inactive state sensitivity for deep neural network interpretability", "authors": "['Lech Szymanski', 'Brendan McCane', 'Craig Atkinson']", "abstract": "We introduce switched linear projections for expressing the activity of a neuron in a ReLU-based deep neural network in terms of a single linear projection in the input space. The method works by isolating the active subnetwork, a series of linear transformations, that completely determine the entire computation of the deep network for a given input instance. We also propose that for interpretability it is more instructive and meaningful to focus on the patterns that deactive the neurons in the network, which are ignored by the exisiting methods that implicitly track only the active aspect of the network's computation. We introduce a novel interpretability method for the inactive state sensitivity (Insens). Comparison against existing methods shows that Insens is more robust (in the presence of noise), more complete (in terms of patterns that affect the computation) and a very effective interpretability method for deep neural networks", "pdf": "/pdf/a9741d7e3c64d0cff6e7b6b2795a6bfa66f4c7d0.pdf", "keywords": "['deep learning', 'interpretability', 'artificial neural networks']", "id": "SyxjVRVKDB"}, {"number": "341", "title": "InfoCNF: Efficient Conditional Continuous Normalizing Flow Using Adaptive Solvers", "authors": "['Tan M. Nguyen', 'Animesh Garg', 'Richard G. Baraniuk', 'Anima Anandkumar']", "abstract": "Continuous Normalizing Flows (CNFs) have emerged as promising deep generative models for a wide range of tasks thanks to their invertibility and exact likelihood estimation. However, conditioning CNFs on signals of interest for conditional image generation and downstream predictive tasks is inefficient due to the high-dimensional latent code generated by the model, which needs to be of the same size as the input data. In this paper, we propose InfoCNF, an efficient conditional CNF that partitions the latent space into a class-specific supervised code and an unsupervised code that shared among all classes for efficient use of labeled information. Since the partitioning strategy (slightly) increases the number of function evaluations (NFEs),  InfoCNF also employs gating networks to learn the error tolerances of its ordinary differential equation (ODE) solvers for better speed and performance. We show empirically that InfoCNF improves the test accuracy over the baseline  while yielding comparable likelihood scores and reducing the NFEs on CIFAR10. Furthermore, applying the same partitioning strategy in InfoCNF on time-series data helps improve extrapolation performance. ", "pdf": "/pdf/7c112152381378a93d40fbe90e16b03ab26e2c28.pdf", "keywords": "['continuous normalizing flows', 'conditioning', 'adaptive solvers', 'gating networks']", "id": "SJgvl6EFwH"}, {"number": "261", "title": "On the Convergence of FedAvg on Non-IID Data", "authors": "['Xiang Li', 'Kaixuan Huang', 'Wenhao Yang', 'Shusen Wang', 'Zhihua Zhang']", "abstract": "Federated learning enables a large amount of edge computing devices to jointly learn a model without data sharing. As a leading algorithm in this setting, Federated Averaging (\\texttt{FedAvg}) runs Stochastic Gradient Descent (SGD) in parallel on a small subset of the total devices and averages the sequences only once in a while. Despite its simplicity, it lacks theoretical guarantees under realistic settings. In this paper, we analyze the convergence of \\texttt{FedAvg} on non-iid data and establish a convergence rate of $\\mathcal{O}(\\frac{1}{T})$ for strongly convex and smooth problems, where $T$ is the number of SGDs. Importantly, our bound demonstrates a trade-off between communication-efficiency and convergence rate. As user devices may be disconnected from the server, we relax the assumption of full device participation to partial device participation and study different averaging schemes; low device participation rate can be achieved without severely slowing down the learning.  Our results indicate that heterogeneity of data slows down the convergence, which matches empirical observations. Furthermore, we provide a necessary condition for \\texttt{FedAvg} on non-iid data: the learning rate $\\eta$ must decay, even if full-gradient is used; otherwise, the solution will be $\\Omega (\\eta)$ away from the optimal.", "pdf": "/pdf/dcd68da80bc99678b1254ec0b4d49dee872c7898.pdf", "keywords": "['Federated Learning', 'stochastic optimization', 'Federated Averaging']", "id": "HJxNAnVtDS"}, {"number": "1579", "title": "Cyclic Graph Dynamic Multilayer Perceptron for Periodic Signals", "authors": "['Mikio Furokawa', 'Erik Gest', 'Takayuki Hirano', 'Kamal Youcef-Toumi']", "abstract": "We propose a feature extraction for periodic signals. Virtually every mechanized transportation vehicle, power generation, industrial machine, and robotic system contains rotating shafts. It is possible to collect data about periodicity by mea- suring a shafts rotation. However, it is difficult to perfectly control the collection timing of the measurements. Imprecise timing creates phase shifts in the resulting data. Although a phase shift does not materially affect the measurement of any given data point collected, it does alter the order in which all of the points are col- lected. It is difficult for classical methods, like multi-layer perceptron, to identify or quantify these alterations because they depend on the order of the input vectors components. This paper proposes a robust method for extracting features from phase shift data by adding a graph structure to each data point and constructing a suitable machine learning architecture for graph data with cyclic permutation. Simulation and experimental results illustrate its effectiveness.", "pdf": "/pdf/cd998a0d545829d56fbf039481e875c86860c51f.pdf", "keywords": "[]", "id": "S1xSzyrYDB"}, {"number": "2589", "title": "Geom-GCN: Geometric Graph Convolutional Networks", "authors": "['Hongbin Pei', 'Bingzhe Wei', 'Kevin Chen-Chuan Chang', 'Yu Lei', 'Bo Yang']", "abstract": "Message-passing neural networks (MPNNs) have been successfully applied in a wide variety of applications in the real world. However, two fundamental weaknesses of MPNNs' aggregators limit their ability to represent graph-structured data: losing the structural information of nodes in neighborhoods and lacking the ability to capture long-range dependencies in disassortative graphs. Few studies have noticed the weaknesses from different perspectives. From the observations on classical neural network and network geometry, we propose a novel geometric aggregation scheme for graph neural networks to overcome the two weaknesses.  The behind basic idea is the aggregation on a graph can benefit from a continuous space underlying the graph. The proposed aggregation scheme is permutation-invariant and consists of three modules, node embedding, structural neighborhood, and bi-level aggregation. We also present an implementation of the scheme in graph convolutional networks, termed Geom-GCN, to perform transductive learning on graphs. Experimental results show the proposed Geom-GCN achieved state-of-the-art performance on a wide range of open datasets of graphs.", "pdf": "/pdf/8525a0a37e61fc3279ee008c3428737a91a4a390.pdf", "keywords": "['Deep Learning', 'Graph Convolutional Network', 'Network Geometry']", "id": "S1e2agrFvS"}, {"number": "606", "title": "Mogrifier LSTM", "authors": "['G\u00e1bor Melis', 'Tom\u00e1\u0161 Ko\u010disk\u00fd', 'Phil Blunsom']", "abstract": "Many advances in Natural Language Processing have been based upon more expressive models for how inputs interact with the context in which they occur. Recurrent networks, which have enjoyed a modicum of success, still lack the generalization and systematicity ultimately required for modelling language. In this work, we propose an extension to the venerable Long Short-Term Memory in the form of mutual gating of the current input and the previous output. This mechanism affords the modelling of a richer space of interactions between inputs and their context. Equivalently, our model can be viewed as making the transition function given by the LSTM context-dependent. Experiments demonstrate markedly improved generalization on language modelling in the range of 34 perplexity points on Penn Treebank and Wikitext-2, and 0.010.05 bpc on four character-based datasets. We establish a new state of the art on all datasets with the exception of Enwik8, where we close a large gap between the LSTM and Transformer models.\n", "pdf": "/pdf/dec59d4add1086f58d1c0626c2f4a095c7e455c7.pdf", "keywords": "['lstm', 'language modelling']", "id": "SJe5P6EYvS"}, {"number": "814", "title": "Tensor Graph Convolutional Networks for Prediction on Dynamic Graphs", "authors": "['Osman Asif Malik', 'Shashanka Ubaru', 'Lior Horesh', 'Misha E. Kilmer', 'Haim Avron']", "abstract": "Many irregular domains such as social networks, financial transactions, neuron connections, and natural language structures are represented as graphs. In recent years, a variety of  graph neural networks (GNNs) have been successfully applied for representation learning and prediction on such graphs. However, in many of the applications, the underlying graph changes over time and existing GNNs are inadequate for handling such dynamic graphs. In this paper we propose a novel technique for learning embeddings of dynamic graphs based on a tensor algebra framework. Our method extends the popular graph convolutional network (GCN) for learning representations of dynamic graphs using the recently proposed tensor M-product technique. Theoretical results that establish the connection between the proposed tensor approach and spectral convolution of tensors are developed. Numerical experiments on real datasets demonstrate the usefulness of the proposed method for an edge classification task on dynamic graphs.", "pdf": "/pdf/ef57c5e2db673a4311108f32c334651f298f2d5d.pdf", "keywords": "['graph convolutional networks', 'graph learning', 'dynamic graphs', 'edge classification', 'tensors']", "id": "rylVTTVtvH"}, {"number": "1374", "title": "Evaluating Lossy Compression Rates of Deep Generative Models", "authors": "['Sicong Huang', 'Alireza Makhzani', 'Yanshuai Cao', 'Roger Grosse']", "abstract": "Deep generative models have achieved remarkable progress in recent years. Despite this progress, quantitative evaluation and comparison of generative models remains as one of the important challenges. One of the most popular metrics for evaluating generative models is the log-likelihood. While the direct computation of log-likelihood can be intractable, it has been recently shown that the log-likelihood of some of the most interesting generative models such as variational autoencoders (VAE) or generative adversarial networks (GAN) can be efficiently estimated using annealed importance sampling (AIS). In this work, we argue that the log-likelihood metric by itself cannot represent all the different performance characteristics of generative models, and propose to use rate distortion curves to evaluate and compare deep generative models. We show that we can approximate the entire rate distortion curve using one single run of AIS for roughly the same computational cost as a single log-likelihood estimate. We evaluate lossy compression rates of different deep generative models such as VAEs, GANs (and its variants) and adversarial autoencoders (AAE) on MNIST and CIFAR10, and arrive at a number of insights not obtainable from log-likelihoods alone.", "pdf": "/pdf/00cbba25b5509019bdbad12f19e24174cb937b2c.pdf", "keywords": "['Deep Learning', 'Generative Models', 'Information Theory', 'Rate Distortion Theory']", "id": "ryga2CNKDH"}, {"number": "453", "title": "Learning Explainable Models Using Attribution Priors", "authors": "['Gabriel Erion', 'Joseph D. Janizek', 'Pascal Sturmfels', 'Scott M. Lundberg', 'Su-In Lee']", "abstract": "Two important topics in deep learning both involve incorporating humans into the modeling process: Model priors transfer information from humans to a model by regularizing the model's parameters; Model attributions transfer information from a model to humans by explaining the model's behavior. Previous work has taken important steps to connect these topics through various forms of gradient regularization. We find, however, that existing methods that use attributions to align a model's behavior with human intuition are ineffective. We develop an efficient and theoretically grounded feature attribution method, expected gradients, and a novel framework, attribution priors, to enforce prior expectations about a model's behavior during training. We demonstrate that attribution priors are broadly applicable by instantiating them on three different types of data: image data, gene expression data, and health care data. Our experiments show that models trained with attribution priors are more intuitive and achieve better generalization performance than both equivalent baselines and existing methods to regularize model behavior.", "pdf": "/pdf/324969c79279a475801b24283635e72653367037.pdf", "keywords": "['Deep Learning', 'Interpretability', 'Attributions', 'Explanations', 'Biology', 'Health', 'Computational Biology']", "id": "rygPm64tDH"}, {"number": "1893", "title": "Asymptotic learning curves of kernel methods: empirical data v.s. Teacher-Student paradigm", "authors": "['Stefano Spigler', 'Mario Geiger', 'Matthieu Wyart']", "abstract": "How many training data are needed to learn a supervised task? It is often observed that the generalization error decreases  as $n^{-\\beta}$ where $n$ is the number of training examples and $\\beta$  an exponent that  depends on both data and algorithm. In this work we measure  $\\beta$  when applying kernel methods to real datasets. For MNIST we find $\\beta\\approx 0.4$ and for CIFAR10 $\\beta\\approx 0.1$. Remarkably, $\\beta$ is the same for  regression and classification tasks, and for Gaussian or Laplace kernels. To rationalize the existence of non-trivial exponents that can be independent of the specific kernel used, we introduce the Teacher-Student framework for kernels. In this scheme, a Teacher generates data according to a Gaussian random field, and a Student learns  them via kernel regression. With a simplifying assumption --- namely that the data are sampled from a regular lattice --- we derive analytically $\\beta$  for translation invariant kernels, using previous results from the kriging literature.  Provided that the Student is not too sensitive to high frequencies, $\\beta$ depends only on the training data and their dimension. We confirm numerically that these predictions hold when the training points are  sampled  at random on a hypersphere. Overall, our results quantify how smooth Gaussian data should be to avoid the curse of dimensionality, and indicate that for kernel learning the relevant dimension of the data  should be defined in terms of how the distance between  nearest data points depends on $n$. With this definition one obtains reasonable effective smoothness estimates for MNIST and CIFAR10.", "pdf": "/pdf/90e7b0840786dd9dccd469ae743c6cee9aaa3b19.pdf", "keywords": "[]", "id": "r1enqkBtwr"}, {"number": "610", "title": "MLModelScope: A Distributed Platform for ML Model Evaluation and Benchmarking at Scale", "authors": "['Cheng Li', 'Abdul Dakkak', 'Jinjun Xiong', 'Wen-mei Hwu']", "abstract": "Machine Learning (ML) and Deep Learning (DL) innovations are being introduced at such a rapid pace that researchers are hard-pressed to analyze and study them. The complicated procedures for evaluating innovations, along with the lack of standard and efficient ways of specifying and provisioning ML/DL evaluation, is a major 'pain point' for the community. This paper proposes MLModelScope, an open-source, framework/hardware agnostic, extensible and customizable design that enables repeatable, fair, and scalable model evaluation and benchmarking.  We implement the distributed design with support for all major frameworks and hardware, and equip it with web, command-line, and library interfaces. To demonstrate MLModelScope's capabilities we perform parallel evaluation and show how subtle changes to model evaluation pipeline affects the accuracy and HW/SW stack choices affect performance.", "pdf": "/pdf/9555f6963a419e4941e131f605582477b822f654.pdf", "keywords": "['Evaluation', 'Scalable', 'Repeatable', 'Fair', 'System']", "id": "ryx2wp4tvS"}, {"number": "2525", "title": "Batch Normalization is a Cause of Adversarial Vulnerability", "authors": "['Angus Galloway', 'Anna Golubeva', 'Thomas Tanay', 'Medhat Moussa', 'Graham W. Taylor']", "abstract": "Batch normalization (BN) is often used in an attempt to stabilize and accelerate training in deep neural networks. In many cases it indeed decreases the number of parameter updates required to achieve low training error. However, it also reduces robustness to small adversarial input perturbations and common corruptions by double-digit percentages, as we show on five standard datasets. Furthermore, we find that substituting weight decay for BN is sufficient to nullify a relationship between adversarial vulnerability and the input dimension. A recent mean-field analysis found that BN induces gradient explosion when used on multiple layers, but this cannot fully explain the vulnerability we observe, given that it occurs already for a single BN layer. We argue that the actual cause is the tilting of the decision boundary with respect to the nearest-centroid classifier along input dimensions of low variance. As a result, the constant introduced for numerical stability in the BN step acts as an important hyperparameter that can be tuned to recover some robustness at the cost of standard test accuracy. We explain this mechanism explicitly on a linear ``toy model and show in experiments that it still holds for nonlinear ``real-world models.", "pdf": "/pdf/b4194c0ee567812e4a29e27d0deebb65dc0242e3.pdf", "keywords": "['batch normalization', 'adversarial examples', 'robustness']", "id": "H1x-3xSKDr"}, {"number": "355", "title": "Disentangling Factors of Variations Using Few Labels", "authors": "['Francesco Locatello', 'Michael Tschannen', 'Stefan Bauer', 'Gunnar R\u00e4tsch', 'Bernhard Sch\u00f6lkopf', 'Olivier Bachem']", "abstract": "Learning disentangled representations is considered a cornerstone problem in representation learning. Recently, Locatello et al. (2019) demonstrated that unsupervised disentanglement learning without inductive biases is theoretically impossible and that existing inductive biases and unsupervised methods do not allow to consistently learn disentangled representations. However, in many practical settings, one might have access to a limited amount of supervision, for example through manual labeling of (some) factors of variation in a few training examples. In this paper, we investigate the impact of such supervision on state-of-the-art disentanglement methods and perform a large scale study, training over 52000 models under well-defined and reproducible experimental conditions.  We observe that a small number of labeled examples (0.01--0.5% of the data set), with potentially imprecise and incomplete labels, is sufficient to perform model selection on state-of-the-art unsupervised models. Further, we investigate the benefit of incorporating supervision into the training process. Overall, we empirically validate that with little and imprecise supervision it is possible to reliably learn disentangled representations.", "pdf": "/pdf/dacac03f52b564ce8585074d3c0ffcdab7ef9f1e.pdf", "keywords": "[]", "id": "SygagpEKwB"}, {"number": "2498", "title": "A Gradient-Based Approach to Neural Networks Structure Learning", "authors": "['Amir Ali Moinfar', 'Amirkeivan Mohtashami', 'Mahdieh Soleymani', 'Ali Sharifi-Zarchi']", "abstract": "Designing the architecture of deep neural networks (DNNs) requires human expertise and is a cumbersome task. One approach to automatize this task has been considering DNN architecture parameters such as the number of layers, the number of neurons per layer, or the activation function of each layer as  hyper-parameters, and using an external method for optimizing it. Here we propose a novel neural network model, called Farfalle Neural Network, in which important architecture features such as the number of neurons in each layer and the wiring among the neurons are automatically learned during the training process. We show that the proposed model can replace a stack of dense layers, which is used as a part of many DNN architectures. It can achieve higher accuracy using significantly fewer parameters.  ", "pdf": "/pdf/a20d53b785d5a92a01826601ae781a5d20bb7cda.pdf", "keywords": "[]", "id": "Bye-sxHFwB"}, {"number": "1787", "title": "Model Based Reinforcement Learning for Atari", "authors": "['\u0141ukasz Kaiser', 'Mohammad Babaeizadeh', 'Piotr Mi\u0142os', 'B\u0142a\u017cej Osi\u0144ski', 'Roy H Campbell', 'Konrad Czechowski', 'Dumitru Erhan', 'Chelsea Finn', 'Piotr Kozakowski', 'Sergey Levine', 'Afroz Mohiuddin', 'Ryan Sepassi', 'George Tucker', 'Henryk Michalewski']", "abstract": "Model-free reinforcement learning (RL) can be used to learn effective policies for complex tasks, such as Atari games, even from image observations. However, this typically requires very large amounts of interaction -- substantially more, in fact, than a human would need to learn the same games. How can people learn so quickly? Part of the answer may be that people can learn how the game works and predict which actions will lead to desirable outcomes. In this paper, we explore how video prediction models can similarly enable agents to solve Atari games with fewer interactions than model-free methods. We describe Simulated Policy Learning (SimPLe), a complete model-based deep RL algorithm based on video prediction models and present a comparison of several model architectures, including a novel architecture that yields the best results in our setting. Our experiments evaluate SimPLe on a range of Atari games in low data regime of 100k interactions between the agent and the environment, which corresponds to two hours of real-time play. In most games SimPLe outperforms state-of-the-art model-free algorithms, in some games by over an order of magnitude.", "pdf": "/pdf/4f55ddc41b7b1bce40220c3b9577d8a60028a4cb.pdf", "keywords": "['reinforcement learning', 'model based rl', 'video prediction model', 'atari']", "id": "S1xCPJHtDB"}, {"number": "620", "title": "INSTANCE CROSS ENTROPY FOR DEEP METRIC LEARNING", "authors": "['Xinshao Wang', 'Elyor Kodirov', 'Yang Hua', 'Neil M. Robertson']", "abstract": "Loss functions play a crucial role in deep metric learning thus a variety of them have been proposed. Some supervise the learning process by pairwise or tripletwise similarity constraints while others take the advantage of structured similarity information among multiple data points. In this work, we approach deep metric learning from a novel perspective. We propose instance cross entropy (ICE) which measures the difference between an estimated instance-level matching distribution and its ground-truth one. ICE has three main appealing properties. Firstly, similar to categorical cross entropy (CCE), ICE has clear probabilistic interpretation and exploits structured semantic similarity information for learning supervision. Secondly, ICE is scalable to infinite training data as it learns on mini-batches iteratively and is independent of the training set size. Thirdly, motivated by our relative weight analysis, seamless sample reweighting is incorporated. It rescales samples gradients to control the differentiation degree over training examples instead of truncating them by sample mining. In addition to its simplicity and intuitiveness, extensive experiments on three real-world benchmarks demonstrate the superiority of ICE.", "pdf": "/pdf/40457401cfa8b248e2c81a59fda28f0daf87343d.pdf", "keywords": "['Deep Metric Learning', 'Instance Cross Entropy', 'Sample Mining/Weighting', 'Image Retrieval']", "id": "BJeguTEKDB"}, {"number": "2359", "title": "Finding Deep Local Optima Using Network Pruning", "authors": "['Yangzi Guo', 'Yiyuan She', 'Ying Nian Wu', 'Adrian Barbu']", "abstract": "Artificial neural networks (ANNs) are very popular nowadays and offer reliable solutions to many classification problems. However, training deep neural networks (DNN) is time-consuming due to the large number of parameters. Recent research indicates that these  DNNs might be over-parameterized and different solutions have been proposed to reduce the complexity both in the number of parameters and in the training time of the neural networks. Furthermore, some researchers argue that after reducing the neural network complexity via connection pruning, the remaining weights are irrelevant and retraining the sub-network would obtain a comparable accuracy with the original one. \nThis may hold true in most vision problems where we always enjoy a large number of training samples and research indicates that most local optima of the convolutional neural networks may be equivalent. However, in non-vision sparse datasets, especially with many irrelevant features where a standard neural network would overfit, this might not be the case and there might be many non-equivalent local optima. This paper presents empirical evidence for these statements and an empirical study of the learnability of neural networks (NNs) on some challenging non-linear real and simulated data with irrelevant variables. \nOur simulation experiments indicate that the cross-entropy loss function on XOR-like data has many local optima, and the number of local optima grows exponentially with the number of irrelevant variables. \nWe also introduce a connection pruning method to improve the capability of NNs to find a deep local minimum even when there are irrelevant variables. \nFurthermore, the performance of the discovered sparse sub-network degrades considerably either by retraining from scratch or the corresponding original initialization, due to the existence of many bad optima around. \nFinally, we will show that the performance of neural networks for real-world experiments on sparse datasets can be recovered or even improved by discovering a good sub-network architecture via connection pruning.", "pdf": "/pdf/b9fda564dbfa824e5fdd7fb8b8207fc683303fe1.pdf", "keywords": "['network pruning', 'non-convex optimization']", "id": "SyeHPgHFDr"}, {"number": "105", "title": "Model-free Learning Control of Nonlinear Stochastic Systems with Stability Guarantee", "authors": "['Minghao Han', 'Yuan Tian', 'Lixian Zhang', 'Jun Wang', 'Wei Pan']", "abstract": "Reinforcement learning (RL) offers a principled way to achieve the optimal cumulative performance index in discrete-time nonlinear stochastic systems, which are modeled as Markov decision processes. Its integration with deep learning techniques has promoted the field of deep RL with an impressive performance in complicated continuous control tasks. However, from a control-theoretic perspective, the first and most important property of a system to be guaranteed is stability. Unfortunately, stability is rarely assured in RL and remains an open question. In this paper, we propose a stability guaranteed RL framework which simultaneously learns a Lyapunov function along with the controller or policy, both of which are parameterized by deep neural networks, by borrowing the concept of Lyapunov function from control theory. Our framework can not only offer comparable or superior control performance over state-of-the-art RL algorithms, but also construct a Lyapunov function to validate the closed-loop stability. In the simulated experiments, our approach is evaluated on several well-known examples including classic CartPole balancing, 3-dimensional robot control and control of synthetic biology gene regulatory networks. Compared with RL algorithms without stability guarantee, our approach can enable the system to recover to the operating point when interfered by uncertainties such as unseen disturbances and system parametric variations to a certain extent. ", "pdf": "/pdf/38c6a17e84be962a2994c51873793ee04ebe4499.pdf", "keywords": "['Reinforcement learning', 'nonlinear stochastic system', 'Lyapunov']", "id": "SkeWc2EKPH"}, {"number": "1626", "title": "WORD SEQUENCE PREDICTION FOR AMHARIC LANGUAGE", "authors": "['Nuniyat Kifle', 'Ermias Abebe']", "abstract": "Word prediction is guessing what word comes after, based on some current information, and it is the main\nfocus of this study. Even though Amharic is used by a large number of populations, no significant work is\ndone on the topic. In this study, Amharic word sequence prediction model is developed using Machine\nlearning. We used statistical methods using Hidden Markov Model by incorporating detailed parts of speech\ntag and user profiling or adaptation. One of the needs for this research is to overcome the challenges on inflected languages. Word sequence prediction is a challenging task for inflected languages (Gustavii &Pettersson, 2003; Seyyed & Assi, 2005). These kinds of languages are morphologically rich and have enormous word forms, which is a word can\nhave different forms. As Amharic language is morphologically rich it shares the problem (Tessema,\n2014).This problem makes word prediction system much more difficult and results poor performance.\nPrevious researches used dictionary approach with no consideration of context information. Due to this\nreason, storing all forms in a dictionary wont solve the problem as in English and other less inflected\nlanguages. Therefore, we introduced two models; tags and words and linear interpolation that use parts of\nspeech tag information in addition to word n-grams in order to maximize the likelihood of syntactic\nappropriateness of the suggestions. The statistics included in the systems varies from single word\nfrequencies to parts-of-speech tag n-grams. We described a combined statistical and lexical word prediction\nsystem and developed Amharic language models of bigram and trigram for the training purpose. The overall\nstudy followed Design Science Research Methodology (DSRM).\n", "pdf": "/pdf/f3681de5c0c62b9e82d0e2b7a63d0fb49e2fd293.pdf", "keywords": "['Word prediction', 'POS', 'Statistical approach']", "id": "HkgqmyrYDH"}, {"number": "1716", "title": "Unsupervised domain adaptation with imputation", "authors": "['Matthieu Kirchmeyer', 'Patrick Gallinari', 'Alain Rakotomamonjy', 'Amin Mantrach']", "abstract": "Motivated by practical applications, we consider unsupervised domain adaptation for classification problems, in the presence of missing data in the target domain. More precisely, we focus on the case where there is a domain shift between source and target domains, while some components of the target data are systematically absent. We propose a way to impute non-stochastic missing data for a classification task by leveraging supervision from a complete source domain through domain adaptation. We introduce a single model performing joint domain adaptation, imputation and classification which is shown to perform well under various representative divergence families (H-divergence, Optimal Transport). We perform experiments on two families of datasets: a classical digit classification benchmark commonly used in domain adaptation papers and real world digital advertising datasets, on which we evaluate our models classification performance in an unsupervised setting. We analyze its behavior showing the benefit of explicitly imputing non-stochastic missing data jointly with domain adaptation.", "pdf": "/pdf/03ca5b14535e841ec2d9398c1af8a013816b5a59.pdf", "keywords": "['domain adaptation', 'imputation', 'missing data', 'advertising']", "id": "B1lgUkBFwr"}, {"number": "896", "title": "Training Neural Networks for and by Interpolation", "authors": "['Leonard Berrada', 'Andrew Zisserman', 'Pawan M. Kumar']", "abstract": "In modern supervised learning, many deep neural networks are able to interpolate the data: the empirical loss can be driven to near zero on all samples simultaneously. In this work, we explicitly exploit this interpolation property for the design of a new optimization algorithm for deep learning. Specifically, we use it to compute an adaptive learning-rate in closed form at each iteration. This results in the Adaptive Learning-rates for Interpolation with Gradients (ALI-G) algorithm. ALI-G retains the main advantage of SGD which is a low computational cost per iteration. But unlike SGD, the learning-rate of ALI-G uses a single constant hyper-parameter and does not require a decay schedule, which makes it considerably easier to tune. We provide convergence guarantees of ALI-G in the stochastic convex setting. Notably, all our convergence results tackle the realistic case where the interpolation property is satisfied up to some tolerance. We provide experiments on a variety of architectures and tasks: (i) learning a differentiable neural computer; (ii) training a wide residual network on the SVHN data set; (iii) training a Bi-LSTM on the SNLI data set; and (iv) training wide residual networks and densely connected networks on the CIFAR data sets. ALI-G produces state-of-the-art results among adaptive methods, and even yields comparable performance with SGD, which requires manually tuned learning-rate schedules. Furthermore, ALI-G is simple to implement in any standard deep learning framework and can be used as a drop-in replacement in existing code.", "pdf": "/pdf/f134558a175667f1bfb61244a540c8bfe386d168.pdf", "keywords": "['optimization', 'adaptive learning-rate', 'Polyak step-size', 'Newton-Raphson']", "id": "BJevJCVYvB"}, {"number": "1008", "title": "CLEVRER: Collision Events for Video Representation and Reasoning", "authors": "['Kexin Yi*', 'Chuang Gan*', 'Yunzhu Li', 'Pushmeet Kohli', 'Jiajun Wu', 'Antonio Torralba', 'Joshua B. Tenenbaum']", "abstract": "The ability to reason about temporal and causal events from videos lies at the core of human intelligence. Most video reasoning benchmarks, however, focus on pattern recognition from complex visual and language input, instead of on causal structure. We study the complementary problem, exploring the temporal and causal structures behind videos of objects with simple visual appearance. To this end, we introduce the CoLlision Events for Video REpresentation and Reasoning (CLEVRER) dataset, a  diagnostic video dataset for systematic evaluation of computational models on a wide range of reasoning tasks.  Motivated by the theory of human casual judgment, CLEVRER includes four types of question:  descriptive (e.g., what color), explanatory (whats responsible for), predictive (what will happen next), and counterfactual (what if).  We evaluate various state-of-the-art models for visual reasoning on our benchmark. While these models thrive on the perception-based task (descriptive), they perform poorly on the causal tasks (explanatory, predictive and counterfactual), suggesting that a principled approach for causal reasoning should incorporate the capability of both perceiving complex visual and language inputs, and understanding the underlying dynamics and causal relations. We also study an oracle model that explicitly combines these components via symbolic representations. ", "pdf": "/pdf/5c16bdbb2bb062be7c809cb259b10585a45dec5b.pdf", "keywords": "['Neuro-symbolic', 'Reasoning']", "id": "HkxYzANYDB"}, {"number": "2358", "title": "Adversarial Training Generalizes Data-dependent Spectral Norm Regularization", "authors": "['Kevin Roth', 'Yannic Kilcher', 'Thomas Hofmann']", "abstract": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks. Specifically, we present a data-dependent variant of spectral norm regularization and prove that it is equivalent to adversarial training based on a specific $\\ell_2$-norm constrained projected gradient ascent attack. This fundamental connection confirms the long-standing argument that a network's sensitivity to adversarial examples is tied to its spectral properties and hints at novel ways to robustify and defend against adversarial attacks. We provide extensive empirical evidence to support our theoretical results. ", "pdf": "/pdf/478cde394439b29ef1fe946667fd7a1a97d5198c.pdf", "keywords": "['Adversarial Robustness', 'Adversarial Training', 'Spectral Norm Regularization']", "id": "S1ervgHFwS"}, {"number": "174", "title": "HighRes-net: Multi-Frame Super-Resolution by Recursive Fusion", "authors": "['Michel Deudon', 'Alfredo Kalaitzis', 'Md Rifat Arefin', 'Israel Goytom', 'Zhichao Lin', 'Kris Sankaran', 'Vincent Michalski', 'Samira E Kahou', 'Julien Cornebise', 'Yoshua Bengio']", "abstract": "Generative deep learning has sparked a new wave of Super-Resolution (SR) algorithms that enhance single images with impressive aesthetic results, albeit with imaginary details. Multi-frame Super-Resolution (MFSR) offers a more grounded approach to the ill-posed problem, by conditioning on multiple low-resolution views. This is important for satellite monitoring of human impact on the planet -- from deforestation, to human rights violations -- that depend on reliable imagery. To this end, we present HighRes-net, the first deep learning approach to MFSR that learns its sub-tasks in an end-to-end fashion: (i) co-registration, (ii) fusion, (iii) up-sampling, and (iv) registration-at-the-loss. Co-registration of low-res views is learned implicitly through a reference-frame channel, with no explicit registration mechanism. We learn a global fusion operator that is applied recursively on an arbitrary number of low-res pairs. We introduce a registered loss, by learning to align the SR output to a ground-truth through ShiftNet. We show that by learning deep representations of multiple views, we can super-resolve low-resolution signals and enhance Earth observation data at scale. Our approach recently topped the European Space Agency's MFSR competition on real-world satellite imagery.", "pdf": "/pdf/1d6bd5153f19fca0feeb4290bf323b24c26adbfd.pdf", "keywords": "['multi-frame super-resolution', 'super-resolution', 'remote sensing', 'fusion', 'de-aliasing', 'deep learning', 'registration']", "id": "HJxJ2h4tPr"}, {"number": "53", "title": "Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data", "authors": "['Sergei Popov', 'Stanislav Morozov', 'Artem Babenko']", "abstract": "Nowadays, deep neural networks (DNNs) have become the main instrument for machine learning tasks within a wide range of domains, including vision, NLP, and speech. Meanwhile, in an important case of heterogenous tabular data, the advantage of DNNs over shallow counterparts remains questionable. In particular, there is no sufficient evidence that deep learning machinery allows constructing methods that outperform gradient boosting decision trees (GBDT), which are often the top choice for tabular problems. In this paper, we introduce Neural Oblivious Decision Ensembles (NODE), a new deep learning architecture, designed to work with any tabular data. In a nutshell, the proposed NODE architecture generalizes ensembles of oblivious decision trees, but benefits from both end-to-end gradient-based optimization and the power of multi-layer hierarchical representation learning. With an extensive experimental comparison to the leading GBDT packages on a large number of tabular datasets, we demonstrate the advantage of the proposed NODE architecture, which outperforms the competitors on most of the tasks. We open-source the PyTorch implementation of NODE and believe that it will become a universal framework for machine learning on tabular data.", "pdf": "/pdf/a232ed6c3759aed211ca949a7fe572d04605f653.pdf", "keywords": "['tabular data', 'architectures', 'DNN']", "id": "r1eiu2VtwH"}, {"number": "1166", "title": "Higher-Order Function Networks for Learning Composable 3D Object Representations", "authors": "['Eric Mitchell', 'Selim Engin', 'Volkan Isler', 'Daniel D Lee']", "abstract": "We present a new approach to 3D object representation where a neural network encodes the geometry of an object directly into the weights and biases of a second 'mapping' network. This mapping network can be used to reconstruct an object by applying its encoded transformation to points randomly sampled from a simple geometric space, such as the unit sphere. We study the effectiveness of our method through various experiments on subsets of the ShapeNet dataset. We find that the proposed approach can reconstruct encoded objects with accuracy equal to or exceeding state-of-the-art methods with orders of magnitude fewer parameters. Our smallest mapping network has only about 7000 parameters and shows reconstruction quality on par with state-of-the-art object decoder architectures with millions of parameters. Further experiments on feature mixing through the composition of learned functions show that the encoding captures a meaningful subspace of objects.", "pdf": "/pdf/aa1d65118055944102c9de56cbada2966f55de6f.pdf", "keywords": "['computer vision', '3d reconstruction', 'deep learning', 'representation learning']", "id": "HJgfDREKDB"}, {"number": "1372", "title": "Variational Autoencoders with Normalizing Flow Decoders", "authors": "['Rogan Morrow', 'Wei-Chen Chiu']", "abstract": "Recently proposed normalizing flow models such as Glow (Kingma & Dhariwal, 2018) have been shown to be able to generate high quality, high dimensional images with relatively fast sampling speed. Due to the inherently restrictive design of architecture , however, it is necessary that their model are excessively deep in order to achieve effective training. In this paper we propose to combine Glow model with an underlying variational autoencoder in order to counteract this issue. We demonstrate that such our proposed model is competitive with Glow in terms of image quality while requiring far less time for training. Additionally, our model achieves state-of-the-art FID score on CIFAR-10 for a likelihood-based model.", "pdf": "/pdf/d8e0df2b7afeaa076f0e448e960df6d5365069c9.pdf", "keywords": "[]", "id": "r1eh30NFwB"}, {"number": "1388", "title": "Blending Diverse Physical Priors with Neural Networks", "authors": "['Yunhao Ba', 'Guangyuan Zhao', 'Achuta Kadambi']", "abstract": "Rethinking physics in the era of deep learning is an increasingly important topic. This topic is special because, in addition to data, one can leverage a vast library of physical prior models (e.g. kinematics, fluid flow, etc) to perform more robust inference. The nascent sub-field of physics-based learning (PBL) studies this problem of blending neural networks with physical priors. While previous PBL algorithms have been applied successfully to specific tasks, it is hard to generalize existing PBL methods to a wide range of physics-based problems. Such generalization would require an architecture that can adapt to variations in the correctness of the physics, or in the quality of training data. No such architecture exists. In this paper, we aim to generalize PBL, by making a first attempt to bring neural architecture search (NAS) to the realm of PBL. We introduce a new method known as physics-based neural architecture search (PhysicsNAS) that is a top-performer across a diverse range of quality in the physical model and the dataset. ", "pdf": "/pdf/2e074d45af9069ab0550566426f22993b26dbc61.pdf", "keywords": "['Physics-based learning', 'Physics-aware learning']", "id": "HkeQ6ANYDB"}, {"number": "1521", "title": "Simple and Effective Regularization Methods for Training on Noisily Labeled Data with Generalization Guarantee", "authors": "['Wei Hu', 'Zhiyuan Li', 'Dingli Yu']", "abstract": "Over-parameterized deep neural networks trained by simple first-order methods are known to be able to fit any labeling of data. Such over-fitting ability hinders generalization when mislabeled training examples are present. On the other hand, simple regularization methods like early-stopping can often achieve highly nontrivial performance on clean test data in these scenarios, a phenomenon not theoretically understood. This paper proposes and analyzes two simple and intuitive regularization methods: (i) regularization by the distance between the network parameters to initialization, and (ii) adding a trainable auxiliary variable to the network output for each training example. Theoretically, we prove that gradient descent training with either of these two methods leads to a generalization guarantee on the clean data distribution despite being trained using noisy labels. Our generalization analysis relies on the connection between wide neural network and neural tangent kernel (NTK). The generalization bound is independent of the network size, and is comparable to the bound one can get when there is no label noise. Experimental results verify the effectiveness of these methods on noisily labeled datasets.", "pdf": "/pdf/907345259310ec754023a3696a33480febe41d0b.pdf", "keywords": "['deep learning theory', 'regularization', 'noisy labels']", "id": "Hke3gyHYwH"}, {"number": "10", "title": "Scoring-Aggregating-Planning: Learning task-agnostic priors from interactions and sparse rewards for zero-shot generalization", "authors": "['Huazhe Xu', 'Boyuan Chen', 'Yang Gao', 'Trevor Darrell']", "abstract": "Humans can learn task-agnostic priors from interactive experience and utilize the priors for novel tasks without any finetuning. In this paper, we propose Scoring-Aggregating-Planning (SAP), a framework that can learn task-agnostic semantics and dynamics priors from arbitrary quality interactions as well as the corresponding sparse rewards and then plan on unseen tasks in zero-shot condition. The framework finds a neural score function for local regional state and action pairs that can be aggregated to approximate the quality of a full trajectory; moreover, a dynamics model that is learned with self-supervision can be incorporated for planning. Many of previous works that leverage interactive data for policy learning either need massive on-policy environmental interactions or assume access to expert data while we can achieve a similar goal with pure off-policy imperfect data. Instantiating our framework results in a generalizable policy to unseen tasks. Experiments demonstrate that the proposed method can outperform baseline methods on a wide range of applications including gridworld, robotics tasks and video games.", "pdf": "/pdf/a86483704a793bacecf55a3183a94d366ff62e2f.pdf", "keywords": "['learning priors from exploration data', 'policy zero-shot generalization', 'reward shaping', 'model-based']", "id": "HyeuP2EtDB"}, {"number": "389", "title": "INFERENCE, PREDICTION, AND ENTROPY RATE OF CONTINUOUS-TIME, DISCRETE-EVENT PROCESSES", "authors": "['Sarah Marzen', 'James P. Crutchfield']", "abstract": "The inference of models, prediction of future symbols, and entropy rate estimation of discrete-time, discrete-event processes is well-worn ground. However, many time series are better conceptualized as continuous-time, discrete-event processes. Here, we provide new methods for inferring models, predicting future symbols, and estimating the entropy rate of continuous-time, discrete-event processes. The methods rely on an extension of Bayesian structural inference that takes advantage of neural networks universal approximation power. Based on experiments with simple synthetic data, these new methods seem to be competitive with state-of- the-art methods for prediction and entropy rate estimation as long as the correct model is inferred.", "pdf": "/pdf/1df7f7913ba29e9a58ab4edd867cd69590b4f2a6.pdf", "keywords": "['continuous-time prediction']", "id": "B1gn-pEKwH"}, {"number": "1492", "title": "Polylogarithmic width suffices for gradient descent to achieve arbitrarily small test error with shallow ReLU networks", "authors": "['Ziwei Ji', 'Matus Telgarsky']", "abstract": "Recent theoretical work has guaranteed that overparameterized networks trained by gradient descent achieve arbitrarily low training error, and sometimes even low test error.\nThe required width, however, is always polynomial in at least one of the sample size $n$, the (inverse) target error $1/\\epsilon$, and the (inverse) failure probability $1/\\delta$. \nThis work shows that $\\widetilde{\\Theta}(1/\\epsilon)$ iterations of gradient descent with $\\widetilde{\\Omega}(1/\\epsilon^2)$ training examples on two-layer ReLU networks of any width exceeding $\\textrm{polylog}(n,1/\\epsilon,1/\\delta)$ suffice to achieve a test misclassification error of $\\epsilon$. \nWe also prove that stochastic gradient descent can achieve $\\epsilon$ test error with polylogarithmic width and $\\widetilde{\\Theta}(1/\\epsilon)$ samples. \nThe analysis relies upon the separation margin of the limiting kernel, which is guaranteed positive, can distinguish between true labels and random labels, and can give a tight sample-complexity analysis in the infinite-width setting.", "pdf": "/pdf/cca1e522e843ed364400ff78580e09c14ed194d1.pdf", "keywords": "['neural tangent kernel', 'polylogarithmic width', 'test error', 'gradient descent', 'classification']", "id": "HygegyrYwH"}, {"number": "1067", "title": "Chameleon: Adaptive Code Optimization for Expedited Deep Neural Network Compilation", "authors": "['Byung Hoon Ahn', 'Prannoy Pilligundla', 'Amir Yazdanbakhsh', 'Hadi Esmaeilzadeh']", "abstract": "Achieving faster execution with shorter compilation time can foster further diversity and innovation in neural networks. However, the current paradigm of executing neural networks either relies on hand-optimized libraries, traditional compilation heuristics, or very recently genetic algorithms and other stochastic methods. These methods suffer from frequent costly hardware measurements rendering them not only too time consuming but also suboptimal. As such, we devise a solution that can learn to quickly adapt to a previously unseen design space for code optimization, both accelerating the search and improving the output performance. This solution dubbed Chameleon leverages reinforcement learning whose solution takes fewer steps to converge, and develops an adaptive sampling algorithm that not only focuses on the costly samples (real hardware measurements) on representative points but also uses a domain-knowledge inspired logic to improve the samples itself. Experimentation with real hardware shows that Chameleon provides 4.45x speed up in optimization time over AutoTVM, while also improving inference time of the modern deep networks by 5.6%.", "pdf": "/pdf/6089270ff1b85869bd7113cf6fa1687fa51295b3.pdf", "keywords": "['Reinforcement Learning', 'Learning to Optimize', 'Combinatorial Optimization', 'Compilers', 'Code Optimization', 'Neural Networks', 'ML for Systems', 'Learning for Systems']", "id": "rygG4AVFvH"}, {"number": "2469", "title": "DiffTaichi: Differentiable Programming for Physical Simulation", "authors": "['Yuanming Hu', 'Luke Anderson', 'Tzu-Mao Li', 'Qi Sun', 'Nathan Carr', 'Jonathan Ragan-Kelley', 'Fredo Durand']", "abstract": "We present DiffTaichi, a new differentiable programming language tailored for building high-performance differentiable physical simulators. Based on an imperative programming language, DiffTaichi generates gradients of simulation steps using source code transformations that preserve arithmetic intensity and parallelism. A light-weight tape is used to record the whole simulation program structure and replay the gradient kernels in a reversed order, for end-to-end backpropagation.\nWe demonstrate the performance and productivity of our language in gradient-based learning and optimization tasks on 10 different physical simulators. For example, a differentiable elastic object simulator written in our language is 4.2x shorter than the hand-engineered CUDA version yet runs as fast, and is 188x faster than the TensorFlow implementation.\nUsing our differentiable programs, neural network controllers are typically optimized within only tens of iterations.", "pdf": "/pdf/6d9976c7113eb4ad907e38be6d4797388ff35a3b.pdf", "keywords": "['Differentiable programming', 'robotics', 'optimal control', 'physical simulation', 'machine learning system']", "id": "B1eB5xSFvr"}, {"number": "1273", "title": "Unaligned Image-to-Sequence Transformation with Loop Consistency", "authors": "['Siyang Wang', 'Justin Lazarow', 'Kwonjoon Lee', 'Zhuowen Tu']", "abstract": "We tackle the problem of modeling sequential visual phenomena. Given examples of a phenomena that can be divided into discrete time steps, we aim to take an input from any such time and realize this input at all other time steps in the sequence. Furthermore, we aim to do this \\textit{without} ground-truth aligned sequences --- avoiding the difficulties needed for gathering aligned data. This generalizes the unpaired image-to-image problem from generating pairs to generating sequences. We extend cycle consistency to \\textit{loop consistency} and alleviate difficulties associated with learning in the resulting long chains of computation. We show competitive results compared to existing image-to-image techniques when modeling several different data sets including the Earth's seasons and aging of human faces.", "pdf": "/pdf/fb85101445593cfec1d43633ba3d178869ce4e38.pdf", "keywords": "[]", "id": "H1ebc0VYvH"}, {"number": "1298", "title": "RNNs Incrementally Evolving on an Equilibrium Manifold: A Panacea for Vanishing and Exploding Gradients?", "authors": "['Anil Kag', 'Ziming Zhang', 'Venkatesh Saligrama']", "abstract": "Recurrent neural networks (RNNs) are particularly well-suited for modeling long-term dependencies in sequential data, but are notoriously hard to train because the error backpropagated in time either vanishes or explodes at an exponential rate. While a number of works attempt to mitigate this effect through gated recurrent units, skip-connections, parametric constraints and design choices, we propose a novel incremental RNN (iRNN), where hidden state vectors keep track of incremental changes, and as such approximate state-vector increments of Rosenblatt's (1962) continuous-time RNNs. iRNN exhibits identity gradients and is able to account for long-term dependencies (LTD). We show that our method is computationally efficient overcoming overheads of many existing methods that attempt to improve RNN training, while suffering no performance degradation. We demonstrate the utility of our approach with extensive experiments and show competitive performance against standard LSTMs on LTD and other non-LTD tasks.\n", "pdf": "/pdf/34194213dd8d50a2f1eef0ece3c53bfdefd05845.pdf", "keywords": "['novel recurrent neural architectures', 'learning representations of outputs or states']", "id": "HylpqA4FwS"}, {"number": "759", "title": "Temporal-difference learning for nonlinear value function approximation in the lazy training regime", "authors": "['Andrea Agazzi', 'Jianfeng Lu']", "abstract": "We discuss the approximation of the value function for infinite-horizon discounted Markov Reward Processes (MRP) with nonlinear functions trained with the Temporal-Difference (TD) learning algorithm. We consider this problem under a certain scaling of the approximating function, leading to a regime called lazy training. In this regime the parameters of the model vary only slightly during the learning process, a feature that has recently been observed in the training of neural networks, where the scaling we study arises naturally, implicit in the initialization of their parameters.  Both in the under- and over-parametrized frameworks, we prove exponential convergence to local, respectively global minimizers of the above algorithm in the lazy training regime. We then give examples of such convergence results in the case of models that diverge if trained with non-lazy TD learning, and in the case of neural networks.", "pdf": "/pdf/d70eeb064e9ccb14d62940c9762a7ed170c09d01.pdf", "keywords": "['deep reinforcement learning', 'function approximation', 'temporal-difference', 'lazy training']", "id": "HJghoa4YDB"}, {"number": "439", "title": "Fast Linear Interpolation for Piecewise-Linear Functions, GAMs, and Deep Lattice Networks", "authors": "['Nathan Zhang', 'Kevin Canini', 'Sean Silva', 'and Maya R. Gupta']", "abstract": "We present fast implementations of linear interpolation operators for both piecewise linear functions and multi-dimensional look-up tables. We use a compiler-based solution (using MLIR) for accelerating this family of workloads. On real-world multi-layer lattice models and a standard CPU, we show these strategies deliver $5-10\\times$ faster runtimes compared to a C++ interpreter implementation that uses prior techniques, producing runtimes that are 1000s of times faster than TensorFlow 2.0 for single evaluations.", "pdf": "/pdf/51bd03a213e61d6acf7fd571fa8f430744f81ee4.pdf", "keywords": "['hardware', 'compiler', 'MLIR', 'runtime', 'CPU', 'interpolation']", "id": "H1e-X64FDB"}, {"number": "2378", "title": "End to End Trainable Active Contours via Differentiable Rendering", "authors": "['Shir Gur', 'Tal Shaharabany', 'Lior Wolf']", "abstract": "We present an image segmentation method that iteratively evolves a polygon. At each iteration, the vertices of the polygon are displaced based on the local value of a 2D shift map that is inferred from the input image via an encoder-decoder architecture. The main training loss that is used is the difference between the polygon shape and the ground truth segmentation mask. The network employs a neural renderer to create the polygon from its vertices, making the process fully differentiable. We demonstrate that our method outperforms the state of the art segmentation networks and deep active contour solutions in a variety of benchmarks, including medical imaging and aerial images.", "pdf": "/pdf/8fd896acc91bd1f06a713396633ab37e62e6dd46.pdf", "keywords": "[]", "id": "rkxawlHKDr"}, {"number": "2495", "title": "PROVABLY BENEFITS OF DEEP HIERARCHICAL RL", "authors": "['Zeyu Jia', 'Simon S. Du', 'Ruosong Wang', 'Mengdi Wang', 'Lin F. Yang']", "abstract": "Modern complex sequential decision-making problem often both low-level policy and high-level planning. Deep hierarchical reinforcement learning (Deep HRL) admits multi-layer abstractions which naturally model the policy in a hierarchical manner, and it is believed that deep HRL can reduce the sample complexity compared to the standard RL frameworks. We initiate the study of rigorously characterizing the complexity of Deep HRL. We present a model-based optimistic algorithm which demonstrates that the complexity of learning a near-optimal policy for deep HRL scales with the sum of number of states at each abstraction layer whereas standard RL scales with the product of number of states at each abstraction layer. Our algorithm achieves this goal by using the fact that distinct high-level states have similar low-level structures, which allows an efficient information exploitation and thus experiences from different high-level state-action pairs can be generalized to unseen state-actions. Overall, our result shows an exponential improvement using Deep HRL comparing to standard RL framework.", "pdf": "/pdf/c8dc175c6cfa31a0343171321b61d72657a5cfa0.pdf", "keywords": "['hierarchical model', 'reinforcement learning', 'low regret', 'online learning', 'tabular reinforcement learning']", "id": "ByxloeHFPS"}, {"number": "1545", "title": "Unsupervised Representation Learning by Predicting Random Distances", "authors": "['Hu Wang', 'Guansong Pang', 'Chunhua Shen', 'Congbo Ma']", "abstract": "Deep neural networks have gained tremendous success in a broad range of machine learning tasks due to its remarkable capability to learn semantic-rich features from high-dimensional data. However, they often require large-scale labelled data to successfully learn such features, which significantly hinders their adaption into unsupervised learning tasks, such as anomaly detection and clustering, and limits their applications into critical domains where obtaining massive labelled data is prohibitively expensive. To enable downstream unsupervised learning on those domains, in this work we propose to learn features without using any labelled data by training neural networks to predict data distances in a randomly projected space. Random mapping is a highly efficient yet theoretical proven approach to obtain approximately preserved distances. To well predict these random distances, the representation learner is optimised to learn class structures that are implicitly embedded in the randomly projected space. Experimental results on 19 real-world datasets show our learned representations substantially outperform state-of-the-art competing methods in both anomaly detection and clustering tasks.", "pdf": "/pdf/4f6a753f5cef654e9ea6f5afbde831b6872943de.pdf", "keywords": "['representation learning', 'unsupervised learning', 'anomaly detection', 'clustering']", "id": "rkgIW1HKPB"}, {"number": "1289", "title": "Collapsed amortized variational inference for switching nonlinear dynamical systems", "authors": "['Zhe Dong', 'Bryan A. Seybold', 'Kevin P. Murphy', 'Hung H. Bui']", "abstract": "We propose an efficient inference method for switching nonlinear dynamical systems. The key idea is to learn an inference network which can be used as a proposal distribution for the continuous latent variables, while performing exact marginalization of the discrete latent variables. This allows us to use the reparameterization trick, and apply end-to-end training with SGD. We show that this method can successfully segment time series data (including videos) into meaningful 'regimes', due to the use of piece-wise nonlinear dynamics.", "pdf": "/pdf/8ff4876f3b6c797a479de48e232ebffed7280748.pdf", "keywords": "[]", "id": "BkxdqA4tvB"}, {"number": "1820", "title": "NoiGAN: NOISE AWARE KNOWLEDGE GRAPH EMBEDDING WITH GAN", "authors": "['Kewei Cheng', 'Yikai Zhu', 'Ming Zhang', 'Yizhou Sun']", "abstract": "Knowledge graph has gained increasing attention in recent years for its successful applications of numerous tasks. Despite the rapid growth of knowledge construction, knowledge graphs still suffer from severe incompletion and inevitably involve various kinds of errors. Several attempts have been made to complete knowledge graph as well as to detect noise. However, none of them considers unifying these two tasks even though they are inter-dependent and can mutually boost the performance of each other. In this paper, we proposed to jointly combine these two tasks with a unified Generative Adversarial Networks (GAN) framework to learn noise-aware knowledge graph embedding. Extensive experiments have demonstrated that our approach is superior to existing state-of-the-art algorithms both in regard to knowledge graph completion and error detection. ", "pdf": "/pdf/af2dc238fa53b6282ee3b82a85719e6457d01204.pdf", "keywords": "['Knowledge graph embedding', 'Noise aware']", "id": "rkgTdkrtPH"}, {"number": "77", "title": "DeepHoyer: Learning Sparser Neural Network with Differentiable Scale-Invariant Sparsity Measures", "authors": "['Huanrui Yang', 'Wei Wen', 'Hai Li']", "abstract": "In seeking for sparse and efficient neural network models, many previous works investigated on enforcing L1 or L0 regularizers to encourage weight sparsity during training. The L0 regularizer measures the parameter sparsity directly and is invariant to the scaling of parameter values. But it cannot provide useful gradients and therefore requires complex optimization techniques. The L1 regularizer is almost everywhere differentiable and can be easily optimized with gradient descent. Yet it is not scale-invariant and causes the same shrinking rate to all parameters, which is inefficient in increasing sparsity. Inspired by the Hoyer measure (the ratio between L1 and L2 norms) used in traditional compressed sensing problems, we present DeepHoyer, a set of sparsity-inducing regularizers that are both differentiable almost everywhere and scale-invariant. Our experiments show that enforcing DeepHoyer regularizers can produce even sparser neural network models than previous works, under the same accuracy level. We also show that DeepHoyer can be applied to both element-wise and structural pruning.", "pdf": "/pdf/1d5e3997e449727a4e2d2c3559ef81ec5d1b8fc0.pdf", "keywords": "['Deep neural network', 'Sparsity inducing regularizer', 'Model compression']", "id": "rylBK34FDS"}, {"number": "872", "title": "Neural-Guided Symbolic Regression with Asymptotic Constraints", "authors": "['Li Li', 'Minjie Fan', 'Rishabh Singh', 'Patrick Riley']", "abstract": "Symbolic regression is a type of discrete optimization problem that involves searching expressions that fit given data points. In many cases, other mathematical constraints about the unknown expression not only provide more information beyond just values at some inputs, but also effectively constrain the search space. We identify the asymptotic constraints of leading polynomial powers as the function approaches 0 and infinity as useful constraints and create a system to use them for symbolic regression. The first part of the system is a conditional expression generating neural network which preferentially generates expressions with the desired leading powers, producing novel expressions outside the training domain. The second part, which we call Neural-Guided Monte Carlo Tree Search, uses the network during a search to find an expression that conforms to a set of data points and desired leading powers. Lastly, we provide an extensive experimental validation on thousands of target expressions showing the efficacy of our system compared to exiting methods for finding unknown functions outside of the training set.", "pdf": "/pdf/ba1b1f678f79eed79b49ecff6a6e42d7db8265fc.pdf", "keywords": "['symbolic regression', 'program synthesis', 'monte carlo tree search']", "id": "S1gTAp4FDB"}, {"number": "2119", "title": "City Metro Network Expansion with Reinforcement Learning", "authors": "['Yu Wei', 'Minjia Mao', 'Xi Zhao', 'Jianhua Zou']", "abstract": "This paper presents a method to solve the city metro network expansion problem using reinforcement learning (RL). In this method, we formulate the metro expansion as a process of sequential station selection, and design feasibility rules based on the selected station sequence to ensure the reasonable connection patterns of metro line. Following this formulation, we train an actor critic model to design the next metro line. The actor is a seq2seq network with attention mechanism to generate the parameterized policy which is the probability distribution over feasible stations. The critic is used to estimate the expected reward, which is determined by the output station sequences generated by the actor during training, in order to reduce the training variance. The learning procedure only requires the reward calculation, thus our general method can be extended to multi-factor cases easily. Considering origin-destination (OD) trips and social equity, we expand the current metro network in Xi'an, China, based on the real mobility information of 24,770,715 mobile phone users in the whole city. The results demonstrate the effectiveness of our method. ", "pdf": "/pdf/58ab3c4b5acb4c2fb1218f1a5d4c9333e165c677.pdf", "keywords": "[]", "id": "SJxAlgrYDr"}, {"number": "2287", "title": "VIMPNN: A physics informed neural network for estimating potential energies of out-of-equilibrium systems", "authors": "['Jay Morgan', 'Adeline Paiement', 'Christian Klinke']", "abstract": "Simulation of molecular and crystal systems enables insight into interesting chemical properties that benefit processes ranging from drug discovery to material synthesis. However these simulations can be computationally expensive and time consuming despite the approximations through Density Functional Theory (DFT). We propose the Valence Interaction Message Passing Neural Network (VIMPNN) to approximate DFT's ground-state energy calculations. VIMPNN integrates physics prior knowledge such as the existence of different interatomic bounds to estimate more accurate energies. Furthermore, while many previous machine learning methods consider only stable systems, our proposed method is demonstrated on unstable systems at different atomic distances. VIMPNN predictions can be used to determine the stable configurations of systems, i.e. stable distance for atoms -- a necessary step for the future simulation of crystal growth for example. Our method is extensively evaluated on a augmented version of the QM9 dataset that includes unstable molecules, as well as a new dataset of infinite- and finite-size crystals, and is compared with the Message Passing Neural Network (MPNN). VIMPNN has comparable accuracy with DFT, while allowing for 5 orders of magnitude in computational speed up compared to DFT simulations, and produces more accurate and informative potential energy curves than MPNN for estimating stable configurations.", "pdf": "/pdf/af83d7aeaad5e7d828c6e74f1684e4ff6ebd7c87.pdf", "keywords": "['neural network', 'chemical energy estimation', 'density functional theory']", "id": "HJl8SgHtwr"}, {"number": "2508", "title": "Deep Evidential Uncertainty", "authors": "['Alexander Amini', 'Wilko Schwarting', 'Ava Soleimany', 'Daniela Rus']", "abstract": "Deterministic neural networks (NNs) are increasingly being deployed in safety critical domains, where calibrated, robust and efficient measures of uncertainty are crucial. While it is possible to train regression networks to output the parameters of a probability distribution by maximizing a Gaussian likelihood function, the resulting model remains oblivious to the underlying confidence of its predictions. In this paper, we propose a novel method for training deterministic NNs to not only estimate the desired target but also the associated evidence in support of that target. We accomplish this by  placing evidential priors over our original Gaussian likelihood function and training our NN to infer the hyperparameters of our evidential distribution. We impose priors during training such that the model is penalized when its predicted evidence is not aligned with the correct output. Thus the model estimates not only the probabilistic mean and variance of our target but also the underlying uncertainty associated with each of those parameters. We observe that our evidential regression method learns well-calibrated measures of uncertainty on various benchmarks, scales to complex computer vision tasks, and is robust to adversarial input perturbations.\n", "pdf": "/pdf/b0dd6c91b99250caa18315b28e61ded20499c327.pdf", "keywords": "['Evidential deep learning', 'Uncertainty estimation', 'Epistemic uncertainty']", "id": "S1eSoeSYwr"}, {"number": "485", "title": "Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep Reinforcement Learning", "authors": "['Yufei Wang*', 'Ziju Shen*', 'Zichao Long', 'Bin Dong']", "abstract": "Conservation laws are considered to be fundamental laws of nature. It has broad application in many fields including physics, chemistry, biology, geology, and engineering. Solving the differential equations associated with conservation laws is a major branch in computational mathematics. Recent success of machine learning, especially deep learning, in areas such as computer vision and natural language processing, has attracted a lot of attention from the community of computational mathematics and inspired many intriguing works in combining machine learning with traditional methods. In this paper, we are the first to explore the possibility and benefit of solving nonlinear conservation laws using deep reinforcement learning. As a proof of concept, we focus on 1-dimensional scalar conservation laws. We deploy the machinery of deep reinforcement learning to train a policy network that can decide on how the numerical solutions should be approximated in a sequential and spatial-temporal adaptive manner. We will show that the problem of solving conservation laws can be naturally viewed as a sequential decision making process and the numerical schemes learned in such a way can easily enforce long-term accuracy. \nFurthermore, the learned policy network is carefully designed to determine a good local discrete approximation based on the current state of the solution, which essentially makes the proposed method a meta-learning approach.\nIn other words, the proposed method is capable of learning how to discretize for a given situation mimicking human experts. Finally, we will provide details on how the policy network is trained, how well it performs compared with some state-of-the-art numerical solvers such as WENO schemes, and how well it generalizes. Our code is released anomynously at \\url{https://github.com/qwerlanksdf/L2D}.", "pdf": "/pdf/400c18d81359004c254bad433bc535d8fdbe2e73.pdf", "keywords": "['Numerical Methods', 'Conservation Laws', 'Reinforcement Learning']", "id": "rygBVTVFPB"}, {"number": "1182", "title": "Symplectic Recurrent Neural Networks", "authors": "['Zhengdao Chen', 'Jianyu Zhang', 'Martin Arjovsky', 'L\u00e9on Bottou']", "abstract": "We propose Symplectic Recurrent Neural Networks (SRNNs) as learning algorithms that capture the dynamics of physical systems from observed trajectories. SRNNs model the Hamiltonian function of the system by a neural networks, and leverage symplectic integration, multiple-step training and initial state optimization to address the challenging numerical issues associated with Hamiltonian systems. We show SRNNs succeed reliably on complex and noisy Hamiltonian systems. Finally, we show how to augment the SRNN integration scheme in order to handle stiff dynamical systems such as bouncing billiards.", "pdf": "/pdf/6f092e9b2fa82cd15223dc2a3ac34b60a7deca8c.pdf", "keywords": "['Hamiltonian systems', 'learning physical laws', 'symplectic integrators', 'recurrent neural networks', 'inverse problems']", "id": "BkgYPREtPr"}, {"number": "1057", "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations", "authors": "['Zhenzhong Lan', 'Mingda Chen', 'Sebastian Goodman', 'Kevin Gimpel', 'Piyush Sharma', 'Radu Soricut']", "abstract": "Increasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations and longer training times. To address these problems,  we present two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT~\\citep{devlin2018bert}. Comprehensive empirical evidence shows that our proposed methods lead to models that scale much better compared to the original BERT. We also use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentence inputs. As a result, our best model establishes new state-of-the-art results on the GLUE, RACE, and \\squad benchmarks while having fewer parameters compared to BERT-large. The code and the pretrained models are available at https://github.com/google-research/ALBERT.", "pdf": "/pdf/ce1860d9372b46ab2700549349420cc19125d478.pdf", "keywords": "['Natural Language Processing', 'BERT', 'Representation Learning']", "id": "H1eA7AEtvS"}, {"number": "1515", "title": "Black-box Off-policy Estimation for Infinite-Horizon Reinforcement Learning", "authors": "['Ali Mousavi', 'Lihong Li', 'Qiang Liu', 'Denny Zhou']", "abstract": "Off-policy estimation for long-horizon problems is important in many real-life applications such as healthcare and robotics, where high-fidelity simulators may not be available and on-policy evaluation is expensive or impossible.  Recently, \\citet{liu18breaking} proposed an approach that avoids the curse of horizon suffered by typical importance-sampling-based methods. While showing promising results, this approach is limited in practice as it requires data being collected by a known behavior policy. In this work, we propose a novel approach that eliminates such limitations. In particular, we formulate the problem as solving for the fixed point of a 'backward flow' operator and show that the fixed point solution gives the desired importance ratios of stationary distributions between the target and behavior policies.  We analyze its asymptotic consistency and finite-sample\ngeneralization. Experiments on benchmarks verify the effectiveness of our proposed approach.\n", "pdf": "/pdf/70159d307dae110203ef877556fc5534c81b0eaa.pdf", "keywords": "['reinforcement learning', 'off-policy estimation', 'importance sampling', 'propensity score']", "id": "S1ltg1rFDS"}, {"number": "542", "title": "Prune or quantize? Strategy for Pareto-optimally low-cost and accurate CNN", "authors": "['Kengo Nakata', 'Daisuke Miyashita', 'Asuka Maki', 'Fumihiko Tachibana', 'Shinichi Sasaki', 'Jun Deguchi']", "abstract": "Pruning and quantization are typical approaches to reduce the computational cost of CNN inference. Although the idea to combine them together seems natural, it is being unexpectedly difficult to figure out the resultant effect of the combination unless measuring the performance on a certain hardware which a user is going to use. This is because the benefits of pruning and quantization strongly depend on the hardware architecture where the model is executed. For example, a CPU-like architecture without any parallelization may fully exploit the reduction of computations by unstructured pruning for speeding up, but a GPU-like massive parallel architecture would not. Besides, there have been emerging proposals of novel hardware architectures such as one supporting variable bit precision quantization. From an engineering viewpoint, optimization for each hardware architecture is useful and important in practice, but this is quite a brute-force approach. Therefore, in this paper, we first propose hardware-agnostic metric to measure the computational cost. And using the metric, we demonstrate that Pareto-optimal performance, where the best accuracy is obtained at a given computational cost, is achieved when a slim model with smaller number of parameters is quantized moderately rather than a fat model with huge number of parameters is quantized to extremely low bit precision such as binary or ternary. Furthermore, we empirically found the possible quantitative relation between the proposed metric and the signal to noise ratio during SGD training, by which the information obtained during SGD training provides the optimal policy of quantization and pruning. We show the Pareto frontier is improved by 4 times in post-training quantization scenario based on these findings. These findings are available not only to improve the Pareto frontier for accuracy vs. computational cost, but also give us some new insights on deep neural network.", "pdf": "/pdf/739e3925990713d557e2dbf1739383585bdf0c7c.pdf", "keywords": "['CNN', 'Quantization', 'Pruning', 'Accelerator', 'Computational cost']", "id": "HkxAS6VFDB"}, {"number": "755", "title": "Option Discovery using Deep Skill Chaining", "authors": "['Akhil Bagaria', 'George Konidaris']", "abstract": "Autonomously discovering temporally extended actions, or skills, is a longstanding goal of hierarchical reinforcement learning. We propose a new algorithm that combines skill chaining with deep neural networks to autonomously discover skills in high-dimensional, continuous domains. The resulting algorithm, deep skill chaining, constructs skills with the property that executing one enables the agent to execute another. We demonstrate that deep skill chaining significantly outperforms both non-hierarchical agents and other state-of-the-art skill discovery techniques in challenging continuous control tasks.", "pdf": "/pdf/2a79d71c9829eea5736920f59bb682c1090ab82b.pdf", "keywords": "['Hierarchical Reinforcement Learning', 'Reinforcement Learning', 'Skill Discovery', 'Deep Learning', 'Deep Reinforcement Learning']", "id": "B1gqipNYwH"}, {"number": "2097", "title": "Neural Arithmetic Unit by reusing many small pre-trained networks", "authors": "['Ammar Ahmad', 'Oneeb Babar', 'Murtaza Taj']", "abstract": "We propose a solution for evaluation of mathematical expression. However, instead of designing a single end-to-end model we propose a Lego bricks style architecture. In this architecture instead of training a complex end-to-end neural network, many small networks can be trained independently each accomplishing one specific operation and acting a single lego brick. More difficult or complex task can then be solved using a combination of these smaller network. In this work we first identify 8 fundamental operations that are commonly used to solve arithmetic operations (such as 1 digit multiplication, addition, subtraction, sign calculator etc). These fundamental operations are then learned using simple feed forward neural networks. We then shows that different operations can be designed simply by reusing these smaller networks. As an example we reuse these smaller networks to develop larger and a more complex network to solve n-digit multiplication, n-digit division, and cross product. This bottom-up strategy not only introduces reusability, we also show that it allows to generalize for computations involving n-digits and we show results for up to 7 digit numbers. Unlike existing methods, our solution also generalizes for both positive as well as negative numbers.", "pdf": "/pdf/fdbea97f07135cd8a74697b40863f2f77a52bbab.pdf", "keywords": "['NALU', 'feed forward NN']", "id": "HyerxgHYvH"}, {"number": "1955", "title": "Reducing Computation in Recurrent Networks by Selectively Updating State Neurons", "authors": "['Thomas Hartvigsen', 'Cansu Sen', 'Xiangnan Kong', 'Elke Rundensteiner']", "abstract": "Recurrent Neural Networks (RNN) are the state-of-the-art approach to sequential learning. However, standard RNNs use the same amount of computation at each timestep, regardless of the input data. As a result, even for high-dimensional hidden states, all dimensions are updated at each timestep regardless of the recurrent memory cell. Reducing this rigid assumption could allow for models with large hidden states to perform inference more quickly. Intuitively, not all hidden state dimensions need to be recomputed from scratch at each timestep. Thus, recent methods have begun studying this problem by imposing mainly a priori-determined patterns for updating the state. In contrast, we now design a fully-learned approach, SA-RNN, that augments any RNN by predicting discrete update patterns at the fine granularity of independent hidden state dimensions through the parameterization of a distribution of update-likelihoods driven entirely by the input data. We achieve this without imposing assumptions on the structure of the update pattern. Better yet, our method adapts the update patterns online, allowing different dimensions to be updated conditional to the input. To learn which to update, the model solves a multi-objective optimization problem, maximizing accuracy while minimizing the number of updates based on a unified control. Using publicly-available datasets we demonstrate that our method consistently achieves higher accuracy with fewer updates compared to state-of-the-art alternatives. Additionally, our method can be directly applied to a wide variety of models containing RNN architectures.", "pdf": "/pdf/08cf4380ea9c107d75980378e8b7059b3bb275e3.pdf", "keywords": "['recurrent neural networks', 'conditional computation', 'representation learning']", "id": "SkeP3yBFDS"}, {"number": "653", "title": "A NEW POINTWISE CONVOLUTION IN DEEP NEURAL NETWORKS THROUGH EXTREMELY FAST AND NON PARAMETRIC TRANSFORMS", "authors": "['Joonhyun Jeong', 'Sung-Ho Bae']", "abstract": "    Some conventional transforms such as Discrete Walsh-Hadamard Transform (DWHT) and Discrete Cosine Transform (DCT) have been widely used as feature extractors in image processing but rarely applied in neural networks. However, we found that these conventional transforms have the ability to capture the cross-channel correlations without any learnable parameters in DNNs. This paper firstly proposes to apply conventional transforms on pointwise convolution, showing that such transforms significantly reduce the computational complexity of neural networks without accuracy performance degradation. Especially for DWHT, it requires no floating point multiplications but only additions and subtractions, which can considerably reduce computation overheads. In addition, its fast algorithm further reduces complexity of floating point addition from O(n^2) to O(nlog n). These non-parametric and low computational properties construct extremely efficient networks in the number parameters and operations, enjoying accuracy gain. Our proposed DWHT-based model gained 1.49% accuracy increase with 79.4% reduced parameters and 48.4% reduced FLOPs compared with its baseline model (MoblieNet-V1) on the CIFAR 100 dataset.", "pdf": "/pdf/4fbb3e8b7b61fb95f7a5b15d112b579833a9ab4c.pdf", "keywords": "['Pointwise Convolution', 'Discrete Walsh-Hadamard Transform', 'Discrete Cosine-Transform']", "id": "H1l0O6EYDH"}, {"number": "939", "title": "Semi-Supervised Generative Modeling for Controllable Speech Synthesis", "authors": "['Raza Habib', 'Soroosh Mariooryad', 'Matt Shannon', 'Eric Battenberg', 'RJ Skerry-Ryan', 'Daisy Stanton', 'David Kao', 'Tom Bagby']", "abstract": "We present a novel generative model that combines state-of-the-art neural text- to-speech (TTS) with semi-supervised probabilistic latent variable models. By providing partial supervision to some of the latent variables, we are able to force them to take on consistent and interpretable purposes, which previously hasnt been possible with purely unsupervised methods. We demonstrate that our model is able to reliably discover and control important but rarely labelled attributes of speech, such as affect and speaking rate, with as little as 1% (30 minutes) supervision. Even at such low supervision levels we do not observe a degradation of synthesis quality compared to a state-of-the-art baseline. We will release audio samples at https://google.github.io/tacotron/publications/semisupervised_generative_modeling_for_controllable_speech_synthesis/.", "pdf": "/pdf/a116d6d9c6bc6d9d5854d7f6af9e9191ca298d7f.pdf", "keywords": "['TTS', 'Speech Synthesis', 'Semi-supervised Models', 'VAE', 'disentanglement']", "id": "rJeqeCEtvH"}, {"number": "189", "title": "Neural Machine Translation with Universal Visual Representation", "authors": "['Zhuosheng Zhang', 'Kehai Chen', 'Rui Wang', 'Masao Utiyama', 'Eiichiro Sumita', 'Zuchao Li', 'Hai Zhao']", "abstract": "Though visual information has been introduced for enhancing neural machine translation (NMT), its effectiveness strongly relies on the availability of large amounts of bilingual parallel sentence pairs with manual image annotations. In this paper, we present a universal visual representation learned over the monolingual corpora with image annotations, which overcomes the lack of large-scale bilingual sentence-image pairs, thereby extending image applicability in NMT. In detail, a group of images with similar topics to the source sentence will be retrieved from a light topic-image lookup table learned over the existing sentence-image pairs, and then is encoded as image representations by a pre-trained ResNet. An attention layer with a gated weighting is to fuse the visual information and text information as input to the decoder for predicting target translations. In particular, the proposed method enables the visual information to be integrated into large-scale text-only NMT in addition to the multimodel NMT. Experiments on four widely used translation datasets, including the WMT'16 English-to-Romanian, WMT'14 English-to-German, WMT'14 English-to-French, and Multi30K, show that the proposed approach achieves significant improvements over strong baselines.", "pdf": "/pdf/2ac2a018a5183db8cbcf9e8e33442c42d2eb55c6.pdf", "keywords": "['Neural Machine Translation', 'Visual Representation', 'Multimodal Machine Translation', 'Language Representation']", "id": "Byl8hhNYPS"}, {"number": "868", "title": "Entropy Penalty: Towards Generalization Beyond the IID Assumption", "authors": "['Devansh Arpit', 'Caiming Xiong', 'Richard Socher']", "abstract": "It has been shown that instead of learning actual object features, deep networks tend to exploit non-robust (spurious) discriminative features that are shared between training and test sets. Therefore, while they achieve state of the art performance on such test sets, they achieve poor generalization on out of distribution (OOD) samples where the IID (independent, identical distribution) assumption breaks and the distribution of non-robust features shifts. Through theoretical and empirical analysis, we show that this happens because maximum likelihood training (without appropriate regularization) leads the model to depend on all the correlations (including spurious ones) present between inputs and targets in the dataset. We then show evidence that the information bottleneck (IB) principle can address this problem. To do so, we propose a regularization approach based on IB called Entropy Penalty, that reduces the model's dependence on spurious features-- features corresponding to such spurious correlations. This allows deep networks trained with Entropy Penalty to generalize well even under distribution shift of spurious features. As a controlled test-bed for evaluating our claim, we train deep networks with Entropy Penalty on a colored MNIST (C-MNIST) dataset and show that it is able to generalize well on vanilla MNIST, MNIST-M and SVHN datasets in addition to an OOD version of C-MNIST itself. The baseline regularization methods we compare against fail to generalize on this test-bed.", "pdf": "/pdf/b8f61567262ba95a4578f830fd2dd5bc1f3461c7.pdf", "keywords": "['domain shift', 'information bottleneck', 'entropy penalty', 'out of distribution generalization']", "id": "Byes0TNFDS"}, {"number": "1776", "title": "AlignNet: Self-supervised Alignment Module", "authors": "['Antonia Creswell', 'Luis Piloto', 'David Barrett', 'Kyriacos Nikiforou', 'David Raposo', 'Marta Garnelo', 'Peter Battaglia', 'Murray Shanahan']", "abstract": "The natural world consists of objects that we perceive as persistent in space and time, even though these objects appear, disappear and reappear in our field of view as we move. This can be attributed to our notion of object persistence -- our knowledge that objects typically continue to exist, even if we can no longer see them -- and our ability to track objects. Drawing inspiration from the psychology literature on `sticky indices', we propose the AlignNet, a model that learns to assign unique indices to new objects when they first appear and reassign the index to subsequent instances of that object. By introducing a persistent object-based memory, the AlignNet may be used to keep track of objects across time, even if they disappear and reappear later. We implement the AlignNet as a graph network applied to a bipartite graph, in which the input nodes are objects from two sets that we wish to align. The network is trained to predict the edges which connect two instances of the same object across sets. The model is also capable of identifying when there are no matches and dealing with these cases. We perform experiments to show the model's ability to deal with the appearance, disappearance and reappearance of objects. Additionally, we demonstrate how a persistent object-based memory can help solve question-answering problems in a partially observable environment.", "pdf": "/pdf/927e3d34f24b57da550a8c95feaa607290bdcfbd.pdf", "keywords": "['Graph networks', 'alignment', 'objects', 'relation networks']", "id": "H1gcw1HYPr"}, {"number": "390", "title": "What graph neural networks cannot learn: depth vs width", "authors": "['Andreas Loukas']", "abstract": "This paper studies the expressive power of graph neural networks falling within the message-passing framework (GNNmp). Two results are presented. First, GNNmp are shown to be Turing universal under sufficient conditions on their depth, width, node attributes, and layer expressiveness. Second, it is discovered that GNNmp can lose a significant portion of their power when their depth and width is restricted. The proposed impossibility statements stem from a new technique that enables the repurposing of seminal results from distributed computing and leads to lower bounds for an array of decision, optimization, and estimation problems involving graphs. Strikingly, several of these problems are deemed impossible unless the product of a GNNmp's depth and width exceeds a polynomial of the graph size; this dependence remains significant even for tasks that appear simple or when considering approximation.", "pdf": "/pdf/1deea7b0fa3c20f142b229f06af2471086407471.pdf", "keywords": "['graph neural networks', 'capacity', 'impossibility results', 'lower bounds', 'expressive power']", "id": "B1l2bp4YwS"}, {"number": "6", "title": "Analysis and Interpretation of Deep CNN Representations as Perceptual Quality Features", "authors": "['Taimoor Tariq', 'Munchurl Kim']", "abstract": "Pre-trained Deep Convolutional Neural Network (CNN) features have popularly been used as full-reference perceptual quality features for CNN based image quality assessment, super-resolution, image restoration and a variety of image-to-image translation problems. In this paper, to get more insight, we link basic human visual perception to characteristics of learned deep CNN representations as a novel and first attempt to interpret them. We characterize the frequency and orientation tuning of channels in trained object detection deep CNNs (e.g., VGG-16) by applying grating stimuli of different spatial frequencies and orientations as input. We observe that the behavior of CNN channels as spatial frequency and orientation selective filters can be used to link basic human visual perception models to their characteristics. Doing so, we develop a theory to get more insight into deep CNN representations as perceptual quality features. We conclude that sensitivity to spatial frequencies that have lower contrast masking thresholds in human visual perception and a definite and strong orientation selectivity are important attributes of deep CNN channels that deliver better perceptual quality features. ", "pdf": "/pdf/4bc56f4cd0e60d71b3ef3f50eaeb08285d0b0fd1.pdf", "keywords": "['interpretation', 'perceptual quality', 'perceptual loss', 'image-restoration.']", "id": "BJlLvnEtDB"}, {"number": "33", "title": "Neural Linear Bandits: Overcoming Catastrophic Forgetting through Likelihood Matching", "authors": "['Tom Zahavy', 'Shie Mannor']", "abstract": "We study neural-linear bandits for solving problems where both exploration and representation learning play an important role. Neural-linear bandits leverage the representation power of deep neural networks and combine it with efficient exploration mechanisms, designed for linear contextual bandits, on top of the last hidden layer. Since the representation is being optimized during learning, information regarding exploration with 'old' features is lost. Here, we propose the first limited memory neural-linear bandit that is resilient to this catastrophic forgetting phenomenon. We perform simulations on a variety of real-world problems, including regression, classification, and sentiment analysis, and observe that our algorithm achieves superior performance and shows resilience to catastrophic forgetting. ", "pdf": "/pdf/f8137b4a6eef0c217ff45f8d5cbff4af2a37997d.pdf", "keywords": "[]", "id": "r1gzdhEKvH"}, {"number": "1547", "title": "BOSH: An Efficient Meta Algorithm for Decision-based Attacks", "authors": "['Zhenxin Xiao', 'Puyudi Yang', 'Yuchen Jiang', 'Kai-Wei Chang', 'Cho-Jui Hsieh']", "abstract": "Adversarial example generation becomes a viable method for evaluating the robustness of a machine learning model. In this paper, we consider hard-label black- box attacks (a.k.a. decision-based attacks), which is a challenging setting that generates adversarial examples based on only a series of black-box hard-label queries. This type of attacks can be used to attack discrete and complex models, such as Gradient Boosting Decision Tree (GBDT) and detection-based defense models. Existing decision-based attacks based on iterative local updates often get stuck in a local minimum and fail to generate the optimal adversarial example with the smallest distortion. To remedy this issue, we propose an efficient meta algorithm called BOSH-attack, which tremendously improves existing algorithms through Bayesian Optimization (BO) and Successive Halving (SH). In particular, instead of traversing a single solution path when searching an adversarial example, we maintain a pool of solution paths to explore important regions. We show empirically that the proposed algorithm converges to a better solution than existing approaches, while the query count is smaller than applying multiple random initializations by a factor of 10.", "pdf": "/pdf/d9963b33e46e848ba315947f37be89600b008e26.pdf", "keywords": "[]", "id": "ryxPbkrtvr"}, {"number": "1161", "title": "Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees", "authors": "['Binghong Chen', 'Bo Dai', 'Qinjie Lin', 'Guo Ye', 'Han Liu', 'Le Song']", "abstract": "We propose a meta path planning algorithm named \\emph{Neural Exploration-Exploitation Trees~(NEXT)} for learning from prior experience for solving new path planning problems in high dimensional continuous state and action spaces. Compared to more classical sampling-based methods like RRT, our approach achieves much better sample efficiency in  high-dimensions and can benefit from prior experience of planning in similar environments. More specifically, NEXT exploits a novel neural architecture which can learn promising search directions from problem structures. The learned prior is then integrated into a UCB-type algorithm to achieve an online balance between \\emph{exploration} and \\emph{exploitation} when solving a new problem. We conduct thorough experiments to show that NEXT accomplishes new planning problems with more compact search trees and significantly outperforms state-of-the-art methods on several benchmarks.", "pdf": "/pdf/c45825c9605af935d5e51f065e4b4499bf2b5bde.pdf", "keywords": "['learning to plan', 'representation learning', 'learning to design algorithm', 'reinforcement learning', 'meta learning']", "id": "rJgJDAVKvB"}, {"number": "2355", "title": "Weight-space symmetry in neural network loss landscapes revisited", "authors": "['Berfin Simsek', 'Johanni Brea', 'Bernd Illing', 'Wulfram Gerstner']", "abstract": "Neural network training depends on the structure of the underlying loss landscape, i.e. local minima, saddle points, flat plateaus, and loss barriers. In relation to the structure of the landscape, we study the permutation symmetry of neurons in each layer of a deep neural network, which gives rise not only to multiple equivalent global minima of the loss function but also to critical points in between partner minima. In a network of $d-1$ hidden layers with $n_k$ neurons in layers $k = 1, \\ldots, d$, we construct continuous paths between equivalent global minima that lead through a `permutation point' where the input and output weight vectors of two neurons in the same hidden layer $k$ collide and interchange. We show that such permutation points are critical points which lie inside high-dimensional subspaces of equal loss, contributing to the global flatness of the landscape. We also find that a permutation point for the exchange of neurons $i$ and $j$ transits into a flat high-dimensional plateau that enables all $n_k!$ permutations of neurons in a given layer $k$ at the same loss value. Moreover, we introduce higher-order permutation points by exploiting the hierarchical structure in the loss landscapes of neural networks, and find that the number of $K$-th order permutation points is much larger than the (already huge) number of equivalent global minima -- at least by a polynomial factor of order $K$. In two tasks, we demonstrate numerically with our path finding method that continuous paths between partner minima exist: first, in a toy network with a single hidden layer on a function approximation task and, second, in a multilayer network on the MNIST task. Our geometric approach yields a lower bound on the number of critical points generated by weight-space symmetries and provides a simple intuitive link between previous theoretical results and numerical observations.", "pdf": "/pdf/e867f6c9ea89d6ad1b42863cfe3db2bf43226d15.pdf", "keywords": "['Weight-space symmetry', 'neural network landscapes']", "id": "rkxmPgrKwB"}, {"number": "1635", "title": "Fast Neural Network Adaptation via Parameter Remapping and Architecture Search", "authors": "['Jiemin Fang*', 'Yuzhu Sun*', 'Kangjian Peng*', 'Qian Zhang', 'Yuan Li', 'Wenyu Liu', 'Xinggang Wang']", "abstract": "Deep neural networks achieve remarkable performance in many computer vision tasks. Most state-of-the-art~(SOTA) semantic segmentation and object detection approaches reuse neural network architectures designed for image classification as the backbone, commonly pre-trained on ImageNet. However, performance gains can be achieved by designing network architectures specifically for detection and segmentation, as shown by recent neural architecture search (NAS) research for detection and segmentation. One major challenge though, is that ImageNet pre-training of the search space representation (a.k.a. super network) or the searched networks incurs huge computational cost. In this paper, we propose a Fast Neural Network Adaptation (FNA) method, which can adapt both the architecture and parameters of a seed network (e.g. a high performing manually designed backbone) to become a network with different depth, width, or kernels via a Parameter Remapping technique, making it possible to utilize NAS for detection/segmentation tasks a lot more efficiently. In our experiments, we conduct FNA on MobileNetV2 to obtain new networks for both segmentation and detection that clearly out-perform existing networks designed both manually and by NAS. The total computation cost of FNA is significantly less than SOTA segmentation/detection NAS approaches: 1737$\\times$ less than DPC, 6.8$\\times$ less than Auto-DeepLab and 7.4$\\times$ less than DetNAS. The code is available at https://github.com/JaminFong/FNA .", "pdf": "/pdf/7743e936d41da3a8e6e98428363cbb80502e9243.pdf", "keywords": "[]", "id": "rklTmyBKPH"}, {"number": "2415", "title": "Scale-Equivariant Steerable Networks", "authors": "['Ivan Sosnovik', 'Micha\u0142 Szmaja', 'Arnold Smeulders']", "abstract": "The effectiveness of Convolutional Neural Networks (CNNs) has been substantially attributed to their built-in property of translation equivariance. However, CNNs do not have embedded mechanisms to handle other types of transformations. In this work, we pay attention to scale changes, which regularly appear in various tasks due to the changing distances between the objects and the camera. First, we introduce the general theory for building scale-equivariant convolutional networks with steerable filters. We develop scale-convolution and generalize other common blocks to be scale-equivariant. We demonstrate the computational efficiency and numerical stability of the proposed method. We compare the proposed models to the previously developed methods for scale equivariance and local scale invariance. We demonstrate state-of-the-art results on the MNIST-scale dataset and on the STL-10 dataset in the supervised learning setting.", "pdf": "/pdf/ce6c00156479706a1ff9e63741b0551427f47911.pdf", "keywords": "['Scale Equivariance', 'Steerable Filters']", "id": "HJgpugrKPS"}, {"number": "1589", "title": "Axial Attention in Multidimensional Transformers", "authors": "['Jonathan Ho', 'Nal Kalchbrenner', 'Dirk Weissenborn', 'Tim Salimans']", "abstract": "Self-attention effectively captures large receptive fields with high information bandwidth, but its computational resource requirements grow quadratically with the number of points over which attention is performed. For data arranged as large multidimensional tensors, such as images and videos, the quadratic growth makes self-attention prohibitively expensive. These tensors often have thousands of positions that one wishes to capture and proposed attentional alternatives either limit the resulting receptive field or require custom subroutines. We propose Axial Attention, a simple generalization of self-attention that naturally aligns with the multiple dimensions of the tensors in both the encoding and the decoding settings. The Axial Transformer uses axial self-attention layers and a shift operation to efficiently build large and full receptive fields.  Notably the proposed structure of the layers allows for the vast majority of the context to be computed in parallel during decoding without introducing any independence assumptions. This semi-parallel structure goes a long way to making decoding from even a very large Axial Transformer broadly applicable. We demonstrate state-of-the-art results for the Axial Transformer on the ImageNet-32 and ImageNet-64 image benchmarks as well as on the BAIR Robotic Pushing video benchmark. We open source the implementation of Axial Transformers.", "pdf": "/pdf/2c2be8a5f23b2fdb3df67a1720ccdc4932aaa206.pdf", "keywords": "['self-attention', 'transformer', 'images', 'videos']", "id": "H1e5GJBtDr"}, {"number": "1913", "title": "Learning to Guide Random Search", "authors": "['Ozan Sener', 'Vladlen Koltun']", "abstract": "We are interested in derivative-free optimization of high-dimensional functions. The sample complexity of existing methods is high and depends on problem dimensionality, unlike the dimensionality-independent rates of first-order methods. The recent success of deep learning suggests that many datasets lie on low-dimensional manifolds that can be represented by deep nonlinear models. We therefore consider derivative-free optimization of a high-dimensional function that lies on a latent low-dimensional manifold. We develop an online learning approach that learns this manifold while performing the optimization. In other words, we jointly learn the manifold and optimize the function. Our analysis suggests that the presented method significantly reduces sample complexity. We empirically evaluate the method on continuous optimization benchmarks and high-dimensional continuous control problems. Our method achieves significantly lower sample complexity than Augmented Random Search, Bayesian optimization, covariance matrix adaptation (CMA-ES), and other derivative-free optimization algorithms.", "pdf": "/pdf/dd198a608cc105007bf9adf04e35827eb93f043a.pdf", "keywords": "['Random search', 'Derivative-free optimization', 'Learning continuous control']", "id": "B1gHokBKwS"}, {"number": "1213", "title": "Visual Explanation for Deep Metric Learning", "authors": "['Sijie Zhu', 'Taojiannan Yang', 'Chen Chen']", "abstract": "This work explores the visual explanation for deep metric learning and its applications. As an important problem for learning representation, metric learning has attracted much attention recently, while the interpretation of such model is not as well studied as classification. To this end, we propose an intuitive idea to show where contributes the most to the overall similarity of two input images by decomposing the final activation. Instead of only providing the overall activation map of each image, we propose to generate point-to-point activation intensity between two images so that the relationship between different regions is uncovered. We show that the proposed framework can be directly deployed to a large range of metric learning applications and provides valuable information for understanding the model. Furthermore, our experiments show its effectiveness on two potential applications, i.e. cross-view pattern discovery and interactive retrieval. ", "pdf": "/pdf/c59432531b2034ed5f601e2e1adbbdb45aae8405.pdf", "keywords": "['Metric Learning', 'Visual Explanation']", "id": "S1xLuRVFvr"}, {"number": "1846", "title": "Model-Agnostic Feature Selection with Additional Mutual Information", "authors": "['Mukund Sudarshan', 'Aahlad Manas Puli', 'Lakshmi Subramanian', 'Sriram Sankararaman', 'Rajesh Ranganath']", "abstract": "Answering questions about data can require understanding what parts of an input X influence the response Y. Finding such an understanding can be built by testing relationships between variables through a machine learning model. For example, conditional randomization tests help determine whether a variable relates to the response given the rest of the variables. However, randomization tests require users to specify test statistics. We formalize a class of proper test statistics that are guaranteed to select a feature when it provides information about the response even when the rest of the features are known. We show that f-divergences provide a broad class of proper test statistics. In the class of f-divergences, the KL-divergence yields an easy-to-compute proper test statistic that relates to the AMI. Questions of feature importance can be asked at the level of an individual sample.  We show that estimators from the same AMI test can also be used to find important features in a particular instance. We provide an example to show that perfect predictive models are insufficient for instance-wise feature selection. We evaluate our method on several simulation experiments, on a genomic dataset, a clinical dataset for hospital readmission, and on a subset of classes in ImageNet. Our method outperforms several baselines in various simulated datasets, is able to identify biologically significant genes, can select the most important predictors of a hospital readmission event, and is able to identify distinguishing features in an image-classification task. ", "pdf": "/pdf/bd14218f99d6b7dcd035ddba394b2dc038c7b01c.pdf", "keywords": "['feature selection', 'interpretability', 'randomization', 'fdr control', 'p-values']", "id": "HJg_tkBtwS"}, {"number": "863", "title": "Autoencoders and Generative Adversarial Networks for Imbalanced Sequence Classification", "authors": "['Stephanie Ger', 'Diego Klabjan']", "abstract": "We introduce a novel synthetic oversampling method for variable length, multi- feature sequence datasets based on autoencoders and generative adversarial net- works. We show that this method improves classification accuracy for highly imbalanced sequence classification tasks. We show that this method outperforms standard oversampling techniques that use techniques such as SMOTE and autoencoders. We also use generative adversarial networks on the majority class as an outlier detection method for novelty detection, with limited classification improvement. We show that the use of generative adversarial network based synthetic data improves classification model performance on a variety of sequence data sets.\n", "pdf": "/pdf/7d53de57a3ebd9cc3bb7d99ba0243ebaa4fc389a.pdf", "keywords": "['imbalanced multivariate time series classification']", "id": "ryxtCpNtDS"}, {"number": "1294", "title": "Behavior-Guided Reinforcement Learning", "authors": "['Aldo Pacchiano', 'Jack Parker-Holder', 'Yunhao Tang', 'Anna Choromanska', 'Krzysztof Choromanski', 'Michael I. Jordan']", "abstract": "We introduce a new approach for comparing reinforcement learning policies, using Wasserstein distances (WDs) in a newly defined latent behavioral space. We show that by utilizing the dual formulation of the WD, we can learn score functions over trajectories that can be in turn used to lead policy optimization towards (or away from) (un)desired behaviors. Combined with smoothed WDs, the dual formulation allows us to devise efficient algorithms that take stochastic gradient descent steps through WD regularizers. We incorporate these regularizers into two novel on-policy algorithms, Behavior-Guided Policy Gradient and Behavior-Guided Evolution Strategies, which we demonstrate can outperform existing methods in a variety of challenging environments. We also provide an open source demo.", "pdf": "/pdf/6b60981d795cedbb3dbaee7497121ab882e8beb8.pdf", "keywords": "['Reinforcement Learning', 'Optimal Transport', 'Evolution Strategies']", "id": "Hklo5RNtwS"}, {"number": "2550", "title": "Predictive Coding for Boosting Deep Reinforcement Learning with Sparse Rewards", "authors": "['Xingyu Lu', 'Pieter Abbeel', 'Stas Tiomkin']", "abstract": "While recent progress in deep reinforcement learning has enabled robots to learn complex behaviors, tasks with long horizons and sparse rewards remain an ongoing challenge. In this work, we propose an effective reward shaping method through predictive coding to tackle sparse reward problems. By learning predictive representations offline and using these representations for reward shaping, we gain access to reward signals that understand the structure and dynamics of the environment. In particular, our method achieves better learning by providing reward signals that 1) understand environment dynamics 2) emphasize on features most useful for learning 3) resist noise in learned representations through reward accumulation. We demonstrate the usefulness of this approach in different domains ranging from robotic manipulation to navigation, and we show that reward signals produced through predictive coding are as effective for learning as hand-crafted rewards.", "pdf": "/pdf/3cc45a51eac1fd4b392f78aa0a9d78a26c19c6ff.pdf", "keywords": "['reinforcement learning', 'representation learning', 'reward shaping', 'predictive coding']", "id": "Hkxi2gHYvH"}, {"number": "1269", "title": "Superbloom: Bloom filter meets Transformer", "authors": "['John Anderson', 'Qingqing Huang', 'Walid Krichene', 'Steffen Rendle', 'Li Zhang']", "abstract": "We extend the idea of word pieces in natural language models to machine learning tasks on opaque ids. This is achieved by applying hash functions to map each id to multiple hash tokens in a much smaller space, similarly to a Bloom filter. We show that by applying a multi-layer Transformer to these Bloom filter digests, we are able to obtain models with high accuracy. They outperform models of a similar size without hashing and, to a large degree, models of a much larger size trained using sampled softmax with the same computational budget. Our key observation is that it is important to use a multi-layer Transformer for Bloom filter digests to remove ambiguity in the hashed input. We believe this provides an alternative method to solving problems with large vocabulary size.", "pdf": "/pdf/83c074889aa9a046029f2f75efc0cb78a2a7f5b3.pdf", "keywords": "['Bloom filter', 'Transformer', 'word pieces', 'contextual embeddings']", "id": "SJxy5A4twS"}, {"number": "433", "title": "Min-Max Optimization without Gradients: Convergence and Applications to Adversarial ML", "authors": "['Sijia Liu', 'Songtao Lu', 'Xiangyi Chen', 'Yao Feng', 'Kaidi Xu', 'Abdullah Al-Dujaili', 'Minyi Hong', 'Una-May Obelilly']", "abstract": "In this paper, we study the problem of constrained robust (min-max) optimization ina black-box setting, where the desired optimizer cannot access the gradients of the objective function but may query its values. We present a principled optimization framework, integrating a zeroth-order (ZO) gradient estimator with an alternating projected stochastic gradient descent-ascent method, where the former only requires a small number of function queries and the later needs just one-step descent/ascent update. We show that the proposed framework, referred to as ZO-Min-Max, has a sub-linear convergence rate under mild conditions and scales gracefully with problem size. From an application side, we explore a promising connection between black-box min-max optimization and black-box evasion and poisoning attacks in adversarial machine learning (ML). Our empirical evaluations on these use cases demonstrate the effectiveness of our approach and its scalability to dimensions that prohibit using recent black-box solvers.", "pdf": "/pdf/e39bfd34f9b940361ee6d635a6873bdfe01abedc.pdf", "keywords": "['nonconvex optimization', 'min-max optimization', 'robust optimization', 'adversarial attack']", "id": "rylkma4twr"}, {"number": "641", "title": "Online Meta-Critic Learning for Off-Policy Actor-Critic Methods", "authors": "['Wei Zhou', 'Yiying Li', 'Yongxin Yang', 'Huaimin Wang', 'Timothy M. Hospedales']", "abstract": "Off-Policy Actor-Critic (Off-PAC) methods have proven successful in a variety of continuous control tasks. Normally, the critics action-value function is updated using temporal-difference, and the critic in turn provides a loss for the actor that trains it to take actions with higher expected return. In this paper, we introduce a novel and flexible meta-critic that observes the learning process and meta-learns an additional loss for the actor that accelerates and improves actor-critic learning. Compared to the vanilla critic, the meta-critic network is explicitly trained to accelerate the learning process; and compared to existing meta-learning algorithms, meta-critic is rapidly learned online for a single task, rather than slowly over a family of tasks. Crucially, our meta-critic framework is designed for off-policy based learners, which currently provide state-of-the-art reinforcement learning sample efficiency. We demonstrate that online meta-critic learning leads to improvements in a variety of continuous control environments when combined with contemporary Off-PAC methods DDPG, TD3 and the state-of-the-art SAC. ", "pdf": "/pdf/d227d9672f01c43100cdfffd4c51fb20950c5432.pdf", "keywords": "['off-policy actor-critic', 'reinforcement learning', 'meta-learning']", "id": "H1lKd6NYPS"}, {"number": "787", "title": "Faster Neural Network Training with Data Echoing", "authors": "['Dami Choi', 'Alexandre Passos', 'Christopher J. Shallue', 'George E. Dahl']", "abstract": "In the twilight of Moore's law, GPUs and other specialized hardware accelerators have dramatically sped up neural network training. However, earlier stages of the training pipeline, such as disk I/O and data preprocessing, do not run on accelerators. As accelerators continue to improve, these earlier stages will increasingly become the bottleneck. In this paper, we introduce data echoing, which reduces the total computation used by earlier pipeline stages and speeds up training whenever computation upstream from accelerators dominates the training time. Data echoing reuses (or echoes) intermediate outputs from earlier pipeline stages in order to reclaim idle capacity. We investigate the behavior of different data echoing algorithms on various workloads, for various amounts of echoing, and for various batch sizes. We find that in all settings, at least one data echoing algorithm can match the baseline's predictive performance using less upstream computation. We measured a factor of 3.25 decrease in wall-clock time for ResNet-50 on ImageNet when reading training data over a network.", "pdf": "/pdf/b9adfa9f3ef1cf10348c22223c71b988b0d670fb.pdf", "keywords": "['systems', 'faster training', 'large scale']", "id": "rJeO3aVKPB"}, {"number": "1785", "title": "On Universal Equivariant Set Networks", "authors": "['Nimrod Segol', 'Yaron Lipman']", "abstract": "Using deep neural networks that are either invariant or equivariant to permutations in order to learn functions on unordered sets has become prevalent. The most popular, basic models are DeepSets (Zaheer et al. 2017) and PointNet (Qi et al. 2017). While known to be universal for approximating invariant functions, DeepSets and PointNet are not known to be universal when approximating equivariant set functions. On the other hand, several recent equivariant set architectures have been proven equivariant universal (Sannai et al. 2019, Keriven and Peyre 2019), however these models either use layers that are not permutation equivariant (in the standard sense) and/or use higher order tensor variables which are less practical. There is, therefore, a gap in understanding the universality of popular equivariant set models versus theoretical ones. \n\t\t\t\nIn this paper we close this gap by proving that: (i) PointNet is not equivariant universal; and (ii) adding a single linear transmission  layer makes PointNet universal. We call this architecture PointNetST and argue it is the simplest permutation equivariant universal model known to date. Another consequence is that DeepSets is universal, and also PointNetSeg, a popular point cloud segmentation network (used e.g., in Qi et al. 2017) is universal.\n\t\t\nThe key theoretical tool used to prove the above results is an explicit characterization of all permutation equivariant polynomial layers. Lastly, we provide numerical experiments validating the theoretical results and comparing different permutation equivariant models.", "pdf": "/pdf/d1adcc582763d5140cdd271d6c94bda5bf8e7fb6.pdf", "keywords": "['deep learning', 'universality', 'set functions', 'equivariance']", "id": "HkxTwkrKDB"}, {"number": "646", "title": "Finite Depth and Width Corrections to the Neural Tangent Kernel", "authors": "['Boris Hanin', 'Mihai Nica']", "abstract": "We prove the precise scaling, at finite depth and width, for the mean and variance of the neural tangent kernel (NTK) in a randomly initialized ReLU network. The standard deviation is exponential in the ratio of network depth to width. Thus, even in the limit of infinite overparameterization, the NTK is not deterministic if depth and width simultaneously tend to infinity. Moreover, we prove that for such deep and wide networks, the NTK has a non-trivial evolution during training by showing that the mean of its first SGD update is also exponential in the ratio of network depth to width. This is sharp contrast to the regime where depth is fixed and network width is very large. Our results suggest that, unlike relatively shallow and wide networks, deep and wide ReLU networks are capable of learning data-dependent features even in the so-called lazy training regime. ", "pdf": "/pdf/d2542e25b48b0fdb9e0c496f3bb41b3592be559d.pdf", "keywords": "['Neural Tangent Kernel', 'Finite Width Corrections', 'Random ReLU Net', 'Wide Networks', 'Deep Networks']", "id": "SJgndT4KwB"}, {"number": "1826", "title": "UNIVERSAL MODAL EMBEDDING OF DYNAMICS IN VIDEOS AND ITS APPLICATIONS", "authors": "['Israr Ul Haq', 'Yoshinobu Kawahara']", "abstract": "Extracting underlying dynamics of objects in image sequences is one of the challenging problems in computer vision. On the other hand, dynamic mode decomposition (DMD) has recently attracted attention as a way of obtaining modal representations of nonlinear dynamics from (general multivariate time-series) data without explicit prior knowledge about the dynamics. In this paper, we propose a convolutional autoencoder based DMD (CAE-DMD) that is an extended DMD (EDMD) approach, to extract underlying dynamics in videos. To this end, we develop a modified CAE model by incorporating DMD on the encoder, which gives a more meaningful compressed representation of input image sequences. On the reconstruction side, a decoder is used to minimize the reconstruction error after applying the DMD, which in result gives an accurate reconstruction of inputs. We empirically investigated the performance of CAE-DMD in two applications: background/foreground extraction and video classification, on publicly available datasets.", "pdf": "/pdf/f0e33eabea4e03123a86c53114cd47d675796e79.pdf", "keywords": "['Non-linear dynamics', 'Convolutional Autoencoder', 'Foreground modeling', 'Video classification', 'Dynamic mode decomposition']", "id": "H1lkYkrKDB"}, {"number": "764", "title": "Empirical confidence estimates for classification by deep neural networks", "authors": "['Chris Finlay', 'Adam M. Oberman']", "abstract": "How well can we estimate the probability that the classification predicted by a deep neural network is correct (or in the Top 5)?  It is well-known that the softmax values of the network are not estimates of the probabilities of class labels.  However, there is a misconception that these values are not informative.  We define the notion of implied loss and prove that if an uncertainty measure is an implied loss, then low uncertainty means high probability of correct (or Top-k) classification on the test set.   We demonstrate empirically that these values can be used to measure the confidence that the classification is correct.  Our method is simple to use on existing networks: we proposed confidence measures for Top-k which can be evaluated by binning values on the test set. ", "pdf": "/pdf/001822909dba71c907296d76ea62a06331d4d649.pdf", "keywords": "['confidence', 'classification', 'uncertainty', 'anomaly', 'robustness']", "id": "Hke0oa4KwS"}, {"number": "1643", "title": "Multi-Agent Interactions Modeling with Correlated Policies", "authors": "['Minghuan Liu', 'Ming Zhou', 'Weinan Zhang', 'Yuzheng Zhuang', 'Jun Wang', 'Wulong Liu', 'Yong Yu']", "abstract": "In multi-agent systems, complex interacting behaviors arise due to the high correlations among agents. However, previous work on modeling multi-agent interactions from demonstrations is primarily constrained by assuming the independence among policies and their reward structures. \nIn this paper, we cast the multi-agent interactions modeling problem into a multi-agent imitation learning framework with explicit modeling of correlated policies by approximating opponents policies, which can recover agents' policies that can regenerate similar interactions. Consequently, we develop a Decentralized Adversarial Imitation Learning algorithm with Correlated policies (CoDAIL), which allows for decentralized training and execution. Various experiments demonstrate that CoDAIL can better regenerate complex interactions close to the demonstrators and outperforms state-of-the-art multi-agent imitation learning methods. Our code is available at \\url{https://github.com/apexrl/CoDAIL}.", "pdf": "/pdf/beceb7094a1f342270ab228d4e4b63d666a385cb.pdf", "keywords": "['Multi-agent reinforcement learning', 'Imitation learning']", "id": "B1gZV1HYvS"}, {"number": "391", "title": "MMD GAN with Random-Forest Kernels", "authors": "['Tao Huang', 'Zhen Han', 'Xu Jia', 'Hanyuan Hang']", "abstract": "In this paper, we propose a novel kind of kernel, random forest kernel, to enhance the empirical performance of MMD GAN. Different from common forests with deterministic routings, a probabilistic routing variant is used in our innovated random-forest kernel, which is possible to merge with the CNN frameworks. Our proposed random-forest kernel has the following advantages: From the perspective of random forest, the output of GAN discriminator can be viewed as feature inputs to the forest, where each tree gets access to merely a fraction of the features, and thus the entire forest benefits from ensemble learning. In the aspect of kernel method, random-forest kernel is proved to be characteristic, and therefore suitable for the MMD structure. Besides, being an asymmetric kernel, our random-forest kernel is much more flexible, in terms of capturing the differences between distributions. Sharing the advantages of CNN, kernel method, and ensemble learning, our random-forest kernel based MMD GAN obtains desirable empirical performances on CIFAR-10, CelebA and LSUN bedroom data sets. Furthermore, for the sake of completeness, we also put forward comprehensive theoretical analysis to support our experimental results.", "pdf": "/pdf/448f26dd1c7692fabce2a1f7ff4f56af03d97b01.pdf", "keywords": "['GANs', 'MMD', 'kernel', 'random forest', 'unbiased gradients']", "id": "HJxhWa4KDr"}, {"number": "1513", "title": "SNOW: Subscribing to Knowledge via Channel Pooling for Transfer & Lifelong Learning of Convolutional Neural Networks", "authors": "['Chungkuk Yoo', 'Bumsoo Kang', 'Minsik Cho']", "abstract": "SNOW is an efficient learning method to improve training/serving throughput as well as accuracy for transfer and lifelong learning of convolutional neural networks based on knowledge subscription. SNOW selects the top-K useful intermediate\nfeature maps for a target task from a pre-trained and frozen source model through a novel channel pooling scheme, and utilizes them in the task-specific delta model. The source model is responsible for generating a large number of generic feature maps. Meanwhile, the delta model selectively subscribes to those feature maps and fuses them with its local ones to deliver high accuracy for the target task. Since a source model takes part in both training and serving of all target tasks\nin an inference-only mode, one source model can serve multiple delta models, enabling significant computation sharing. The sizes of such delta models are fractional of the source model, thus SNOW also provides model-size efficiency.\nOur experimental results show that SNOW offers a superior balance between accuracy and training/inference speed for various image classification tasks to the existing transfer and lifelong learning practices.", "pdf": "/pdf/f9060b44e8657b6d708c6c180451273066356b70.pdf", "keywords": "['channel pooling', 'efficient training and inferencing', 'lifelong learning', 'transfer learning', 'multi task']", "id": "rJxtgJBKDr"}, {"number": "1341", "title": "Intriguing Properties of Adversarial Training at Scale", "authors": "['Cihang Xie', 'Alan Yuille']", "abstract": "Adversarial training is one of the main defenses against adversarial attacks. In this paper, we provide the first rigorous study on diagnosing elements of large-scale adversarial training on ImageNet, which reveals two intriguing properties. \n\nFirst, we study the role of normalization. Batch normalization (BN) is a crucial element for achieving state-of-the-art performance on many vision tasks, but we show it may prevent networks from obtaining strong robustness in adversarial training. One unexpected observation is that, for models trained with BN, simply removing clean images from training data largely boosts adversarial robustness, i.e., 18.3%. We relate this phenomenon to the hypothesis that clean images and adversarial images are drawn from two different domains. This two-domain hypothesis may explain the issue of BN when training with a mixture of clean and adversarial images, as estimating normalization statistics of this mixture distribution is challenging. Guided by this two-domain hypothesis, we show disentangling the mixture distribution for normalization, i.e., applying separate BNs to clean and adversarial images for statistics estimation, achieves much stronger robustness. Additionally, we find that enforcing BNs to behave consistently at training and testing can further enhance robustness.\n\nSecond, we study the role of network capacity. We find our so-called 'deep' networks are still shallow for the task of adversarial learning. Unlike traditional classification tasks where accuracy is only marginally improved by adding more layers to 'deep' networks (e.g., ResNet-152), adversarial training exhibits a much stronger demand on deeper networks to achieve higher adversarial robustness. This robustness improvement can be observed substantially and consistently even by pushing the network capacity to an unprecedented scale, i.e., ResNet-638.  ", "pdf": "/pdf/acbff4b8434a596abc7db9812854e7293907b8fe.pdf", "keywords": "['adversarial defense', 'adversarial machine learning']", "id": "HyxJhCEFDS"}, {"number": "808", "title": "Poisoning Attacks with Generative Adversarial Nets", "authors": "['Luis Mu\u00f1oz-Gonz\u00e1lez', 'Bjarne Pfitzner', 'Matteo Russo', 'Javier Carnerero-Cano', 'Emil C. Lupu']", "abstract": "Machine learning algorithms are vulnerable to poisoning attacks: An adversary can inject malicious points in the training dataset to influence the learning process and degrade the algorithm's performance. Optimal poisoning attacks have already been proposed to evaluate worst-case scenarios, modelling attacks as a bi-level optimization problem. Solving these problems is computationally demanding and has limited applicability for some models such as deep networks. In this paper we introduce a novel generative model to craft systematic poisoning attacks against machine learning classifiers generating adversarial training examples, i.e. samples that look like genuine data points but that degrade the classifier's accuracy when used for training. We propose a Generative Adversarial Net with three components: generator, discriminator, and the target classifier. This approach allows us to model naturally the detectability constrains that can be expected in realistic attacks and to identify the regions of the underlying data distribution that can be more vulnerable to data poisoning. Our experimental evaluation shows the effectiveness of our attack to compromise machine learning classifiers, including deep networks.", "pdf": "/pdf/14b0c1e1035bc2a7227de453e9e467bd1cf28220.pdf", "keywords": "['data poisoning', 'adversarial machine learning', 'generative adversarial nets']", "id": "Bke-6pVKvB"}, {"number": "1718", "title": "DyNet: Dynamic Convolution for Accelerating Convolution Neural Networks", "authors": "['Kane Zhang', 'Jian Zhang', 'Qiang Wang', 'Zhao Zhong']", "abstract": "Convolution operator is the core of convolutional neural networks (CNNs) and occupies the most computation cost. To make CNNs more efficient, many methods have been proposed to either design lightweight networks or compress models. Although some efficient network structures have been proposed, such as MobileNet or ShuffleNet, we find that there still exists redundant information between convolution kernels. To address this issue, we propose a novel dynamic convolution method named \\textbf{DyNet} in this paper, which can adaptively generate convolution kernels based on image contents. To demonstrate the effectiveness, we apply DyNet on multiple state-of-the-art CNNs. The experiment results show that DyNet can reduce the computation cost remarkably, while maintaining the performance nearly unchanged. Specifically, for ShuffleNetV2 (1.0), MobileNetV2 (1.0), ResNet18 and ResNet50, DyNet reduces 40.0%, 56.7%, 68.2% and 72.4% FLOPs respectively while the Top-1 accuracy on ImageNet only changes by +1.0%, -0.27%, -0.6% and -0.08%. Meanwhile, DyNet further accelerates the inference speed of MobileNetV2 (1.0), ResNet18 and ResNet50 by 1.87x,1.32x and 1.48x on CPU platform respectively. To verify the scalability, we also apply DyNet on segmentation task, the results show that DyNet can reduces 69.3% FLOPs while maintaining the Mean IoU on segmentation task.", "pdf": "/pdf/1805cd4025104e121d1f8ca13b2d67fe1bb8b534.pdf", "keywords": "['CNNs', 'dynamic convolution kernel']", "id": "SyeZIkrKwS"}, {"number": "1733", "title": "When Robustness Doesnt Promote Robustness: Synthetic vs. Natural Distribution Shifts on ImageNet", "authors": "['Rohan Taori', 'Achal Dave', 'Vaishaal Shankar', 'Nicholas Carlini', 'Benjamin Recht', 'Ludwig Schmidt']", "abstract": "We conduct a large experimental comparison of various robustness metrics for image classification. The main question of our study is to what extent current synthetic robustness interventions (lp-adversarial examples, noise corruptions, etc.) promote robustness under natural distribution shifts occurring in real data. To this end, we evaluate 147 ImageNet models under 199 different evaluation settings. We find that no current robustness intervention improves robustness on natural distribution shifts beyond a baseline given by standard models without a robustness intervention. The only exception is the use of larger training datasets, which provides a small increase in robustness on one natural distribution shift. Our results indicate that robustness improvements on real data may require new methodology and more evaluations on natural distribution shifts.", "pdf": "/pdf/5e949b5312e00689668edd085aa71b726fe70946.pdf", "keywords": "['robustness', 'distribution shift', 'image corruptions', 'adversarial robustness', 'reliable machine learning']", "id": "HyxPIyrFvH"}, {"number": "1860", "title": "Projected Canonical Decomposition for Knowledge Base Completion", "authors": "['Timoth\u00e9e Lacroix', 'Guillaume Obozinski', 'Joan Bruna', 'Nicolas Usunier']", "abstract": "The leading approaches to tensor completion and link prediction are based on the canonical polyadic (CP) decomposition of tensors. While these approaches were originally motivated by low rank approximations, the best performances are usually obtained for ranks as high as permitted by computation constraints. For large scale factorization problems where the factor dimensions have to be kept small, the performances of these approaches tend to drop drastically. The other main tensor factorization model, Tucker decomposition, is more flexible than CP for fixed factor dimensions, so we expect Tucker-based approaches to yield better performance under strong constraints on the number of parameters. However, as we show in this paper through experiments on standard benchmarks of link prediction in knowledge bases, ComplEx, a variant of CP, achieves similar performances to recent approaches based on Tucker decomposition on all operating points in terms of number of parameters. In a control experiment, we show that one problem in the practical application of Tucker decomposition to large-scale tensor completion comes from the adaptive optimization algorithms based on diagonal rescaling, such as Adagrad. We present a new algorithm for a constrained version of Tucker which implicitly applies Adagrad to a CP-based model with an additional projection of the embeddings onto a fixed lower dimensional subspace. The resulting Tucker-style extension of ComplEx obtains similar best performances as ComplEx, with substantial gains on some datasets under constraints on the number of parameters.", "pdf": "/pdf/1a97a632e703994b66d62ae0e82f26ecc6b1e480.pdf", "keywords": "['knowledge base completion', 'adagrad']", "id": "ByeAK1BKPB"}, {"number": "1006", "title": "Efficient Training of Robust and Verifiable Neural Networks", "authors": "['Akhilan Boopathy', 'Lily Weng', 'Sijia Liu', 'Pin-Yu Chen', 'Luca Daniel']", "abstract": "Recent works have developed several methods of defending neural networks against adversarial attacks with certified guarantees. We propose that many common certified defenses can be viewed under a unified framework of regularization. This unified framework provides a technique for comparing different certified defenses with respect to robust generalization. In addition, we develop a new regularizer that is both more efficient than existing certified defenses and can be used to train networks with higher certified accuracy. Our regularizer also extends to an L0 threat model and ensemble models. Through experiments on MNIST, CIFAR-10 and GTSRB, we demonstrate improvements in training speed and certified accuracy compared to state-of-the-art certified defenses.", "pdf": "/pdf/8be2d30b90ff65b9cdd41dbedd032dcceabd7e12.pdf", "keywords": "[]", "id": "Hke_f0EYPH"}, {"number": "82", "title": "Equivariant neural networks and equivarification", "authors": "['Erkao Bao', 'Linqi Song']", "abstract": "A key difference from existing works is that our equivarification method can be applied without knowledge of the detailed functions of a layer in a neural network, and hence, can be generalized to any feedforward neural networks. Although the network size scales up, the constructed equivariant neural network does not increase the complexity of the network compared with the original one, in terms of the number of parameters. As an illustration, we build an equivariant neural network for image classification by equivarifying a convolutional neural network. Results show that our proposed method significantly reduces the design and training complexity, yet preserving the learning performance in terms of accuracy.", "pdf": "/pdf/9dfd9da1e9291567a85e8be6233f74fa0369ff49.pdf", "keywords": "['equivariant', 'invariant', 'neural network', 'equivarification']", "id": "BkxDthVtvS"}, {"number": "523", "title": "Unsupervised Universal Self-Attention Network for Graph Classification", "authors": "['Dai Quoc Nguyen', 'Tu Dinh Nguyen', 'Dinh Phung']", "abstract": "Existing graph embedding models often have weaknesses in exploiting graph structure similarities, potential dependencies among nodes and global network properties. To this end, we present U2GAN, a novel unsupervised model leveraging on the strength of the recently introduced universal self-attention network (Dehghani et al., 2019), to learn low-dimensional embeddings of graphs which can be used for graph classification. In particular, given an input graph, U2GAN first applies a self-attention computation, which is then followed by a recurrent transition to iteratively memorize its attention on vector representations of each node and its neighbors across each iteration. Thus, U2GAN can address the weaknesses in the existing models in order to produce plausible node embeddings whose sum is the final embedding of the whole graph. Experimental results show that our unsupervised U2GAN produces new state-of-the-art performances on a range of well-known benchmark datasets for the graph classification task. It even outperforms supervised methods in most of benchmark cases.", "pdf": "/pdf/890c4ec4c1c8106153bfa0fca28406f98ef8184d.pdf", "keywords": "['Graph embedding', 'graph classification', 'universal self-attention network', 'graph neural network']", "id": "HJeLBpEFPB"}, {"number": "1473", "title": "Towards Stable and Efficient Training of Verifiably Robust Neural Networks", "authors": "['Huan Zhang', 'Hongge Chen', 'Chaowei Xiao', 'Sven Gowal', 'Robert Stanforth', 'Bo Li', 'Duane Boning', 'Cho-Jui Hsieh']", "abstract": "Training neural networks with verifiable robustness guarantees is challenging. Several existing approaches utilize linear relaxation based neural network output bounds under perturbation, but they can slow down training by a factor of hundreds depending on the underlying network architectures. Meanwhile, interval bound propagation (IBP) based training is efficient and significantly outperforms linear relaxation based methods on many tasks, yet it may suffer from stability issues since the bounds are much looser especially at the beginning of training. In this paper, we propose a new certified adversarial training method, CROWN-IBP, by combining the fast IBP bounds in a forward bounding pass and a tight linear relaxation based bound, CROWN, in a backward bounding pass. CROWN-IBP is computationally efficient and consistently outperforms IBP baselines on training verifiably robust neural networks. We conduct large scale experiments on MNIST and CIFAR datasets, and outperform all previous linear relaxation and bound propagation based certified defenses in L_inf robustness.\nNotably, we achieve 7.02% verified test error on MNIST at epsilon=0.3, and 66.94% on CIFAR-10 with epsilon=8/255.", "pdf": "/pdf/06192b543d3903c59809e74c3c4d084d66eb4f77.pdf", "keywords": "['Robust Neural Networks', 'Verifiable Training', 'Certified Adversarial Defense']", "id": "Skxuk1rFwB"}, {"number": "1292", "title": "Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling", "authors": "['Ouyu Lan*', 'Xiao Huang*', 'Bill Yuchen Lin', 'He Jiang', 'Xiang Ren']", "abstract": "Sequence labeling is a fundamental framework for various natural language processing problems including part-of-speech tagging and named entity recognition. Its performance is largely influenced by the annotation quality and quantity in supervised learning scenarios.  In many cases, ground truth labels are costly and time-consuming to collect or even non-existent,  while imperfect ones could be easily accessed or transferred from different domains. A typical example is crowd-sourced datasets which have multiple annotations for each sentence which may be noisy or incomplete.   Additionally,  predictions from multiple source models in transfer learning can be seen as a case of multi-source supervision.  In this paper, we propose a novel framework named Consensus Network (CONNET) to conduct training with imperfect annotations from multiple sources.   It learns the representation for every weak supervision source and dynamically aggregates them by a context-aware attention mechanism.  Finally, it leads to a model reflecting the consensus among multiple sources.  We evaluate the proposed framework in two practical settings of multi-source learning:  learning with crowd annotations and unsupervised cross-domain model adaptation. Extensive experimental results show that our model achieves significant improvements over existing methods in both settings.", "pdf": "/pdf/33d72e3977a46779f756e0ed5fa803c8a3805bd9.pdf", "keywords": "['crowdsourcing', 'domain adaptation', 'sequence labeling', 'named entity recognition', 'weak supervision']", "id": "HJe9cR4KvB"}, {"number": "1090", "title": "BERT-AL: BERT for Arbitrarily Long Document Understanding", "authors": "['Ruixuan Zhang', 'Zhuoyu Wei', 'Yu Shi', 'Yining Chen']", "abstract": "Pretrained language models attract lots of attentions, and they take advantage of the two-stages training process: pretraining on huge corpus and finetuning on specific tasks. Thereinto, BERT (Devlin et al., 2019) is a Transformer (Vaswani et al., 2017) based model and has been the state-of-the-art for many kinds of Nature Language Processing (NLP) tasks. However, BERT cannot take text longer than the maximum length as input since the maximum length is predefined during pretraining. When we apply BERT to long text tasks, e.g., document-level text summarization: 1) Truncating inputs by the maximum sequence length will decrease performance, since the model cannot capture long dependency and global information ranging the whole document. 2) Extending the maximum length requires re-pretraining which will cost a mass of time and computing resources. What's even worse is that the computational complexity will increase quadratically with the length, which will result in an unacceptable training time. To resolve these problems, we propose to apply Transformer to only model local dependency and recurrently capture long dependency by inserting multi-channel LSTM into each layer of BERT. The proposed model is named as BERT-AL (BERT for Arbitrarily Long Document Understanding) and it can accept arbitrarily long input without re-pretraining from scratch. We demonstrate BERT-AL's effectiveness on text summarization by conducting experiments on the CNN/Daily Mail dataset. Furthermore, our method can be adapted to other Transformer based models, e.g., XLNet (Yang et al., 2019) and RoBERTa (Liu et al., 2019), for various NLP tasks with long text.", "pdf": "/pdf/92fa664b2e445ced111dd2f25a5807318c13a351.pdf", "keywords": "[]", "id": "SklnVAEFDB"}, {"number": "2072", "title": "A Generalized Training Approach for Multiagent Learning", "authors": "['Paul Muller', 'Shayegan Omidshafiei', 'Mark Rowland', 'Karl Tuyls', 'Julien Perolat', 'Siqi Liu', 'Daniel Hennes', 'Luke Marris', 'Marc Lanctot', 'Edward Hughes', 'Zhe Wang', 'Guy Lever', 'Nicolas Heess', 'Thore Graepel', 'Remi Munos']", "abstract": "This paper investigates a population-based training regime based on game-theoretic principles called Policy-Spaced Response Oracles (PSRO). PSRO is general in the sense that it (1) encompasses well-known algorithms such as fictitious play and double oracle as special cases, and (2) in principle applies to general-sum, many-player games. Despite this, prior studies of PSRO have been focused on two-player zero-sum games, a regime where in Nash equilibria are tractably computable. In moving from two-player zero-sum games to more general settings, computation of Nash equilibria quickly becomes infeasible.  Here, we extend the theoretical underpinnings of PSRO by considering an alternative solution concept, -Rank, which is unique (thus faces no equilibrium selection issues, unlike Nash) and applies readily to general-sum, many-player settings. We establish convergence guarantees in several games classes, and identify links between Nash equilibria and -Rank. We demonstrate the competitive performance of -Rank-based PSRO against an exact Nash solver-based PSRO in 2-player Kuhn and Leduc Poker. We then go beyond the reach of prior PSRO applications by considering 3- to 5-player poker games, yielding instances where -Rank achieves faster convergence than approximate Nash solvers, thus establishing it as a favorable general games solver. We also carry out an initial empirical validation in MuJoCo soccer, illustrating the feasibility of the proposed approach in another complex domain.", "pdf": "/pdf/7f3a5843704098cc456ab961def2f56902eaf1dd.pdf", "keywords": "['multiagent learning', 'game theory', 'training', 'games']", "id": "Bkl5kxrKDr"}, {"number": "857", "title": "Deep Multiple Instance Learning for Taxonomic Classification of Metagenomic read sets", "authors": "['Andreas Georgiou', 'Vincent Fortuin', 'Harun Mustafa', 'Gunnar R\u00e4tsch']", "abstract": "Metagenomic studies have increasingly utilized sequencing technologies in order to analyze DNA fragments found in environmental samples. It can provide useful insights for studying the interactions between hosts and microbes, infectious disease proliferation, and novel species discovery. One important step in this analysis is the taxonomic classification of those DNA fragments. Of particular interest is the determination of the distribution of the taxa of microbes in metagenomic samples. Recent attempts using deep learning focus on architectures that classify single DNA reads independently from each other. In this work, we attempt to solve the task of directly predicting the distribution over the taxa of whole metagenomic read sets. We formulate this task as a Multiple Instance Learning (MIL) problem. We extend architectures used in single-read taxonomic classification with two different types of permutation-invariant MIL pooling layers: a) deepsets and b) attention-based pooling. We illustrate that our architecture can exploit the co-occurrence of species in metagenomic read sets and outperforms the single-read architectures in predicting the distribution over the taxa at higher taxonomic ranks.", "pdf": "/pdf/9f5642678a828e2d9688bb9a363654a4835bded2.pdf", "keywords": "[]", "id": "HJl8AaVFwB"}, {"number": "591", "title": "VL-BERT: Pre-training of Generic Visual-Linguistic Representations", "authors": "['Weijie Su', 'Xizhou Zhu', 'Yue Cao', 'Bin Li', 'Lewei Lu', 'Furu Wei', 'Jifeng Dai']", "abstract": "We introduce a new pre-trainable generic representation for visual-linguistic tasks, called Visual-Linguistic BERT (VL-BERT for short). VL-BERT adopts the simple yet powerful Transformer model as the backbone, and extends it to take both visual and linguistic embedded features as input. In it, each element of the input is either of a word from the input sentence, or a region-of-interest (RoI) from the input image. It is designed to fit for most of the visual-linguistic downstream tasks. To better exploit the generic representation, we pre-train VL-BERT on the massive-scale Conceptual Captions dataset, together with text-only corpus. Extensive empirical analysis demonstrates that the pre-training procedure can better align the visual-linguistic clues and benefit the downstream tasks, such as visual commonsense reasoning, visual question answering and referring expression comprehension. It is worth noting that VL-BERT achieved the first place of single model on the leaderboard of the VCR benchmark.", "pdf": "/pdf/e81890cf813d756666607d9a5e43f5db490a5c98.pdf", "keywords": "['Visual-Linguistic', 'Generic Representation', 'Pre-training']", "id": "SygXPaEYvH"}, {"number": "640", "title": "BUZz: BUffer Zones for defending  adversarial examples in image classification", "authors": "['Phuong Ha Nguyen*', 'Kaleel Mahmood*', 'Lam M. Nguyen', 'Thanh Nguyen', 'Marten van Dijk']", "abstract": "We propose a novel defense against all existing gradient based adversarial attacks on deep neural networks for image classification problems. Our defense is based on a combination of deep neural networks and simple image transformations. While straight forward in implementation, this defense yields a unique security property which we term buffer zones. In this paper, we formalize the concept of buffer zones. We argue that our defense based on buffer zones is secure  against state-of-the-art black box attacks. We are able to achieve this security even when the adversary has access to the entire original training data set and unlimited query access to the defense. We verify our security claims through experimentation using FashionMNIST, CIFAR-10 and CIFAR-100. We demonstrate <10% attack success rate -- significantly lower than what other well-known defenses offer -- at only a price of a 15-20% drop in clean accuracy. By using a new intuitive metric we explain why this trade-off offers a significant improvement over prior work.", "pdf": "/pdf/59d5a7ec09ce48b4e9d64d00a2e6075f25e77fd0.pdf", "keywords": "['adversarial machine learning', 'machine learning security']", "id": "HJlY_6VKDr"}, {"number": "256", "title": "Hierarchical Foresight: Self-Supervised Learning of Long-Horizon Tasks via Visual Subgoal Generation", "authors": "['Suraj Nair', 'Chelsea Finn']", "abstract": "Video prediction models combined with planning algorithms have shown promise in enabling robots to learn to perform many vision-based tasks through only self-supervision, reaching novel goals in cluttered scenes with unseen objects. However, due to the compounding uncertainty in long horizon video prediction and poor scalability of sampling-based planning optimizers, one significant limitation of these approaches is the ability to plan over long horizons to reach distant goals. To that end, we propose a framework for subgoal generation and planning, hierarchical visual foresight (HVF), which generates subgoal images conditioned on a goal image, and uses them for planning. The subgoal images are directly optimized to decompose the task into easy to plan segments, and as a result, we observe that the method naturally identifies semantically meaningful states as subgoals. Across three out of four simulated vision-based manipulation tasks, we find that our method achieves more than 20% absolute performance improvement over planning without subgoals and model-free RL approaches. Further, our experiments illustrate that our approach extends to real, cluttered visual scenes.", "pdf": "/pdf/aa5541d4bdbf7a204c65f956284a12d430af31bb.pdf", "keywords": "['video prediction', 'reinforcement learning', 'planning']", "id": "H1gzR2VKDH"}, {"number": "1347", "title": "Biologically inspired sleep algorithm for increased generalization and adversarial robustness in deep neural networks", "authors": "['Timothy Tadros', 'Giri Krishnan', 'Ramyaa Ramyaa', 'Maxim Bazhenov']", "abstract": "Current artificial neural networks (ANNs) can perform and excel at a variety of tasks ranging from image classification to spam detection through training on large datasets of labeled data. While the trained network may perform well on similar testing data, inputs that differ even slightly from the training data may trigger unpredictable behavior. Due to this limitation, it is possible to design inputs with very small perturbations that can result in misclassification. These adversarial attacks present a security risk to deployed ANNs and indicate a divergence between how ANNs and humans perform classification. Humans are robust at behaving in the presence of noise and are capable of correctly classifying objects that are noisy, blurred, or otherwise distorted.  It has been hypothesized that sleep promotes generalization of knowledge and improves robustness against noise in animals and humans. In this work, we utilize a biologically inspired sleep phase in ANNs and demonstrate the benefit of sleep on defending against adversarial attacks as well as in increasing ANN classification robustness. We compare the sleep algorithm's performance on various robustness tasks with two previously proposed adversarial defenses - defensive distillation and fine-tuning. We report an increase in robustness after sleep phase to adversarial attacks as well as to general image distortions for three datasets: MNIST, CUB200, and a toy dataset. Overall, these results demonstrate the potential for biologically inspired solutions to solve existing problems in ANNs and guide the development of more robust, human-like ANNs.", "pdf": "/pdf/23bc921edfb8cc42a65a409f7156a6ef2daed92f.pdf", "keywords": "['Adversarial Robustness', 'Generalization', 'Neural Computing', 'Deep Learning']", "id": "r1xGnA4Kvr"}, {"number": "157", "title": "Scalable and Order-robust Continual Learning with Additive Parameter Decomposition", "authors": "['Jaehong Yoon', 'Saehoon Kim', 'Eunho Yang', 'Sung Ju Hwang']", "abstract": "While recent continual learning methods largely alleviate the catastrophic problem on toy-sized datasets, there are issues that remain to be tackled in order to apply them to real-world problem domains. First, a continual learning model should effectively handle catastrophic forgetting and be efficient to train even with a large number of tasks. Secondly, it needs to tackle the problem of order-sensitivity, where the performance of the tasks largely varies based on the order of the task arrival sequence, as it may cause serious problems where fairness plays a critical role (e.g. medical diagnosis). To tackle these practical challenges, we propose a novel continual learning method that is scalable as well as order-robust, which instead of learning a completely shared set of weights, represents the parameters  for each task as a sum of task-shared and sparse task-adaptive parameters. With our Additive Parameter Decomposition (APD), the task-adaptive parameters for earlier tasks remain mostly unaffected, where we update them only to reflect the changes made to the task-shared parameters. This decomposition of parameters effectively prevents catastrophic forgetting and order-sensitivity, while being computation- and memory-efficient. Further, we can achieve even better scalability with APD using hierarchical knowledge consolidation, which clusters the task-adaptive parameters to obtain hierarchically shared parameters. We validate our network with APD, APD-Net, on multiple benchmark datasets against state-of-the-art continual learning methods, which it largely outperforms in accuracy, scalability, and order-robustness.", "pdf": "/pdf/b49a92bb73462108bc002c7b9d60328265a050e1.pdf", "keywords": "['Continual Learning', 'Lifelong Learning', 'Catastrophic Forgetting', 'Deep Learning']", "id": "r1gdj2EKPB"}, {"number": "326", "title": "Ecological Reinforcement Learning", "authors": "['John D. Co-Reyes', 'Suvansh Sanjeev', 'Glen Berseth', 'Abhishek Gupta', 'Sergey Levine']", "abstract": "Reinforcement learning algorithms have been shown to effectively learn tasks in a variety of static, deterministic, and  simplistic environments, but their application to environments which are characteristic of dynamic lifelong settings encountered in the real world has been limited. Understanding the impact of specific environmental properties on the learning dynamics of reinforcement learning algorithms is important as we want to align the environments in which we develop our algorithms with the real world, and this is strongly coupled with the type of intelligence which can be learned. In this work, we study what we refer to as ecological reinforcement learning: the interaction between properties of the environment and the reinforcement learning agent. To this end, we introduce environments with characteristics that we argue better reflect natural environments: non-episodic learning, uninformative ``fundamental drive'' reward signals, and natural dynamics that cause the environment to change even when the agent fails to take intelligent actions. We show these factors can have a profound effect on the learning progress of reinforcement learning algorithms. Surprisingly, we find that these seemingly more challenging learning conditions can often make reinforcement learning agents learn more effectively. Through this study, we hope to shift the focus of the community towards learning in realistic, natural environments with dynamic elements.", "pdf": "/pdf/ab410b0e9755809ecd4e5d471fe710b07f5148b0.pdf", "keywords": "['non-episodic', 'environment analysis', 'reward shaping', 'curriculum learning']", "id": "S1xxx64YwH"}, {"number": "2531", "title": "Variational Information Bottleneck for Unsupervised Clustering: Deep Gaussian Mixture Embedding", "authors": "['Yigit Ugur', 'George Arvanitakis', 'Abdellatif Zaidi']", "abstract": "In this paper, we develop an unsupervised generative clustering framework that combines variational information bottleneck and the Gaussian Mixture Model. Specifically, in our approach we use the variational information bottleneck method and model the latent space as a mixture of Gaussians. We derive a bound on the cost function of our model that generalizes the evidence lower bound (ELBO); and provide a variational inference type algorithm that allows to compute it. In the algorithm, the coders mappings are parametrized using neural networks and the bound is approximated by Markov sampling and optimized with stochastic gradient descent. Numerical results on real datasets are provided to support the efficiency of our method.", "pdf": "/pdf/9119343fd57e297acd3a2f2eb992c64a12353527.pdf", "keywords": "['clustering', 'Variational Information Bottleneck', 'Gaussian Mixture Model']", "id": "HyxQ3gSKvr"}, {"number": "1805", "title": "Skew-Fit: State-Covering Self-Supervised Reinforcement Learning", "authors": "['Vitchyr H. Pong', 'Murtaza Dalal', 'Steven Lin', 'Ashvin Nair', 'Shikhar Bahl', 'Sergey Levine']", "abstract": "Autonomous agents that must exhibit flexible and broad capabilities will need to be equipped with large repertoires of skills. Defining each skill with a manually-designed reward function limits this repertoire and imposes a manual engineering burden. Self-supervised agents that set their own goals can automate this process, but designing appropriate goal setting objectives can be difficult, and often involves heuristic design decisions. In this paper, we propose a formal exploration objective for goal-reaching policies that maximizes state coverage. We show that this objective is equivalent to maximizing the entropy of the goal distribution together with goal reaching performance, where goals correspond to full state observations. To instantiate this principle, we present an algorithm called Skew-Fit for learning a maximum-entropy goal distributions. Skew-Fit enables self-supervised agents to autonomously choose and practice reaching diverse goals. We show that, under certain regularity conditions, our method converges to a uniform distribution over the set of valid states, even when we do not know this set beforehand. Our experiments show that it can learn a variety of manipulation tasks from images, including opening a door with a real robot, entirely from scratch and without any manually-designed reward function.", "pdf": "/pdf/75b54ec2afc748a7f962d69b6e1ebd3d40762570.pdf", "keywords": "['deep reinforcement learning', 'goal space', 'goal conditioned reinforcement learning', 'self-supervised reinforcement learning', 'goal sampling', 'reinforcement learning']", "id": "r1gIdySFPH"}, {"number": "2366", "title": "Multi-source Multi-view Transfer Learning in Neural Topic Modeling with Pretrained Topic and Word Embeddings", "authors": "['Pankaj Gupta', 'Yatin Chaudhary', 'Hinrich Sch\u00fctze']", "abstract": "Though word embeddings and topics are complementary representations, several\npast works have only used pretrained word embeddings in (neural) topic modeling\nto address data sparsity problem in short text or small collection of documents.\nHowever, no prior work has employed (pretrained latent) topics in transfer learning\nparadigm. In this paper, we propose a framework to perform transfer learning\nin neural topic modeling using (1) pretrained (latent) topics obtained from a large\nsource corpus, and (2) pretrained word and topic embeddings jointly (i.e., multiview)\nin order to improve topic quality, better deal with polysemy and data sparsity\nissues in a target corpus. In doing so, we first accumulate topics and word representations\nfrom one or many source corpora to build respective pools of pretrained\ntopic (i.e., TopicPool) and word embeddings (i.e., WordPool). Then, we identify\none or multiple relevant source domain(s) and take advantage of corresponding\ntopics and word features via the respective pools to guide meaningful learning\nin the sparse target domain. We quantify the quality of topic and document representations\nvia generalization (perplexity), interpretability (topic coherence) and\ninformation retrieval (IR) using short-text, long-text, small and large document\ncollections from news and medical domains. We have demonstrated the state-ofthe-\nart results on topic modeling with the proposed transfer learning approaches.", "pdf": "/pdf/630308393f9cfa9270786bed087dacfaee1ec11b.pdf", "keywords": "['Neural Topic Modeling', 'Transfer Learning', 'Unsupervised learning', 'Natural Language Processing']", "id": "ByxODxHYwB"}, {"number": "2439", "title": "Laconic Image Classification: Human vs. Machine Performance", "authors": "['Javier Carrasco', 'Aidan Hogan', 'Jorge P\u00e9rez']", "abstract": "We propose laconic classification as a novel way to understand and compare the performance of diverse image classifiers. The goal in this setting is to minimise the amount of information (aka. entropy) required in individual test images to maintain correct classification. Given a classifier and a test image, we compute an approximate minimal-entropy positive image for which the classifier provides a correct classification, becoming incorrect upon any further reduction. The notion of entropy offers a unifying metric that allows to combine and compare the effects of various types of reductions (e.g., crop, colour reduction, resolution reduction) on classification performance, in turn generalising similar methods explored in previous works. Proposing two complementary frameworks for computing the minimal-entropy positive images of both human and machine classifiers, in experiments over the ILSVRC test-set, we find that machine classifiers are more sensitive entropy-wise to reduced resolution (versus cropping or reduced colour for machines, as well as reduced resolution for humans), supporting recent results suggesting a texture bias in the ILSVRC-trained models used. We also find, in the evaluated setting, that humans classify the minimal-entropy positive images of machine models with higher precision than machines classify those of humans.", "pdf": "/pdf/9df6c5ed4c6fd3a172d7a34ff503862e94d95ce1.pdf", "keywords": "['minimal images', 'entropy', 'human vs. machine performance']", "id": "rJgPFgHFwr"}, {"number": "1585", "title": "Double Neural Counterfactual Regret Minimization", "authors": "['Hui Li', 'Kailiang Hu', 'Shaohua Zhang', 'Yuan Qi', 'Le Song']", "abstract": "Counterfactual regret minimization (CFR) is a fundamental and effective technique for solving Imperfect Information Games (IIG). However, the original CFR algorithm only works for discrete states and action spaces, and the resulting strategy is maintained as a tabular representation. Such tabular representation limits the method from being directly applied to large games. In this paper, we propose a double neural representation for the IIGs, where one neural network represents the cumulative regret, and the other represents the average strategy.  Such neural representations allow us to avoid manual game abstraction and carry out end-to-end optimization. To make the learning efficient, we also developed several novel techniques including a robust sampling method and a mini-batch Monte Carlo Counterfactual Regret Minimization (MCCFR) method, which may be of independent interests.  Empirically, on games tractable to tabular approaches, neural strategies trained with our algorithm converge comparably to their tabular counterparts, and significantly outperform those based on deep reinforcement learning.  On extremely large games with billions of decision nodes, our approach achieved strong performance while using hundreds of times less memory than the tabular CFR. On head-to-head matches of hands-up no-limit texas hold'em, our neural agent beat the strong agent ABS-CFR by $9.8\\pm4.1$ chips per game. It's a successful application of neural CFR in large games.\n", "pdf": "/pdf/b8cc78ebf1ae64586fb7ed77793297f0a9b4a816.pdf", "keywords": "['Counterfactual Regret Minimization', 'Imperfect Information game', 'Neural Strategy', 'Deep Learning', 'Robust Sampling']", "id": "ByedzkrKvH"}, {"number": "936", "title": "Neural Text Generation With Unlikelihood Training", "authors": "['Sean Welleck', 'Ilia Kulikov', 'Stephen Roller', 'Emily Dinan', 'Kyunghyun Cho', 'Jason Weston']", "abstract": "Neural text generation is a key tool in natural language applications, but it is well known there are major problems at its core. In particular, standard likelihood training and decoding leads to dull and repetitive outputs. While some post-hoc fixes have been proposed, in particular top-k and nucleus sampling, they do not address the fact that the token-level probabilities predicted by the model are poor. In this paper we show that the likelihood objective itself is at fault, resulting in a model that assigns too much probability to sequences containing repeats and frequent words, unlike those from the human training distribution. We propose a new objective, unlikelihood training, which forces unlikely generations to be assigned lower probability by the model. We show that both token and sequence level unlikelihood training give less repetitive, less dull text while maintaining perplexity, giving superior generations using standard greedy or beam search. According to human evaluations, our approach with standard beam search also outperforms the currently popular decoding methods of nucleus sampling or beam blocking, thus providing a strong alternative to existing techniques.", "pdf": "/pdf/b1605077dc551ef983c69ef382a249fb5048060d.pdf", "keywords": "['language modeling', 'machine learning']", "id": "SJeYe0NtvH"}, {"number": "1399", "title": "From Inference to Generation: End-to-end Fully Self-supervised Generation of Human Face from Speech", "authors": "['Hyeong-Seok Choi', 'Changdae Park', 'Kyogu Lee']", "abstract": "This work seeks the possibility of generating the human face from voice solely based on the audio-visual data without any human-labeled annotations. To this end, we propose a multi-modal learning framework that links the inference stage and generation stage. First, the inference networks are trained to match the speaker identity between the two different modalities. Then the pre-trained inference networks cooperate with the generation network by giving conditional information about the voice. The proposed method exploits the recent development of GANs techniques and generates the human face directly from the speech waveform making our system fully end-to-end. We analyze the extent to which the network can naturally disentangle two latent factors that contribute to the generation of a face image one that comes directly from a speech signal and the other that is not related to it and explore whether the network can learn to generate natural human face image distribution by modeling these factors. Experimental results show that the proposed network can not only match the relationship between the human face and speech, but can also generate the high-quality human face sample conditioned on its speech. Finally, the correlation between the generated face and the corresponding speech is quantitatively measured to analyze the relationship between the two modalities.", "pdf": "/pdf/e2eb3ce3e64f68afdde63f27bde08fd98bd51db0.pdf", "keywords": "['Multi-modal learning', 'Self-supervised learning', 'Voice profiling', 'Conditional GANs']", "id": "H1guaREYPr"}, {"number": "2243", "title": "DO-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images", "authors": "['Tianshuo Cong', 'Dan Peng', 'Furui Liu', 'Zhitang Chen']", "abstract": "Some fundamental limitations of deep learning have been exposed such as lacking generalizability and being vunerable to adversarial attack. Instead, researchers realize that causation is much more stable than association relationship in data. In this paper, we propose a new framework called do-calculus AutoEncoder(DO-AE) for deep representation learning that fully capture bivariate causal relationship in the images which allows us to intervene in images generation process. DO-AE consists of two key ingredients: causal relationship mining in images and intervention-enabling deep causal structured representation learning. The goal here is to learn deep representations that correspond to the concepts in the physical world as well as their causal structure. To verify the proposed method, we create a dataset named PHY2D, which contains abstract graphic description in accordance with the laws of physics. Our experiments demonstrate our method is able to correctly identify the bivariate causal relationship between concepts in images and the representation learned enables a do-calculus manipulation to images, which generates artificial images that might possibly break the physical law depending on where we intervene the causal system.", "pdf": "/pdf/c75e7d930ec5a0bf2427b3cc38fcc6a8fe9ef579.pdf", "keywords": "['Causality discovery', 'AutoEncoder', 'Deep representation learning', 'Do-calculus']", "id": "r1e7NgrYvH"}, {"number": "793", "title": "Quantum Expectation-Maximization for Gaussian Mixture Models", "authors": "['Iordanis Kerenidis', 'Anupam Prakash', 'Alessandro Luongo']", "abstract": "The Expectation-Maximization (EM) algorithm is a fundamental tool in unsupervised machine learning. It is often used as an efficient way to solve Maximum Likelihood (ML) and Maximum A Posteriori estimation problems, especially for models with latent variables. It is also the algorithm of choice to fit mixture models: generative models that represent unlabelled points originating from $k$ different processes, as samples from $k$ multivariate distributions. In this work we define and use a quantum version of EM to fit a Gaussian Mixture Model. Given quantum access to a dataset of $n$ vectors of dimension $d$, our algorithm has convergence and precision guarantees similar to the classical algorithm, but the runtime is only polylogarithmic in the number of elements in the training set, and is polynomial in other parameters - as the dimension of the feature space, and the number of components in the mixture. We generalize further the algorithm by fitting any mixture model of base distributions in the exponential family. We discuss the performance of the algorithm on datasets that are expected to be classified successfully by those algorithms, arguing that on those cases we can give strong guarantees on the runtime.", "pdf": "/pdf/6b9c6f7549b48b1e16d31713875b905c7dbec30d.pdf", "keywords": "['Quantum', 'ExpectationMaximization', 'Unsupervised', 'QRAM']", "id": "Hkgs3aNYDS"}, {"number": "1611", "title": "Continual Density Ratio Estimation (CDRE): A new method for evaluating generative models in continual learning", "authors": "['Yu Chen', 'Song Liu', 'Tom Diethe', 'Peter Flach']", "abstract": "We propose a new method Continual Density Ratio Estimation (CDRE), which can estimate density ratios between a target distribution of real samples and a distribution of samples generated by a model while the model is changing over time and the data of the target distribution is not available after a certain time point. This method perfectly fits the setting of continual learning, in which one model is supposed to learn different tasks sequentially and the most crucial restriction is that model has none or very limited access to the data of all learned tasks. Through CDRE, we can evaluate generative models in continual learning using f-divergences. To the best of our knowledge, there is no existing method that can evaluate generative models under the setting of continual learning without storing real samples from the target distribution.", "pdf": "/pdf/bacfa0fe1e3cc463ee5675f850b1b230c7845f3a.pdf", "keywords": "['density ratio estimation', 'continual learning', 'evaluation', 'generative model', 'f divergence']", "id": "HJemQJBKDr"}, {"number": "248", "title": "TabFact: A Large-scale Dataset for Table-based Fact Verification", "authors": "['Wenhu Chen', 'Hongmin Wang', 'Jianshu Chen', 'Yunkai Zhang', 'Hong Wang', 'Shiyang Li', 'Xiyou Zhou', 'William Yang Wang']", "abstract": "The problem of verifying whether a textual hypothesis holds based on the given evidence, also known as fact verification, plays an important role in the study of natural language understanding and semantic representation. However, existing studies are mainly restricted to dealing with unstructured evidence (e.g., natural language sentences and documents, news, etc), while verification under structured evidence, such as tables, graphs, and databases, remains unexplored. This paper specifically aims to study the fact verification given semi-structured data as evidence. To this end, we construct a large-scale dataset called TabFact with 16k Wikipedia tables as the evidence for 118k human-annotated natural language statements, which are labeled as either ENTAILED or REFUTED. TabFact is challenging since it involves both soft linguistic reasoning and hard symbolic reasoning. To address these reasoning challenges, we design two different models: Table-BERT and Latent Program Algorithm (LPA). Table-BERT leverages the state-of-the-art pre-trained language model to encode the linearized tables and statements into continuous vectors for verification. LPA parses statements into LISP-like programs and executes them against the tables to obtain the returned binary value for verification. Both methods achieve similar accuracy but still lag far behind human performance. We also perform a comprehensive analysis to demonstrate great future opportunities.", "pdf": "/pdf/3119bcb6199dfa1eeb714b26144530ce1d987a2a.pdf", "keywords": "['Fact Verification', 'Tabular Data', 'Symbolic Reasoning']", "id": "rkeJRhNYDH"}, {"number": "540", "title": "Piecewise linear activations substantially shape the loss surfaces of neural networks", "authors": "['Fengxiang He', 'Bohan Wang', 'Dacheng Tao']", "abstract": "Understanding the loss surface of a neural network is fundamentally important to the understanding of deep learning. This paper presents how piecewise linear activation functions substantially shape the loss surfaces of neural networks. We first prove that {\\it the loss surfaces of many neural networks have infinite spurious local minima} which are defined as the local minima with higher empirical risks than the global minima. Our result demonstrates that the networks with piecewise linear activations possess substantial differences to the well-studied linear neural networks. This result holds for any neural network with arbitrary depth and arbitrary piecewise linear activation functions (excluding linear functions) under most loss functions in practice. Essentially, the underlying assumptions are consistent with most practical circumstances where the output layer is narrower than any hidden layer. In addition, the loss surface of a neural network with piecewise linear activations is partitioned into multiple smooth and multilinear cells by nondifferentiable boundaries. The constructed spurious local minima are concentrated in one cell as a valley: they are connected with each other by a continuous path, on which empirical risk is invariant. Further for one-hidden-layer networks, we prove that all local minima in a cell constitute an equivalence class; they are concentrated in a valley; and they are all global minima in the cell.", "pdf": "/pdf/9fc93c5ae0dcd8dffa1b0e77e1ec74c59f92d8a8.pdf", "keywords": "['neural network', 'nonlinear activation', 'loss surface', 'spurious local minimum']", "id": "B1x6BTEKwr"}, {"number": "642", "title": "Model-based Saliency for the Detection of Adversarial Examples", "authors": "['Lisa Schut', 'Yarin Gal']", "abstract": "Adversarial perturbations cause a shift in the salient features of an image, which may result in a misclassification. We demonstrate that gradient-based saliency approaches are unable to capture this shift, and develop a new defense which detects adversarial examples based on learnt saliency models instead. We study two approaches: a CNN trained to distinguish between natural and adversarial images using the saliency masks produced by our learnt saliency model, and a CNN trained on the salient pixels themselves as its input. On MNIST, CIFAR-10 and ASSIRA, our defenses are able to detect various adversarial attacks, including strong attacks such as C&W and DeepFool, contrary to gradient-based saliency and detectors which rely on the input image. The latter are unable to detect adversarial images when the L_2- and L_infinity- norms of the perturbations are too small. Lastly, we find that the salient pixel based detector improves on saliency map based detectors as it is more robust to white-box attacks.", "pdf": "/pdf/37a8a79df61747fa43219cde649fe785fe2c7aee.pdf", "keywords": "['Adversarial Examples', 'Defense', 'Model-based Saliency']", "id": "HJe5_6VKwS"}, {"number": "339", "title": "Hierarchical Disentangle Network for Object Representation Learning", "authors": "['Shishi Qiao', 'Ruiping Wang', 'Shiguang Shan', 'Xilin Chen']", "abstract": "An object can be described as the combination of primary visual attributes. Disentangling such underlying primitives is the long objective of representation learning. It is observed that categories have the natural multi-granularity or hierarchical characteristics, i.e. any two objects can share some common primitives in a particular category granularity while they may possess their unique ones in another granularity. However, previous works usually operate in a flat manner (i.e. in a particular granularity) to disentangle the representations of objects. Though they may obtain the primitives to constitute objects as the categories in that granularity, their results are obviously not efficient and complete. In this paper, we propose the hierarchical disentangle network (HDN) to exploit the rich hierarchical characteristics among categories to divide the disentangling process in a coarse-to-fine manner, such that each level only focuses on learning the specific representations in its granularity and finally the common and unique representations in all granularities jointly constitute the raw object. Specifically, HDN is designed based on an encoder-decoder architecture. To simultaneously ensure the disentanglement and interpretability of the encoded representations, a novel hierarchical generative adversarial network (GAN) is elaborately designed. Quantitative and qualitative evaluations on four object datasets validate the effectiveness of our method.", "pdf": "/pdf/c2e51052dbff2225f639ed34102a38d146ce68a6.pdf", "keywords": "[]", "id": "rkg8xTEtvB"}, {"number": "505", "title": "DYNAMIC SELF-TRAINING FRAMEWORK  FOR GRAPH CONVOLUTIONAL NETWORKS", "authors": "['Ziang Zhou', 'Shenzhong Zhang', 'Zengfeng Huang']", "abstract": "Graph neural networks (GNN) such as GCN, GAT, MoNet have achieved state-of-the-art results on semi-supervised learning on graphs. However, when the number of labeled nodes is very small, the performances of GNNs downgrade dramatically. Self-training has proved to be effective for resolving this issue, however, the performance of self-trained GCN is still inferior to that of G2G and DGI for many settings. Moreover, additional model complexity make it more difficult to tune the hyper-parameters and do model selection. We argue that the power of self-training is still not fully explored for the node classification task. In this paper, we propose a unified end-to-end self-training framework called \\emph{Dynamic Self-traning}, which generalizes and simplifies prior work. A simple instantiation of the framework based on GCN is provided and empirical results show that our framework outperforms all previous methods including GNNs, embedding based method and  self-trained GCNs by a noticeable margin. Moreover, compared with standard self-training, hyper-parameter tuning for our framework is easier.", "pdf": "/pdf/15d64d7eae0a0667de0c3bfa5c4821f40f2cf63b.pdf", "keywords": "['self-training', 'semi-supervised learning', 'graph convolutional networks']", "id": "SJgCEpVtvr"}, {"number": "1647", "title": "A Random Matrix Perspective on Mixtures of Nonlinearities in High Dimensions", "authors": "['Ben Adlam', 'Jake Levinson', 'Jeffrey Pennington']", "abstract": "One of the distinguishing characteristics of modern deep learning systems is that they typically employ neural network architectures that utilize enormous numbers of parameters, often in the millions and sometimes even in the billions. While this paradigm has inspired significant research on the properties of large networks, relatively little work has been devoted to the fact that these networks are often used to model large complex datasets, which may themselves contain millions or even billions of constraints. In this work, we focus on this high-dimensional regime in which both the dataset size and the number of features tend to infinity. We analyze the performance of a simple regression model trained on the random features $F=f(WX+B)$ for a random weight matrix $W$ and random bias vector $B$, obtaining an exact formula for the asymptotic training error on a noisy autoencoding task. The role of the bias can be understood as parameterizing a distribution over activation functions, and our analysis actually extends to general such distributions, even those not expressible with a traditional additive bias. Intruigingly, we find that a mixture of nonlinearities can outperform the best single nonlinearity on the noisy autoecndoing task, suggesting that mixtures of nonlinearities might be useful for approximate kernel methods or neural network architecture design.", "pdf": "/pdf/ce43d830186bc4455778324d5c578d134adaf67f.pdf", "keywords": "[]", "id": "BJx7N1SKvB"}, {"number": "244", "title": "Implicit Bias of Gradient Descent based Adversarial Training on Separable Data", "authors": "['Yan Li', 'Ethan X.Fang', 'Huan Xu', 'Tuo Zhao']", "abstract": "Adversarial training is a principled approach for training robust neural networks. Despite of tremendous successes in practice, its theoretical properties still remain largely unexplored. In this paper, we provide new theoretical insights of gradient descent based adversarial training by studying its computational properties, specifically on its implicit bias. We take the binary classification task on linearly separable data as an illustrative example, where the loss asymptotically attains its infimum as the parameter diverges to infinity along certain directions. Specifically, we show that for any fixed iteration $T$, when the adversarial perturbation during training has proper bounded L2 norm,  the classifier learned by gradient descent based adversarial training converges in direction to the maximum L2 norm margin classifier at the rate of $O(1/\\sqrt{T})$, significantly faster than the rate $O(1/\\log T}$ of training with clean data. In addition, when the adversarial perturbation during training has bounded Lq norm, the resulting classifier converges in direction to a maximum mixed-norm margin classifier, which has a natural interpretation of robustness, as being the maximum L2 norm margin classifier under worst-case bounded Lq norm perturbation to the data.  Our findings provide theoretical backups for adversarial training that it indeed promotes robustness against adversarial perturbation.", "pdf": "/pdf/4c97f1e2f10751f45110d91b3db5805e5766cae0.pdf", "keywords": "['implicit bias', 'adversarial training', 'robustness', 'gradient descent']", "id": "HkgTTh4FDH"}, {"number": "906", "title": "First-Order Preconditioning via Hypergradient Descent", "authors": "['Ted Moskovitz', 'Rui Wang', 'Janice Lan', 'Sanyam Kapoor', 'Thomas Miconi', 'Jason Yosinski', 'Aditya Rawal']", "abstract": "Standard gradient-descent methods are susceptible to a range of issues that can impede training, such as high correlations and different scaling in parameter space. These difficulties can be addressed by second-order approaches that apply a preconditioning matrix to the gradient to improve convergence.  Unfortunately, such algorithms typically struggle to scale to high-dimensional problems, in part because the calculation of specific preconditioners such as the inverse Hessian or Fisher information matrix is highly expensive. We introduce first-order preconditioning (FOP), a fast, scalable approach that generalizes previous work on hypergradient descent (Almeida et al., 1998; Maclaurin et al., 2015; Baydin et al., 2017) to learn a preconditioning matrix that only makes use of first-order information. Experiments show that FOP is able to improve the performance of standard deep learning optimizers on several visual classification tasks with minimal computational overhead. We also investigate the properties of the learned preconditioning matrices and perform a preliminary theoretical analysis of the algorithm.", "pdf": "/pdf/696ce02ead07c34c2a1c7824201a8c814bfe58fe.pdf", "keywords": "['optimization', 'deep learning', 'hypgergradient']", "id": "Skg3104FDS"}, {"number": "1836", "title": "Target-Embedding Autoencoders for Supervised Representation Learning", "authors": "['Daniel Jarrett', 'Mihaela van der Schaar']", "abstract": "Autoencoder-based learning has emerged as a staple for disciplining representations in unsupervised and semi-supervised settings. This paper analyzes a framework for improving generalization in a purely supervised setting, where the target space is high-dimensional. We motivate and formalize the general framework of target-embedding autoencoders (TEA) for supervised prediction, learning intermediate latent representations jointly optimized to be both predictable from features as well as predictive of targets---encoding the prior that variations in targets are driven by a compact set of underlying factors. As our theoretical contribution, we provide a guarantee of generalization for linear TEAs by demonstrating uniform stability, interpreting the benefit of the auxiliary reconstruction task as a form of regularization. As our empirical contribution, we extend validation of this approach beyond existing static classification applications to multivariate sequence forecasting, verifying their advantage on both linear and nonlinear recurrent architectures---thereby underscoring the further generality of this framework beyond feedforward instantiations.", "pdf": "/pdf/faa226acb48cee96a11ff11e7382d4999f80dc00.pdf", "keywords": "['autoencoders', 'supervised learning', 'representation learning', 'target-embedding', 'label-embedding']", "id": "BygXFkSYDH"}, {"number": "2424", "title": "Deep Interaction Processes for Time-Evolving Graphs", "authors": "['xiaofu chang', 'jianfeng wen', 'xuqin liu', 'yanming fang', 'le song', 'yuan qi']", "abstract": "Time-evolving graphs are ubiquitous such as online transactions on an e-commerce platform and user interactions on social networks. While neural approaches have been proposed for graph modeling, most of them focus on static graphs. In this paper we present a principled deep neural approach that models continuous time-evolving graphs at multiple time resolutions based on a temporal point process framework.  To model the dependency between latent dynamic representations of each node, we define a mixture of temporal cascades in which a node's neural representation depends on not only this node's previous representations but also the previous representations of related nodes that have interacted with this node. We generalize LSTM on this temporal cascade mixture and introduce novel time gates to model time intervals between interactions. Furthermore, we introduce a selection mechanism that gives important nodes large influence in both $k-$hop subgraphs of nodes in an interaction. To capture temporal dependency at multiple time-resolutions, we stack our neural representations in several layers and fuse them based on attention. Based on the temporal point process framework, our approach can naturally handle growth (and shrinkage) of graph nodes and interactions, making it inductive. Experimental results on interaction prediction and classification tasks -- including a  real-world financial application --  illustrate the effectiveness of the time gate, the selection and attention mechanisms of our approach, as well as its \nsuperior performance over the alternative approaches.", "pdf": "/pdf/23de29b2b72a376d3683d26fdb50dce4854d11b2.pdf", "keywords": "['deep temporal point process', 'multiple time resolutions', 'dynamic continuous time-evolving graph', 'anti-fraud detection']", "id": "HyxWteSFwS"}, {"number": "945", "title": "New Loss Functions for Fast Maximum Inner Product Search", "authors": "['Ruiqi Guo', 'Quan Geng', 'David Simcha', 'Felix Chern', 'Phil Sun', 'Sanjiv Kumar']", "abstract": "Quantization based methods are popular for solving large scale maximum inner product search problems. However, in most traditional quantization works, the objective is to minimize the reconstruction error for datapoints to be searched. In this work, we focus directly on minimizing error in inner product approximation and derive a new class of quantization loss functions. One key aspect of the new loss functions is that we weight the error term based on the value of the inner product, giving more importance to pairs of queries and datapoints whose inner products are high. We provide theoretical grounding to the new quantization loss function, which is simple, intuitive and able to work with a variety of quantization techniques, including binary quantization and product quantization. We conduct experiments on public benchmarking datasets \\url{http://ann-benchmarks.com} to demonstrate that our method using the new objective outperforms other state-of-the-art methods. We are committed to release our source code.", "pdf": "/pdf/1a6e7ff2b3b00348070a28893c6c3018051d187f.pdf", "keywords": "[]", "id": "BkeaxAEKvB"}, {"number": "1130", "title": "Learning to Learn by Zeroth-Order Oracle", "authors": "['Yangjun Ruan', 'Yuanhao Xiong', 'Sashank Reddi', 'Sanjiv Kumar', 'Cho-Jui Hsieh']", "abstract": "In the learning to learn (L2L) framework, we cast the design of optimization algorithms as a machine learning problem and use deep neural networks to learn the update rules. In this paper, we extend the L2L framework to zeroth-order (ZO) optimization setting, where no explicit gradient information is available. Our learned optimizer, modeled as recurrent neural network (RNN), first approximates gradient by ZO gradient estimator and then produces parameter update utilizing the knowledge of previous iterations. To reduce high variance effect due to ZO gradient estimator, we further introduce another RNN to learn the Gaussian sampling rule and dynamically guide the query direction sampling. Our learned optimizer outperforms hand-designed algorithms in terms of convergence rate and final solution on both synthetic and practical ZO optimization tasks (in particular, the black-box adversarial attack task, which is one of the most widely used tasks of ZO optimization). We finally conduct extensive analytical experiments to demonstrate the effectiveness of our proposed optimizer.", "pdf": "/pdf/82af16aa7747c67c67a200a7387e65361e9958d2.pdf", "keywords": "['learning to learn', 'zeroth-order optimization', 'black-box adversarial attack']", "id": "ryxz8CVYDH"}, {"number": "1147", "title": "Neural Clustering Processes", "authors": "['Ari Pakman', 'Yueqi Wang', 'Catalin Mitelut', 'JinHyung Lee', 'Liam Paninski']", "abstract": "Mixture models, a basic building block in countless statistical models, involve latent random variables over discrete spaces, and existing posterior inference methods can be inaccurate and/or very slow.  In this work we introduce a novel deep learning architecture for efficient amortized Bayesian inference over mixture models. While previous approaches to amortized clustering assumed a fixed or maximum number of mixture components and only amortized over the continuous parameters of each mixture component, our method amortizes over the local discrete labels of all the data points, and performs inference over an unbounded number of mixture components. The latter property makes our method natural for the challenging case of nonparametric Bayesian models, where the number of mixture components grows with the dataset. Our approach exploits the exchangeability of the generative models and is based on mapping distributed, permutation-invariant representations of discrete  arrangements into varying-size multinomial conditional probabilities. The resulting algorithm parallelizes easily, yields iid samples from the approximate posteriors along with a normalized probability estimate of each sample (a quantity generally unavailable using Markov Chain Monte Carlo) and can easily be applied to both conjugate and non-conjugate models, as training only requires samples from the generative model. We also present an extension of the method to models of random communities (such as infinite relational or stochastic block models). As a scientific application, we present a novel approach to neural spike sorting for high-density multielectrode arrays. \n", "pdf": "/pdf/14fac9e92aa1a9af7a5b288c84841d64e6a5b195.pdf", "keywords": "['amortized inference', 'probabilistic clustering', 'mixture models', 'exchangeability', 'spike sorting']", "id": "ryxF80NYwS"}, {"number": "2028", "title": "Barcodes as summary of objective functions' topology", "authors": "['Serguei Barannikov', 'Alexander Korotin', 'Dmitry Oganesyan', 'Daniil Emtsev', 'Evgeny Burnaev']", "abstract": "We apply canonical forms of gradient complexes (barcodes) to explore neural networks loss surfaces. We present an algorithm for calculations of the objective function's barcodes of minima.  Our experiments confirm two principal observations: (1) the barcodes of minima are located in a small lower part of the range of values of objective function and (2) increase of the neural network's depth brings down the minima's barcodes. This has natural implications for the neural network learning and the ability to generalize. ", "pdf": "/pdf/b6865eed88f60717b37d68870744f22fc714e0f5.pdf", "keywords": "['Barcodes', 'canonical form invariants', 'loss surface', 'gradient complexes']", "id": "S1gwC1StwS"}, {"number": "2518", "title": "PROGRESSIVE LEARNING AND DISENTANGLEMENT OF HIERARCHICAL REPRESENTATIONS", "authors": "['Zhiyuan Li', 'Jaideep Vitthal Murkute', 'Prashnna Kumar Gyawali', 'Linwei Wang']", "abstract": "Learning rich representation from data is an important task for deep generative models such as variational auto-encoder (VAE). However, by extracting high-level abstractions in the bottom-up inference process, the goal of preserving all factors of variations for top-down generation is compromised. Motivated by the concept of starting small, we present a strategy to progressively learn independent hierarchical representations from high- to low-levels of abstractions. The model starts with learning the most abstract representation, and then progressively grow the network architecture to introduce new  representations at different levels of abstraction. We quantitatively demonstrate the ability of the presented model to improve disentanglement in comparison to existing works on two benchmark datasets using three disentanglement metrics, including a new metric we proposed to complement the previously-presented metric of mutual information gap. We further present both qualitative and quantitative evidence on how the progression of learning improves disentangling of hierarchical representations. By drawing on the respective advantage of hierarchical representation learning and progressive learning, this is to our knowledge the first attempt to improve disentanglement by progressively growing the capacity of VAE to learn hierarchical representations.", "pdf": "/pdf/efb4325df6680b31749512d779002476a362c608.pdf", "keywords": "['generative model', 'disentanglement', 'progressive learning', 'VAE']", "id": "SJxpsxrYPS"}, {"number": "1047", "title": "How noise affects the Hessian spectrum in overparameterized neural networks", "authors": "['Mingwei Wei', 'David Schwab']", "abstract": "Stochastic gradient descent (SGD) forms the core optimization method for deep neural networks. While some theoretical progress has been made, it still remains unclear why SGD leads the learning dynamics in overparameterized networks to solutions that generalize well. Here we show that for overparameterized networks with a degenerate valley in their loss landscape, SGD on average decreases the trace of the Hessian of the loss. We also generalize this result to other noise structures and show that isotropic noise in the non-degenerate subspace of the Hessian decreases its determinant. In addition to explaining SGDs role in sculpting the Hessian spectrum, this opens the door to new optimization approaches that may confer better generalization performance. We test our results with experiments on toy models and deep neural networks.", "pdf": "/pdf/fc79c0c9ba8f2e87f1e15f0099c0e886856618b3.pdf", "keywords": "['noise', 'optimization', 'loss landscape', 'Hessian']", "id": "Hklcm0VYDS"}, {"number": "1835", "title": "Watch the Unobserved: A Simple Approach to Parallelizing Monte Carlo Tree Search", "authors": "['Anji Liu', 'Jianshu Chen', 'Mingze Yu', 'Yu Zhai', 'Xuewen Zhou', 'Ji Liu']", "abstract": "Monte Carlo Tree Search (MCTS) algorithms have achieved great success on many challenging benchmarks (e.g., Computer Go). However, they generally require a large number of rollouts, making their applications costly. Furthermore, it is also extremely challenging to parallelize MCTS due to its inherent sequential nature: each rollout heavily relies on the statistics (e.g., node visitation counts) estimated from previous simulations to achieve an effective exploration-exploitation tradeoff. In spite of these difficulties, we develop an algorithm, WU-UCT, to effectively parallelize MCTS, which achieves linear speedup and exhibits only limited performance loss with an increasing number of workers. The key idea in WU-UCT is a set of statistics that we introduce to track the number of on-going yet incomplete simulation queries (named as unobserved samples). These statistics are used to modify the UCT tree policy in the selection steps in a principled manner to retain effective exploration-exploitation tradeoff when we parallelize the most time-consuming expansion and simulation steps. Experiments on a proprietary benchmark and the Atari Game benchmark demonstrate the linear speedup and the superior performance of WU-UCT comparing to existing techniques.", "pdf": "/pdf/a348732b5ca8e27b8fe0b211c92ec4d1b6defbae.pdf", "keywords": "['parallel Monte Carlo Tree Search (MCTS)', 'Upper Confidence bound for Trees (UCT)', 'Reinforcement Learning (RL)']", "id": "BJlQtJSKDB"}]