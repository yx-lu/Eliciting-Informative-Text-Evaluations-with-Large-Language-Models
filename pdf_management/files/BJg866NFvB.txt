Title:
```
Published as a conference paper at ICLR 2020
```
Abstract:
```
Identifying when to give treatments to patients and how to select among multiple treatments over time are important medical problems with a few existing solutions. In this paper, we introduce the Counterfactual Recurrent Network (CRN), a novel sequence-to-sequence model that leverages the increasingly available patient ob- servational data to estimate treatment effects over time and answer such medical questions. To handle the bias from time-varying confounders, covariates affect- ing the treatment assignment policy in the observational data, CRN uses domain adversarial training to build balancing representations of the patient history. At each timestep, CRN constructs a treatment invariant representation which removes the association between patient history and treatment assignments and thus can be reliably used for making counterfactual predictions. On a simulated model of tumour growth, with varying degree of time-dependent confounding, we show how our model achieves lower error in estimating counterfactuals and in choosing the correct treatment and timing of treatment than current state-of-the-art methods.
```

Figures/Tables Captions:
```
Figure 1: Applicability of CRN in cancer treatment planning. We illustrate 3 patients with different covariate and treatment historiesH t . For a current time t, CRN can predict counterfactual trajectories (the coloured dashed branches) for planned treatments in the future. Through the counterfactual predictions, we can decide which treatment plan results in the best patient outcome (in this case, the lowest tumour volume). This way, CRN can be used to perform all of the following: choose optimal treatments (a), find timing when treatment is most effective (b) decide when to stop treatment (c).
Figure 2: CRN architecture. Encoder builds representation Φ(H t ) that maximizes loss of treatment classifier G a and minimizes loss of outcome predictor G y . Φ(H t ) is used to initialize the decoder, which continues to update it to predict counterfactual outcomes of a sequence of future treatments.
Figure 3: Training procedure for build- ing balancing representation.
Figure 4: Results for prediction of patient counterfactuals.
Figure 5: TSNE embedding of the balancing representation Φ(H t ) learnt by the CRN encoder at different timesteps t. Notice that Φ(H t ) is not predictive of the treatment A t given at timestep t.
Table 1: Results for recommending the correct treatment and timing of treatment.
```

Main Content:
```

Section Title: INTRODUCTION
  INTRODUCTION As clinical decision-makers are often faced with the problem of choosing between treatment alterna- tives for patients, reliably estimating their effects is paramount. While clinical trials represent the gold standard for causal inference, they are expensive, have a few patients and narrow inclusion criteria ( Booth & Tannock, 2014 ). Leveraging the increasingly available observational data about patients, such as electronic health records, represents a more viable alternative for estimating treatment effects. A large number of methods have been proposed for performing causal inference using observational data in the static setting ( Johansson et al., 2016 ;  Shalit et al., 2017 ;  Alaa & van der Schaar, 2017 ;  Li & Fu, 2017 ;  Yoon et al., 2018 ;  Alaa & van der Schaar, 2018 ;  Yao et al., 2018 ) and only a few methods address the longitudinal setting ( Xu et al., 2016 ;  Roy et al., 2016 ;  Soleimani et al., 2017 ;  Schulam & Saria, 2017 ;  Lim et al., 2018 ). However, estimating the effects of treatments over time poses unique opportunities such as understanding how diseases evolve under different treatment plans, how individual patients respond to medication over time, but also which are optimal timings for assigning treatments, thus providing new tools to improve clinical decision support systems. The biggest challenge when estimating the effects of time-dependent treatments from observational data involves correctly handling the time-dependent confounders: patient covariates that are affected by past treatments which then influence future treatments and outcomes ( Platt et al., 2009 ). For instance, consider that treatment A is given when a certain patient covariate (e.g. white blood cell Published as a conference paper at ICLR 2020 count) has been outside of normal range values for several consecutive timesteps. Suppose also that this patient covariate was itself affected by the past administration of treatment B. If these patients are more likely to die, without adjusting for the time-dependent confounding (e.g. the changes in the white blood cell count over time), we will incorrectly conclude that treatment A is harmful to patients. Moreover, estimating the effect of a different sequence of treatments on the patient outcome would require not only adjusting for the bias at the current step (in treatment A), but also for the bias introduced by the previous application of treatment B. Existing methods for causal inference in the static setting cannot be applied in this longitudinal setting since they are designed to handle the cross-sectional set-up, where the treatment and outcome depend only on a static value of the patient covariates. If we consider again the above example, these methods would not be able to model how the changes in patient covariates over time affect the assignment of treatments and they would also not be able to estimate the effect of a sequence of treatments on the patient outcome (e.g. sequential application of treatment A followed by treatment B). Different models that can handle these temporal dependencies in the observational data and varying-length patient histories are needed for estimating treatment effects over time. Time-dependent confounders are present in observational data because doctors follow policies: the history of the patients' covariates and the patients' response to past treatments are used to decide future treatments ( Mansournia et al., 2012 ). The direct use of supervised learning methods will be biased by the treatment policies present in the observational data and will not be able to correctly estimate counterfactuals for different treatment assignment policies. Standard methods for adjusting for time-varying confounding and estimating the effects of time- varying exposures are based on ideas from epidemiology. The most widely used among these are Marginal Structural Models (MSMs) ( Robins et al., 2000 ;  Mansournia et al., 2012 ) which use the inverse probability of treatment weighting (IPTW) to adjust for the time-dependent confounding bias. Through IPTW, MSMs create a pseudo-population where the probability of treatment does not depend on the time-varying confounders. However, MSMs are not robust to model misspecification in computing the IPTWs. MSMs can also give high-variance estimates due to extreme weights; computing the IPTW involves dividing by probability of assigning a treatment conditional on patient history which can be numerically unstable if the probability is small. We introduce the Counterfactual Recurrent Network (CRN), a novel sequence-to-sequence archi- tecture for estimating treatment effects over time. CRN leverages recent advances in representation learning (Bengio et al., 2012) and domain adversarial training ( Ganin et al., 2016 ) to overcome the problems of existing methods for causal inference over time. Our main contributions are as follows.

Section Title: Treatment invariant representations over time
  Treatment invariant representations over time CRN constructs treatment invariant represen- tations at each timestep in order to break the association between patient history and treatment assignment and thus removes the bias from time-dependent confounders. For this, CRN uses domain adversarial training ( Ganin et al., 2016 ;  Li et al., 2018 ;  Sebag et al., 2019 ) to trade-off between build- Published as a conference paper at ICLR 2020 ing this balancing representation and predicting patient outcomes. We show that these representations remove the bias from time-varying confounders and can be reliably used for estimating counterfactual outcomes. This represents the first work that introduces ideas from domain adaptation to the area of estimating treatment effects over time. In addition, by building balancing representations, we propose a novel way of removing the bias introduced by time-varying confounders.

Section Title: Counterfactual estimation of future outcomes
  Counterfactual estimation of future outcomes To estimate counterfactual outcomes for treatment plans (and not just single treatments), we integrate the domain adversarial training procedure as part of a sequence-to-sequence architecture. CRN consists of an encoder network which builds treatment invariant representations of the patient history that are used to initialize the decoder. The decoder network estimates outcomes under an intended sequence of future treatments, while also updating the balanced representation. By performing counterfactual estimation of future treatment outcomes, CRN can be used to answer critical medical questions such as deciding when to give treatments to patients, when to start and stop treatment regimes, and also how to select from multiple treatments over time. We illustrate in  Figure 1  the applicability of our method in choosing optimal cancer treatments. In our experiments, we evaluate CRN in a realistic set-up using a model of tumour growth ( Geng et al., 2017 ). We show that CRN achieves better performance in predicting counterfactual outcomes, but also in choosing the right treatment and timing of treatment than current state-of-the-art methods.

Section Title: RELATED WORK
  RELATED WORK We focus on methods for estimating treatment effects over time and for building balancing represen- tations for causal inference. A more in-depth review of related work is in Appendix A.

Section Title: Treatment effects over time
  Treatment effects over time To begin with,  Xu et al. (2016)  use Gaussian processes to model discrete patient outcomes as a generalized mixed-effects model and uses the g-computation method to handle time-varying confounders.  Soleimani et al. (2017)  extend the approach in  Xu et al. (2016)  to the continuous time-setting and model treatment responses using linear time-invariant dynamical systems.  Roy et al. (2016)  use Dirichlet and Gaussian processes to model the observational data and estimate the IPTW in Marginal Structural Models.  Schulam & Saria (2017)  build upon work from  Lok et al. (2008) ;  Arjas & Parner (2004)  and use marked point processes and Gaussian processes to learn causal effects in continuous-time data. These Bayesian non-parametric methods make strong assumptions about model structure and consequently cannot handle well heterogeneous treatment effects arising from baseline variables ( Soleimani et al., 2017 ;  Schulam & Saria, 2017 ) and multiple treatment outcomes ( Xu et al., 2016 ;  Schulam & Saria, 2017 ). The work most related to ours is the one of  Lim et al. (2018)  which improves on the standard MSMs by using recurrent neural networks to estimate the inverse probability of treatment weights (IPTWs).  Lim et al. (2018)  introduces Recurrent Marginal Structural Networks (RMSNs) which also use a sequence-to-sequence deep learning architecture to forecast treatment responses in a similar fashion to our model. However, RMSNs require training additional RNNs to estimate the propensity weights and does not overcome the fundamental problems with IPTWs, such as the high-variance of the weights. Conversely, CRN takes advantage of the recent advances in machine learning, in particular, representation learning to propose a novel way of handling time-varying confounders.

Section Title: Balancing representations for treatment effect estimation
  Balancing representations for treatment effect estimation Balancing the distribution of control and treated groups has been used for counterfactual estimation in the static setting. The methods proposed in the static setting for balancing representations are based on using discrepancy measures in the representation space between treated and untreated patients, which do not generalize to multiple treatments ( Johansson et al., 2016 ;  Shalit et al., 2017 ;  Li & Fu, 2017 ;  Yao et al., 2018 ). Moreover, due to the sequential assignment of treatments in the longitudinal setting, and due to the change of Published as a conference paper at ICLR 2020 patient covariates over time according to previous treatments, the methods for the static setting are not directly applicable to the time-varying setting ( Hernán et al., 2000 ;  Mansournia et al., 2012 ).

Section Title: PROBLEM FORMULATION
  PROBLEM FORMULATION Consider an observational dataset D = {x (i) t , a (i) t , y (i) t+1 } T (i) t=1 ∪{v (i) } N i=1 consisting of information about N independent patients. For each patient (i), we observe time-dependent covariates X (i) t ∈ X t , treatment received A (i) t ∈ {A 1 , . . . A K } = A and outcomes Y (i) t+1 ∈ Y t+1 for T (i) discrete timesteps. The patient can also have baseline covariates V (i) ∈ V such as gender and genetic information. Note that the outcome Y (i) t+1 will be part of the observed covariates X (i) t+1 . For simplicity, the patient superscript (i) will be omitted unless explicitly needed. We adopt the potential outcomes framework proposed by ( Neyman, 1923 ;  Rubin, 1978 ) and ex- tended by ( Robins & Hernán, 2008 ) to account for time-varying treatments. Let Y[ā] be the potential outcomes, either factual or counterfactual, for each possible course of treatmentā. Let H t = (X t ,Ā t−1 , V) represent the history of the patient covariatesX t = (X 1 , . . . , X t ), treatment assignmentsĀ t = (A 1 , . . . , A t ) and static features V. We want to estimate: E(Y t+τ [ā(t, t + τ − 1)]|H t ), (1) whereā(t, t + τ − 1) = [a t , . . . a t+τ −1 ] represents a possible sequence of treatments from timestep t just until before the potential outcome Y t+τ is observed. We make the standard assumptions ( Robins et al., 2000 ;  Lim et al., 2018 ) needed to identify the treatment effects: consistency, positivity and no hidden confounders (sequential strong ignorability). See Appendix B for more more details.

Section Title: COUNTERFACTUAL RECURRENT NETWORK
  COUNTERFACTUAL RECURRENT NETWORK The observational data can be used to train a supervised learning model to forecast: E(Y t+τ | A(t, t + τ − 1) =ā(t, t + τ − 1),H t ). However, without adjusting for the bias introduced by time- varying confounders, this model cannot be reliably used for making causal predictions ( Robins et al., 2000 ;  Robins & Hernán, 2008 ;  Schulam & Saria, 2017 ). The Counterfactual Recurrent Network (CRN) removes this bias through domain adversarial training and estimates the counterfactual outcomes E(Y t+τ [ā(t, t + τ − 1)]|H t ), for any intended future treatment assignmentā(t, t + τ − 1).

Section Title: Balancing representations
  Balancing representations The historyH t = (X t ,Ā t−1 , V) of the patient contains the time- varying confoundersX t which bias the treatment assignment A t ∈ {A 1 , . . . A K } in the observational dataset. Inverse probability of treatment weighting, as performed by MSMs, creates a pseudo- population where the probability of treatment A t does not depend on the time-varying confounders ( Robins et al., 2000 ). In this paper, we propose instead building a representation of the historyH t that is not predictive of the treatment A t . This way, we remove the association between history, containing the time-varying confoundersX t , and current treatment A t .  Robins (1999)  shows that in this case, the estimation of counterfactual treatment outcomes is unbiased. See Appendix C for details and for an example of a causal graph with time-dependent confounders. Let Φ be the representation function that maps the patient historyH t to a representation space R. To obtain unbiased treatment effects, Φ needs to construct treatment invariant representations such that P (Φ(H t ) | A t = A 1 ) = · · · = P (Φ(H t ) | A t = A K ). To achieve this and to estimate counterfactual outcomes under a planned sequence of treatments, we integrate the domain adversarial training framework proposed by  Ganin et al. (2016)  and extended by  Sebag et al. (2019)  to the multi-domain learning setting, into a sequence-to-sequence architecture. In our case, the different treatments at each timestep are considered the different domains. Note that the novelty here comes from the use of domain adversarial training to handle the bias from the time-dependent confounders, rather than the use of sequence-to-sequence models, which have already been applied to forecast treatment responses ( Lim et al., 2018 ).  Figure 2  illustrates our model architecture.

Section Title: Encoder
  Encoder of the outcome predictor network G y . This way, the balanced representation Φ(H t ) is not predictive of the assigned treatment A t , but is discriminative enough to estimate the outcome Y t+1 . To train this model using gradient descent, we use the Gradient Reversal Layer ( Ganin et al., 2016 ).

Section Title: Decoder
  Decoder The decoder network uses the balanced representation computed by the encoder to initialize the state of an RNN that predicts the counterfactual outcomes for a sequence of future treatments. Dur- ing training, the decoder uses as input the outcomes from the observational data (Y t+1 , . . . Y t+τ −1 ), the static patient features V and the intended sequence of treatmentsā(t, t + τ − 1). The decoder is trained in a similar way to the encoder to update the balanced representation and to estimate the outcomes. During testing, we do not have access to ground-truth outcomes; thus, the outcomes predicted by the decoder (Ŷ t+1 , . . .Ŷ t+τ −1 ) are auto-regressively used instead as inputs. By running the decoder with different treatment settings, and by auto-regressively feeding back the outcomes, we can determine when to start and end different treatments, which is the optimal time to give the treatment and which treatments to give over time to obtain the best patient outcomes. The representation Φ(H t ) is built by applying a fully connected layer, with Exponential Linear Unit (ELU) activation to the output of the LSTM. The treatment classifier G a and the predictor network G y consist of a hidden layer each, also with ELU activation. The output layer of G a uses softmax activation, while the output layer of G y uses linear activation for continuous predictions. For categorical outcomes, softmax activation can be used. We follow an approach similar to  Lim et al. (2018)  and we split the encoder and decoder training into separate steps. See Appendix E for details. The encoder and decoder networks use variational dropout ( Gal & Ghahramani, 2016 ) such that the CRN can also give uncertainty intervals for the treatment outcomes. This is particularity important in the estimation of treatment effects, since the model predictions should only be used when they have high confidence. Our model can also be modified to allow for irregular samplings of observations by using a PhasedLSTM ( Neil et al., 2016 ).

Section Title: ADVERSARIALLY BALANCED REPRESENTATION OVER TIME
  ADVERSARIALLY BALANCED REPRESENTATION OVER TIME At each timestep t, let the K different possible treatments A t ∈ {A 1 , . . . A K } represent our domains. As described in Section 4, to remove the bias from time-dependent confounders, we build a represen- tation of historyH t that is invariant across treatments: This requirement can be enforced by minimizing the distance in the distribution of Φ(H t ) between any two pairs of treatments.  Kifer et al. (2004) ;  Ben-David et al. (2007) , propose measuring the disparity between distributions based on their separability by a discriminatively-trained classifier. Let the symmetric hypothesis class H consist of the set of symmetric multiclass classifiers, such as neural network architectures. The H-divergence between all pairs of two distributions is defined in terms of the capacity of the hypothesis class H to discriminate between examples from the multiple distributions. Empirically, minimizing the H−divergence involves building a representation where examples from the multiple domains are as indistinguishable as possible ( Ben-David et al., 2007 ;  Li et al., 2018 ;  Sebag et al., 2019 ).  Ganin et al. (2016)  use this idea to propose an adversarial framework Published as a conference paper at ICLR 2020 for domain adaptation involving building a representation which achieves maximum error on a domain classifier and minimum error on an outcome predictor. Similarly, in our case, we use domain adversarial training to build a representation of the patient history Φ(H t ) that is both invariant to the treatment given at timestep t, A t and that achieves low error in estimating the outcome Y t+1 . Let G a (Φ(H t ); θ a ) be the treatment classifier with param- eters θ a and let G j a (Φ(H t ); θ a ) be the output correspond- ing to treatment A j . Let G y (Φ(H t ); θ y ) be the predictor network with parameters θ y . The representation func- tion Φ is parameterized by the parameters θ r in the RNN: Φ(H t ; θ r ).  Figure 3  shows the adversarial training proce- dure used. For timestep t and patient (i), let L (i) t,a (θ r , θ a ) be the treat- ment (domain) loss and let L (i) t,y (θ r , θ y ) the outcome loss, defined as follows: If the outcome is binary, the cross-entropy loss can be used instead for L t,y . To build treatment invariant repre- sentations and to also estimate patient outcomes, we aim to maximize treatment loss and minimize outcome loss. Thus, the overall loss L (i) t,y at timestep t is given by: L (i) t (θ r , θ y , θ a ) = N i=1 L (i) t,y (θ r , θ y ) − λL (i) t,a (θ r , θ a ), (4) where the hyperparameter λ controls this trade-off between domain discrimination and outcome prediction. We use the standard procedure for training domain adversarial networks from  Ganin et al. (2016)  and we start off with an initial value for λ and use an exponentially increasing schedule during training. To train the model using backpropagation, we use the Gradient Reversal Layer (GRL) ( Ganin et al., 2016 ). For more details about the training procedure, see Appendix E. By using the objective L (i) t (θ r , θ y , θ a ), we reach the saddle point (θ r ,θ y ,θ a ) that achieves the equilibrium between domain discrimination and outcome estimation. The result stated in Theorem 1 proves that the treatment (domain) loss part of our objective (from equation 2) aims to remove the time-dependent confounding bias. A good representation allows us to obtain a low error in estimating counterfactuals for all treatments, while at the same time to minimize the H-divergence between induced marginal distributions of all the domains. We use an algorithm that directly minimizes a combination of the H−divergence and the empirical training margin.

Section Title: EXPERIMENTS
  EXPERIMENTS In real datasets, counterfactual outcomes and the degree of time-dependent confounding are not known ( Schulam & Saria, 2017 ;  Lim et al., 2018 ). To validate the CRN 1 , we evaluate it on a Pharmacokinetic-Pharmacodynamic model of tumour growth ( Geng et al., 2017 ), which uses a state- of-the-art bio-mathematical model to simulate the combined effects of chemotherapy and radiotherapy in lung cancer patients. The same model was used by  Lim et al. (2018)  to evaluate RMSNs.

Section Title: Model of tumour growth
  Model of tumour growth The volume of tumour t days after diagnosis is modelled as follows: where K, ρ, β c , α r , β r , e t are sampled as described in  Geng et al. (2017) . To incorporate heterogeneity in patient responses, the prior means for β c and α r are adjusted to create patient subgroups, which are used as baseline features. The chemotherapy concentration C(t) and radiotherapy dose d(t) are modelled as described in Appendix F. Time-varying confounding is introduced by modelling chemotherapy and radiotherapy assignment as Bernoulli random variables, with probabilities p c and p r depending on the tumour diameter: p c (t) = σ γc Dmax (D(t) − δ c ) and p r (t) = σ γr Dmax (D(t) − δ r ) whereD(t) is the average diameter over the last 15 days, D max = 13cm, σ(·) is the sigmoid and δ c = δ r = D max /2. The amount of time-dependent confounding is controlled through γ c , γ r ; the higher γ is, the more important the history is in assigning treatments. At each timestep, there are four treatment options: no treatment, chemotherapy, radiotherapy, combined chemotherapy and radiotherapy. For details about data simulation, see Appendix F.

Section Title: Benchmarks
  Benchmarks We used the following benchmarks for performance comparison: Marginal Structural Models (MSMs) ( Robins et al., 2000 ), which use logistic regression for estimating the IPTWs and linear regression for prediction (see Appendix G for details). We also compare against the Recurrent Marginal Structural Networks (RMSNs)  Lim et al. (2018) , which is the current state-of-the-art model in estimating treatment responses. RMSNs use RNNs to estimate the IPTWs and the patient outcomes (details in Appendix H). To show that standard supervised learning models do not handle the time- varying confounders we compare against an RNN and a linear regression model, which receive as input treatments and covariates to predict the outcome (see Appendix I for details). Our model architecture follows the description in Sections 4 and 5, with full training details and hyperparameter optimization in Appendix J. To show the importance of adversarial training, we also benchmark against CRN (λ = 0) a model with the same architecture, but with λ = 0, i.e our model architecture without adversarial training.

Section Title: EVALUATE MODELS ON COUNTERFACTUAL PREDICTIONS
  EVALUATE MODELS ON COUNTERFACTUAL PREDICTIONS Previous methods focused on evaluating the error only for factual outcomes (observed patient outcomes) ( Lim et al., 2018 ). However, to build decision support systems, we need to evaluate how well the models estimate the counterfactual outcomes, i.e patient outcomes under alternative treatment options. The parameters γ c and γ r control the treatment assignment policy, i.e. the degree of time-dependent confounding present in the data. We evaluate the benchmarks under different degrees of time-dependent confounding by setting γ = γ c = γ r . For each γ we simulate a 10000 patients for training, 1000 for validation (hyperparameter tuning) and 1000 for out-of-sample testing. For the patients in the test set, for each time t, we also simulate counterfactuals Y t+1 , represented by tumour volume V (t + 1), under all possible treatment options.  Figure 4 (a)  shows the normalized root mean squared error (RMSE) for one-step ahead estimation of counterfactuals with varying degree of time-dependent confounding γ. The RMSE is normalized by the maximum tumour volume: V max = 1150cm 3 . The linear and MSM models provide a baseline for performance as they achieve the highest RMSE. While the use of IPTW in MSMs helps when γ increases, using linear modelling has severe limitations. When there is no time-dependent confounding, the machine learning methods achieve similar performance, close to 0.6% RMSE. As the bias in the dataset increases, the harder it becomes for the RNN and the CRN (λ = 0) to generalize to estimate outcomes of treatments not matching the training policy. When γ = 10, CRN improves by 48.1% on the same model architecture without domain adversarial training CRN (λ = 0). Our proposed model achieves the lowest RMSE across all values of γ. Compared to RMSNs, CRN improves by ∼ 17% when γ > 6. To highlight the gains of our method even for smaller γ,  Figure 4 (b)  shows the RMSE for five-step ahead prediction (with counterfactuals generated as described in Section 6.2 and Appendix L). RMSNs also use a decoder for sequence prediction. However, RMSNs require training additional RNNs to estimate the IPTW, which are used to weight each sample during the decoder training. For τ -step ahead prediction, IPTW involves multiplying τ weights which can result in high variance. The results in  Figure 4 (b)  show the problems with using IPTW to handle the time-dependent confounding bias. See Appendix K for more results on multi-step ahead prediction.

Section Title: Balancing representation
  Balancing representation To evaluate whether the CRN has indeed learnt treatment invariant represenations, for γ = 5, we illustrate in  Figure 5  the T-SNE embeddings of the balancing rep- resentations Φ(H t ) built by the CRN encoder for test patients. We color each point by the treat- ment A t ∈ {no treatment, chemotherapy, radiotherapy, combined chemotherapy and radiotherapy} received at timestep t to highlight the invariance of Φ(H t ) across the different treatments. In Figure 5(b), we show Φ(H t ) only for chemotherapy and radiotherapy for better understanding.

Section Title: EVALUATE RECOMMENDING THE RIGHT TREATMENT AND TIMING OF TREATMENT
  EVALUATE RECOMMENDING THE RIGHT TREATMENT AND TIMING OF TREATMENT Evaluating the models just in terms of the RMSE on counterfactual estimation is also not enough for assessing their reliability when used as part of decision support systems. In this section we assess how well the models can select the correct treatment and timing of treatment for several forecasting horizons τ . We generate test sets consisting of 1000 patients where for each horizon τ and for each time t in a patient's trajectory, there are τ options for giving chemotherapy at one of t, . . . t + τ − 1 and τ options for giving radiotherapy at one of t, . . . t + τ − 1. At the rest of the future timesteps, no treatment is applied. These 2τ treatment plans are assessed in terms of the tumour volume outcome Y t+τ . We select the treatment (chemotherapy or radiotherapy) that achieves lowest Y t+τ , and within the correct treatment the timing with lowest Y t+τ . We also compute the normalized RMSE for predicting Y t+τ . See Appendix L for more details about the test set. The models are evaluated for 3 settings of γ c and γ r .  Table 1  shows the results for this evaluation set-up. The treatment accuracy denotes the percentage of patients for which the correct treatment was selected, while the treatment timing accuracy is the percentage for which the correct timing was selected. Note that when γ c = 0 and γ r = 5, RMSN and MSM select the wrong treatment timing for projection horizons τ > 4. CRN performs similarly among the different policies present in the observational data and achieve the lowest RMSE and highest accuracy in selecting the correct treatment and timing of treatment. In Appendix M we also show the applicability of the CRN in more complex medical scenarios involving real data. We provide experimental results based on the Medical Information Mart for Intensive Care (MIMIC III) database ( Johnson et al., 2016 ) consisting of electronic health records from patients in the ICU.

Section Title: CONCLUSION
  CONCLUSION Despite its wide applicability, the problem of causal inference for time-dependent treatments has been relatively less studied compared to problem of causal inference in the static setting. Both new methods and theory are necessary to be able to harness the full potential of observational data for learning individualized effects of complex treatment scenarios. Further work in this direction is needed for proposing alternative methods for handling time-dependent confounders, for modelling combinations of treatments assigned over time or for estimating the individualized effects of time-dependent treatments with associated dosage. In this paper, we introduced the Counterfactual Recurrent Network (CRN), a model that estimates individualized effects of treatments over time using a novel way of handling the bias from time- dependent confounders through adversarial training. Using a model of tumour growth, we validated CRN in realistic medical scenarios and we showed improvements over existing state-of-the-art methods. We also showed the applicability of the CRN a real dataset consiting of patient electronic health records. The counterfactual predictions of CRN have the potential to be used as part of clinical decision support systems to address relevant medical challenges involving selecting the best treatments for patients over time, identify optimal treatment timings but also when the treatment is no longer needed. In future work, we will aim to build better balancing representations and to provide theoretical guarantees for the expected error on the counterfactuals.

```
