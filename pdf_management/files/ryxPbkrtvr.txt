Title:
```
Under review as a conference paper at ICLR 2020 BOSH: AN EFFICIENT META ALGORITHM FOR DECISION-BASED ATTACKS
```
Abstract:
```
Adversarial example generation becomes a viable method for evaluating the ro- bustness of a machine learning model. In this paper, we consider hard-label black- box attacks (a.k.a. decision-based attacks), which is a challenging setting that generates adversarial examples based on only a series of black-box hard-label queries. This type of attacks can be used to attack discrete and complex models, such as Gradient Boosting Decision Tree (GBDT) and detection-based defense models. Existing decision-based attacks based on iterative local updates often get stuck in a local minimum and fail to generate the optimal adversarial example with the smallest perturbation. To remedy this issue, we propose an efficient meta algorithm called BOSH-attack, which tremendously improves existing algorithms through Bayesian Optimization (BO) and Successive Halving (SH). In particular, instead of traversing a single solution path when searching an adversarial exam- ple, we maintain a pool of solution paths to explore important regions. We show empirically that the proposed algorithm converges to a better solution than exist- ing approaches, while the query count is smaller than applying multiple random initializations by a factor of 10.
```

Figures/Tables Captions:
```
Figure 1: Decision boundary (NN and GBDT models on MNIST dataset) projected on a two- dimensional hyperplane. To choose which 2D hyperplane to project to, we run a decision-based attack from two random initialization points, and use their converged perturbation directions as the vector to form the hyperplane. We then query the decision boundary on this hyperplane to plot these figures.
Figure 2: Distribution of converged adversarial perturbation norm on an MNIST image. The figures show that the final L 2 distortion can be very different because of various starting directions.
Figure 3: Illustration of the effect of Successive Halving and TPE resampling. Note that Figure 3(b) only exhibits part of the curve to show the effect of TPE.
Table 1: Results of hard-label black-box attack on MNIST, CIFAR-10 and ImageNet-1000. We compare the performance of several attack algorithms under untargeted setting.
Table 2: Comparions for the effectiveness of successive halving and TPE resampling. The Relative Gain is based on Multi-Directional attack and Queries means total queries of all directions.
Table 3: Comparison of results of untargeted at- tack on gradient boosting decision tree.
Table 4: Results of attack on MNIST detector models under untargeted setting.
```

Main Content:
```

Section Title: INTRODUCTION
  INTRODUCTION It has been shown that machine learning models, including deep neural networks, are vulnerable to adversarial examples ( Goodfellow et al., 2014 ;  Szegedy et al., 2013 ;  Chen et al., 2017a ). Therefore, evaluating the robustness of a given model becomes crucial for security sensitive applications. In order to evaluate the robustness of deep neural networks, researchers have developed "attack algo- rithms" to generate adversarial examples that can mislead a given neural network while being as close as possible to the original example ( Goodfellow et al., 2014 ;  Moosavi-Dezfooli et al., 2016 ;  Carlini & Wagner, 2017b ;  Chen et al., 2017b ). Most of these attack methods are based on maxi- mizing a loss function with a gradient-based optimizer, where the gradient is either computed by back-propagation (in the white-box setting) or finite-difference estimation (in the soft-label black- box setting). Although these methods work well on standard neural networks, when it comes to complex or even discontinuous models, such as decision trees and detection-based defense models, they cannot be directly applied because the gradient is not available. Hard-label black-box attacks, also known as decision-based attacks, consider the most difficult but realistic setting where the attacker has no information about the model structure and parameters, and the only valid operation is to query the model to get the corresponding decision-based (hard-label) output ( Brendel et al., 2017 ). This type of attacks can be used as a "universal" way to evaluate robustness of any given models, no matter continuous or discrete. For instance,  Cheng et al. (2018) ;  Chen et al. (2019a)  have applied decision-based attacks for evaluating robustness of Gradient Boost- ing Decision Trees (GBDT) and random forest. Current decision-based attacks, including  Brendel et al. (2017) ;  Cheng et al. (2018) ;  Chen et al. (2019b) ;  Cheng et al. (2019) , are based on iterative local updates - starting from an initial point on the decision surface, they iteratively move the points along the surface until reaching a local minimum (in terms of distance to the original example). The update is often based on gradient estimation or some other heuristics. However, the local update nature makes these methods sensitive to the starting point. As we demonstrate in Figure 1(a), the perturbation of converged adversarial examples for a neural network are quite different for different initialization configurations, and this phenomenon becomes more severe when it comes to discrete models such as GBDTs (see Figure 1(b)). This makes decision-based attacks converge to a sub- Under review as a conference paper at ICLR 2020 optimal perturbation. As a result, the solution cannot really reflect the robustness of the targeted model. To overcome these difficulties and make decision-based attacks better reflect the robustness of mod- els, we propose a meta algorithm called BOSH-attack that consistently boosts the solution quality of existing iterative local update based attacks. Our main idea is to combine Bayesian optimization, which finds solution closer to global optimum but suffers from high computation cost, with iterative local updates, which converges fast but often get stuck in local minimum. Specifically, given a deci- sion based attack A, our algorithm maintains a pool of solutions and at each iteration we run A for m steps on each solution. The proposed Bayesian Optimization resampling (BO) and Successive Halving (SH) are then used to explore important solution space based on current information and cut out unnecessary solution paths. Our contributions are summarized below: 1. We conduct thorough experiments to show that current decision-based attacks often con- verge to a local optimum, thus further improvements are required. 2. Based on the idea of Bayesian optimization and successive halving, we design a meta algo- rithm to boost the performance of current decision-based attack algorithms and encourage them to find a much smaller adversarial perturbation efficiently. 3. Comprehensive experiments demonstrate that BOSH-attack can consistently boost existing decision-based attacks to find better examples with much smaller perturbation. In addition to the standard neural network models, we also test our algorithms on attacking discrete GBDT models and detector-based defense models. Moreover, our algorithm can reduce the computation cost by 10x compared to the naive approach.

Section Title: BACKGROUND AND RELATED WORK
  BACKGROUND AND RELATED WORK Given a classification model F : R d → {1, . . . , C} and an example x 0 , adversarial attacks aim to find the adversarial example that is closest to x 0 . For example, an untargeted attack aims to find the minimum perturbation to change the predicted class, which corresponds to the following optimization problem: Exactly minimizing (1) is usually intractable; therefore, we can only expect to get a feasible solution of (1) while hoping δ to be as small as possible.

Section Title: White-box Attack.
  White-box Attack. For neural networks, we can replace the constraint in (1) by a loss func- tion defined on the logit layer output, leading to a continuous optimization problem which can be solved by gradient-based optimizers. This approach has been used in popular methods such as FGSM ( Goodfellow et al., 2014 ), C&W attack ( Carlini & Wagner, 2017b ) and PGD attack ( Madry et al., 2017 ). All these white-box attacks developed for neural networks assume the existence of the gradient. However, for models with discrete components such as GBDT, the objective cannot be easily defined and gradient-based white-box attacks are not applicable. There are few white-box attacks developed for specific discrete models, such as Mixed Integer Linear Programming (MILP) approach for attacking tree ensemble ( Kantchelian et al., 2016 ). However, those algorithms are time consuming and require significant efforts for developing each model. Soft-label Black-box Attack Black box setting considers the cases when an attacker has no direct access to the model's parameter and architecture, and the only valid operation is to query input examples and get the corresponding model output. In the soft-label black box setting, it is assumed that the model outputs the probability of each label for an input query.  Chen et al. (2017b)  showed that the attack can still be formulated as an optimization problem where the objective function value can be computed while the gradient is unavailable. Based on this, various zeroth order optimization algorithms have been proposed, including NES-attack ( Ilyas et al., 2018a ), EAD attack ( Chen et al., 2018 ), bandit-attack ( Ilyas et al., 2018b ), Autozoom ( Tu et al., 2019 ), Genetic algorithm ( Alzantot et al., 2018 ).

Section Title: Hard-label Black-box attack (Decision-based attack)
  Hard-label Black-box attack (Decision-based attack) In this paper, we focus on the hard-label black box attack (also known as decision-based attack). In contrast to the soft-label setting, the Under review as a conference paper at ICLR 2020 attacker can only query the model and get the top-1 predicted label without any probability in- formation. To minimize the perturbation in the decision-based setting,  Brendel et al. (2017)  first proposed a Boundary Attack based on random walk on the decision surface. Later on,  Cheng et al. (2018)  showed that hard-label attack can be reformulated as another continuous optimization prob- lem, and zeroth order optimization algorithms such as NES can be used to solve this problem.  Cheng et al. (2019)  further reduces the queries by only calculating the sign of ZOO updating function, and  Chen et al. (2019b)  proposed another algorithm to improve over boundary attack. Such methods can converge quickly but suffer from local optimum problems, and thus require more careful and thorough search in the solution space.

Section Title: Probability based black-box optimization
  Probability based black-box optimization There are two commonly used methods to solve a black-box or non-differentiable optimization problem: gradient-based and probabilistic-based al- gorithms. Gradient-based methods are based on iterative local updates until convergence, while probabilistic-based algorithms such as Bayesian optimization (BO) ( Pelikan et al., 1999 ;  Snoek et al., 2012 ) approximate the objective function by a probabilistic model. Generally speaking, gradient-based methods are commonly used in black-box attack because it converges fast. How- ever, these methods often stuck in some local optimal directions, especially when the searching space is high dimensional and non-convex. Probabilistic-based algorithms are frequently used in low-dimensional problems such as hyperparameter tuning and can have a better chance to find more global optimal values ( Snoek et al., 2012 ;  Bergstra et al., 2011 ). However, the computation cost grows exponentially while the dimension increases and quickly become unacceptable. Therefore, they cannot be directly applied to generate adversarial examples. In this paper, we attempt to com- bine Bayesian Optimization and iterative local updates to improve the solution quality of current attack algorithms while being able to scale to high dimensional problems.

Section Title: Combinatorial heuristic and genetic algorithms
  Combinatorial heuristic and genetic algorithms There exist various heuristic algorithms com- monly applied to combinatorial optimization problems. In these algorithms, they try to leverage the effects between greedy and random. Commonly, they will search for different directions and drop the bad ones, and then put more attention on the relatively good candidates. Greedy randomized adaptive search ( Feo & Resende, 1995 ) finds good solutions in an iterative way. It first generates a set of solutions and use a greedy function to rank these solutions. Later, good candidates are placed in a restricted candidate list, and randomly chosen when forming the solution. Tabu search ( Glover & Laguna, 1999 ) selects a candidate and checks its immediate neighbors, trying to find an improved solution. In order to avoid stucking in local optimal areas, it maintains a list called tabu list to store past good solutions (often local optimal solutions). In further searches, it will prevent from look- ing for this areas. Other approaches like Genetic Algorithms (GA) and Simulated Annealing (SA) also try to adopt random in the searching process. In this paper, we simply use Successive Halving (SH) ( Jamieson & Talwalkar, 2016 ) to remove unimportant candidate configurations iteratively. The details can be found in Section 3.1.

Section Title: THE PROPOSED ALGORITHM
  THE PROPOSED ALGORITHM Observation: Decision based attacks are easily stuck in local optimum. Most existing adver- sarial attacks adopt iterative local updates to find adversarial examples - starting from an initial point, they iteratively update the solution until convergence. For example, in white-box attacks such as C&W and PGD methods, they aim at optimizing a non-convex loss function by iterative gradient updates. In Figure 1(a), we plot the 2-dimensional projection of the decision surface of a neural network. We can observe that there are two local minimums 1 . Results show that there are two local minimums and the attack algorithm converges to one of them according the the initialization region. Similarly, in decision-based attacks, existing methods start from some point on the decision surface and then iteratively update the point locally on the surface either by gradient update ( Cheng et al., 2018 ;  Chen et al., 2019b ) or random walk ( Brendel et al., 2017 ). In Figure 1(b) we plot the deci- sion surface of a GBDT. We observe a similar issue that there are many local minima in the GBDT decision boundary. We further quantify how serious the problem is. On an MNIST network, Figure 2(a) shows the distribution of converged adversarial perturbations of C&W attack (white-box attack) and Sign- OPT attack (decision-based attack) under approximately 400 random initial points. We observe that the converged solutions of C&W attack are quite concentrated between [1.41, 1.47]. However, when considering decision-based attack such as Sign-OPT, the converged solutions are widely spread from 1.36 to 1.55. In general, our experiments suggested that decision based attacks are much more sensitive to initialization. This is because they only update solutions on the decision boundary while C&W and PGD attack can update solution inside/outside the boundary. Furthermore, such phenomenon is obvious when the victim model is GBDT. For example, in Fig- ure 2(b) we can see the converged solution spread from 0.5 to 1.5 when applying Sign-OPT attack. Therefore, the solution of any single run of Sign-OPT on GBDT cannot really reflect the minimum adversarial perturbation of the given model, and thus it is crucial to design an algorithm that con- verges to a better solution. Since the phenomenon is more severe for decision based attacks, we will mainly focus on improving the quality of decision based attacks in this paper, while in general our method can also be used to boost the performance of white-box attacks marginally, as illustrated in Appendix A. Figure 2(a) and 2(b) show the histogram for final perturbations, and Figure 2(c) shows the converging curve of Sign-OPT attack on a neural network model on MNIST dataset.

Section Title: A GENERAL MECHANISM FOR IMPROVED DECISION BASED ATTACK
  A GENERAL MECHANISM FOR IMPROVED DECISION BASED ATTACK Given a local update based attack A, our goal is to find a solution with improved quality. To this end, we propose a meta algorithm to address this issue by integrating probability-based (Bayesian) black- box optimization with iterative local updates. As shown in Algorithm 1, our algorithm maintains a candidate pool P a that stores all the active configurations, where each configuration u ∈ P a is an intermediate iterate of algorithm A. Also, we assume that there is an attack objective C such that C(u) measures the quality of the solution. For decision based attacks, the goal is to find the optimal direction to minimize the distance to the boundary along that direction ( Cheng et al., 2018 ). Under review as a conference paper at ICLR 2020 Therefore, u is the direction of adversarial perturbation and C(u) = min λ>0 λ s.t. f x 0 + λ u u = y 0 , where y 0 is the correct label. This can be computed by a fine-grained plus binary search procedure (see  Cheng et al. (2018) ), and in fact, in most of the algorithms C(u) is directly maintained during the optimization procedure ( Brendel et al., 2017 ;  Cheng et al., 2019 ). 2 At each iteration, we run m iterations of A on each active configuration u ∈ P a to get the improved configurations. Then we conduct the following two operations to reduce the candidate pool size and to resample new configurations to explore important subspace based on Bayesian optimization. We discuss each step in details as below. Successive Halving (SH) to cut unimportant candidate configuration. After updating each candidate by m iterations, we compute the objective function value of each candidate and dis- card the worst half of them. Iteratively reducing the candidate set into half accelerates the algo- rithm, while still maintaining an accurate solution pool. This idea has been used in hyperparameter search ( Jamieson & Talwalkar, 2016 ) but has not been used in adversarial attack.

Section Title: Bayesian Optimization (BO) for Guided Resampling
  Bayesian Optimization (BO) for Guided Resampling To introduce variance in the intermediate steps and explore other important region, we propose a guided resampling strategy to refine the candidate pool. The general idea is to resample from the solution space in the middle step based on the knowledge acquired before and focus on promising subareas. Specifically, we use a Bayesian optimization method called Tree Parzen Estimator (TPE) ( Bergstra et al., 2011 ) to resample new configurations. In order to do resampling, we maintain another pool P s that stores all the previous iterations per- formed including the cutted ones, since all the information will be useful for resampling. As shown in Algorithm 2, we first divide the observed data in P s into worse and better parts based on the associated objective function value. We then train two separate Kernel Density Estimators (KDE) denoted as l(·) and g(·) on these two subsets. The parameter α is set to 20%, which ensures the better part l(u) has 20% of configurations in P s and the worse part g(u) has the remaining 80%, relatively. Later, we sample new data with the minimum value of l(·)/g(·), which can be proved to have maximum relative improvement in Equation 4 (see more information in Appendix B). Since we can not directly find such points, we sample for a few times (the number is set to 100 during the experiment) from l(·) and keep the one with the minimal l(·)/g(·). The reason we use TPE for resampling is that the computational cost grows linearly with the number of data points in P s . In comparison, traditional Bayesian optimization method like Gaussian Process (GP) will require cubic-time to generate new points. Therefore, TPE is more suitable for high dimensional problems. In the experiments we find that the final best configuration mostly comes from resampling, instead of the set of starting configurations. This proves the effectiveness of resampling during search, the quantitative results will be shown in Section 4.2.

Section Title: EXPERIMENTS
  EXPERIMENTS We conduct experiments on various models and datasets to verify the efficiency and effectiveness of the proposed approach. We try to enhance the performance of decision-based attack on image clas- sification tasks like MNIST, CIFAR-10 and ImageNet, and also conduct experiments on tree model like GBDT and detection model like LID. Furthermore, we demonstrate that our meta-algorithm is also able to improve existing white-box attacks.

Section Title: DECISION-BASED ATTACK ON NEURAL NETWORKS
  DECISION-BASED ATTACK ON NEURAL NETWORKS We conduct experiments on three standard datasets: MNIST ( LeCun et al., 1998 ), CIFAR-10 ( Krizhevsky et al., 2010 ) and ImageNet-1000 ( Deng et al., 2009 ). The neural network model ar- chitecture is the same with the ones reported in  Cheng et al. (2018) : for both MNIST and CIFAR we use the network with four convolution layers, two max-pooling layers and two fully-connected layers, which achieve 99.5% accuracy on MNIST and 82.5% accuracy on CIFAR-10 as reported in ( Carlini & Wagner, 2017b ;  Cheng et al., 2018 ). For ImageNet, we use the pretrained Resnet-50 ( He et al., 2016 ) network provided by torchvision ( Marcel & Rodriguez, 2010 ), which achieves a Top-1 accuracy of 76.15%. We randomly select 100 examples from test sets for evaluation. The parameters of the proposed algorithms can be found in Table 6 in Appendix D.

Section Title: Improved solution quality of existing methods
  Improved solution quality of existing methods We compare the solution quality of the proposed algorithm with three existing decision-based attack methods: Boundary attack ( Brendel et al., 2017 ), OPT-attack ( Cheng et al., 2018 ) and Sign-OPT attack ( Cheng et al., 2019 ) on MNIST, CIFAR-10 and ImageNet data sets. For our algorithm, we use Sign-OPT attack as the base algorithm and set k = 30 for the initial candidate pool. The average L 2 perturbation of our method and baselines are presented in Table 8. Note that all the decision based attacks maintain intermediate iterates on the decision boundary, so they always output a successful attack. The main comparison is the average L 2 perturbation to alter the predictions. We also follow  Cheng et al. (2018)  to report Attack Success Rate (ASR) by calculating ratio of adversarial examples with perturbation < ( is chosen based on Under review as a conference paper at ICLR 2020 different tasks). The results show that can help decision-based attacks achieve lower L 2 perturbation and higher attack success rate. The detailed analysis is shown in the next section. The proposed algorithm can also be used to boost the performance of other decision based attacks. Table 7 in the Appendix demonstrates that the proposed algorithm consistently improves the L 2 perturbation and success rate of Boundary attack and OPT-attack.

Section Title: ANALYSIS
  ANALYSIS We then conduct a study to test each component of our algorithm and compare with the baselines. The experiment is done on MNIST data using Sign-OPT attack as the base attack method. The results are summarized in  Table 2 . Comparison with naive mulitple initialization approach. A naive way to improve the solution quality of existing attack is to run the attack on multiple random initialization points. This strategy has been used in white-box attack 3 and is also applicable to the decision based attacks. We compare Sign-OPT with 30, 50, 100 initial points and the proposed BOSH boosted Sign-OPT approach in  Table 2 . The results demonstrate that successive halving requires much less queries than naively run- ning multiple initial configurations. Due to resampling, the proposed approach converges to a better solution under the same initial pool size. For example, to achieve average 0.91 L 2 perturbation, BOSH boosted Sign-OPT requires 10 times less queries than multi-initial Sign-OPT.

Section Title: Size of the initial pool
  Size of the initial pool The size of initial pool (denoted by k in our algorithm) is an important parameter.  Table 2  shows that increasing k only has a marginal effect after k ≈ 30. When introduc- ing cutting and resampling mechanism into the Sign-OPT attack, the final best perturbation is less sensitive to the number of starting directions, which means that resampling tend to make the search less dependent on the starting directions. Detailed discussion is in Appendix C.

Section Title: Under review as a conference paper at ICLR 2020
  Under review as a conference paper at ICLR 2020 Effect of successive halving and TPE resampling. We study the effect of these two components separately. As shown in Figure 3(a), the approach of successive halving keeps throwing away the worse s percent of configurations until converge during a specific interval until there is only one sample left. When combining this with resampling, as in Figure 3(b), our algorithm finds directions that are better than original ones. We observed emperically that the final best direction often comes from resampling instead of the original starting directions. This observation demonstrates the impor- tance of resampling in the intermediate steps. Furthermore,  Table 2  shows that combining Sign-OPT with successive halving (second column) has worse solutions compared with BOSH Sign-OPT. This indicates that resampling is important for getting a better solution. What is the best cutting interval? The parameter M decides how many iterations are applied using base attacker before the next cutting/resampling stage. This is an important parameter to be tuned. If M is too small, some solution paths will be wrongly throwing away; while if M is too large, the whole procedure requires a large number of queries. In our experiment, we use a subset of images to tune this parameter and find that the images in the same dataset often share similar best cutting interval. This reduces lots of unnecessary computations. The parameters for different datasets are shown in Appendix D.

Section Title: DECISION-BASED ATTACK ON OTHER MODELS
  DECISION-BASED ATTACK ON OTHER MODELS We conduct untargeted attack on gradient boosting decision tree (GBDT). Since Sign-OPT does not include the experiment with GBDT, we use the OPT-based attack ( Cheng et al., 2018 ) and apply our meta algorithm on top of it. We consider two datasets, MNIST and HIGGS, and use the same models provided by ( Cheng et al., 2018 ). We compare the average L 2 perturbation and the attack success rate in  Table 3 . The results show that the proposed method significantly boosts the performance of OPT attack. The overall improvement is more significant than attacking neural networks. This is mainly because that the decision boundary of GBDT contains more local minima than neural networks, as plotted in  Figure 1 .

Section Title: DECISION-BASED ATTACK ON DETECTION MODELS
  DECISION-BASED ATTACK ON DETECTION MODELS To improve the performance of neural networks, a line of research, such as KD+BU ( Feinman et al., 2017 ), LID ( Ma et al., 2018 ), Mahalanobis ( Lee et al., 2018 ) and ML-LOO ( Yang et al., 2019 ), has been focusing on screening out adversarial examples in the test stage without touching the training of the original model. Besides comprehensive evaluation of our attack on various classification models with a variety of data sets, we carry out experimental analysis of our untargeted attack on one state-of-the-art detection model LID ( Ma et al., 2018 ) on MNIST data set. To train a detection model on MNIST, we first train a simple classification network composed of two convolutional layers followed by a hidden dense layer with 1024 units. Then we apply C&W attack to this model to generate adversarial examples from the original test samples. Finally we train LID detectors with the original test samples and adversarial examples we have generated with the standard train/test split. The state-of-the-art detection model LID achieves 0.99 test accuracy. C&W high confidence attack ( Carlini & Wagner, 2017a ) has been shown to have great performance in attacking various detection models. So we compare the average L 2 perturbation and attack success rate of three attacking methods C&W high confidence attack, Sign-OPT attack and BOSH Sign-OPT attack in  Table 4 . At each query, we define the attack to be successful if it fools both the detector model and the original model. The results show that the proposed method can significantly boost the performance of the Sign-OPT attack and it achieves much better performance than C&W high confidence attack.

Section Title: CONCLUSION
  CONCLUSION In this paper, we propose a meta algorithm to boost the performance of existing decision based at- tacks. In particular, instead of traversing a single solution path when searching for an adversarial example, we maintain a pool of solution paths to explore important regions. We show empirically that the proposed algorithm consistently improves the solution quality of many existing decision based attacks, and can obtain adversarial examples with improved quality on not only neural net- works, but also other decision based models, such as GBDT and detection-based models.
  Here local minimum indicates a point on the decision boundary that has shortest distance to the original example, compared to other nearby points on the decision boundary. Those local minimums are the points where a decision-based attack can converge to.

```
