Title:
```
Published as a conference paper at ICLR 2020 INTRINSICALLY MOTIVATED DISCOVERY OF DIVERSE PATTERNS IN SELF-ORGANIZING SYSTEMS
```
Abstract:
```
In many complex dynamical systems, artificial or natural, one can observe self- organization of patterns emerging from local rules. Cellular automata, like the Game of Life (GOL), have been widely used as abstract models enabling the study of various aspects of self-organization and morphogenesis, such as the emergence of spatially localized patterns. However, findings of self-organized patterns in such models have so far relied on manual tuning of parameters and initial states, and on the human eye to identify "interesting" patterns. In this paper, we for- mulate the problem of automated discovery of diverse self-organized patterns in such high-dimensional complex dynamical systems, as well as a framework for experimentation and evaluation. Using a continuous GOL as a testbed, we show that recent intrinsically-motivated machine learning algorithms (POP-IMGEPs), initially developed for learning of inverse models in robotics, can be transposed and used in this novel application area. These algorithms combine intrinsically- motivated goal exploration and unsupervised learning of goal space representa- tions. Goal space representations describe the "interesting" features of patterns for which diverse variations should be discovered. In particular, we compare vari- ous approaches to define and learn goal space representations from the perspective of discovering diverse spatially localized patterns. Moreover, we introduce an ex- tension of a state-of-the-art POP-IMGEP algorithm which incrementally learns a goal representation using a deep auto-encoder, and the use of CPPN primitives for generating initialization parameters. We show that it is more efficient than several baselines and equally efficient as a system pre-trained on a hand-made database of patterns identified by human experts.
```

Figures/Tables Captions:
```
Figure 1: Population-based intrinsically motivated goal exploration process with incremental learn- ing of a goal space (IMGEP-OGL algorithm) used to explore a continuous GOL model.
Figure 2: Example patterns produced in the continuous GOL system (Lenia). Illustration of the dynamical morphing from an initial CPPN image to an animal (a). The automated discovery (b) is able to find similar complex animals as a human-expert manual search (c) by Chan (2019).
Figure 3: (a) Although random explorations reach the highest diversity in the analytic parameter space, (b) IMGEPs reach a higher diversity in the analytic behavior space (except when using ran- dom representations). (c) IMGEPs with a learned goal space discovered a larger diversity of animals compared to a hand-defined goal space. (d) Learned goal spaces are as efficient as a hand-defined space for finding diverse non-animals. Overall, IMGEPs with unsupervised learning of goal features are efficient to discover a diversity of diverse patterns. Depicted is the average diversity (n = 10) with the standard deviation as shaded area (for some not visible because it is too small). The final diversity is significantly different (Welchs t-test, p < 0.01) for algorithms between the braces plotted on the right of each figure. See Figs. 6 to 10 for a qualitative visual illustration of these results.
Figure 4: (a) Hand-defined and (b) learned goal spaces have major differences shown here by a t- SNE visualization. The different number and size of clusters of animals or non-animals can explain the differences in their resulting diversity between the algorithms (Fig. 3).
```

Main Content:
```

Section Title: INTRODUCTION
  INTRODUCTION Self-organization of patterns that emerge from local rules is a pervasive phenomena in natural and artificial dynamical systems ( Ball, 1999 ). It ranges from the formation of snow flakes, spots and rays on animal's skin, to spiral galaxies. Understanding these processes has boosted progress in many fields, ranging from physics to biology ( Camazine et al., 2003 ). This progress relied importantly on the use of powerful and rich abstract computational models of self-organization ( Kauffman, 1993 ). For example, cellular automata like Conway's Game of Life (GOL) have been used to study the emergence of spatially localized patterns (SLPs) ( Gardener, 1970 ), informing theories of the origins of life ( Gardener, 1970 ;  Beer, 2004 ). SLPs, such as the famous glider in GOL ( Gardner et al., 1983 ), are self-organizing patterns that have a local extension and can exist independently of other patterns. However, finding such novel self-organized patterns, and mapping the space of possible emergent patterns, has so far relied heavily on manual tuning of parameters and initial states. Moreover, the dependence of this exploration process on the human eye to identify "interesting" patterns is strongly limiting further advances. We formulate here the problem of automated discovery of a diverse set of self-organized patterns in such high-dimensional, complex dynamical systems. This involves several challenges. A first Published as a conference paper at ICLR 2020 challenge consists in determining a representation of patterns, possibly through learning, enabling to incentivize the discovery of diverse "interesting" patterns. Such a representation guides exploration by providing a measure of (di-)similarity between patterns. This problem is particularly challenging in domains where patterns are high-dimensional as in GOL. In such cases, scientists have a limited intuition about what useful features are and how to represent them. Moreover, low-dimensional representations of patterns are needed for human browsing and the visualization of the discoveries. Representation learning shall both guide exploration, and be fed by self-collected data. A second challenge consists in how to automate exploration of high-dimensional, continuous initial- ization parameters to discover efficiently "interesting" patterns, such as SLPs, with a limited budget of experiments. Sample efficiency is important to enable the later use of such discovery algorithms for physical systems ( Grizou et al., 2020 ), where experimental time and costs are strongly bounded. For example, in the continuous GOL used in this paper as a testbed, initialization consists in deter- mining the values of a real-valued, high-dimensional 256×256 matrix besides 7 additional dynamics parameters. The possible variations of this matrix are too large for a simple random sampling to be efficient. More structured methods are needed. To address these challenges, we propose to leverage and transpose recent intrinsically motivated learning algorithms, within the family of population-based Intrinsically Motivated Goal Exploration Processes (POP-IMGEPs - denoted simply as IMGEPs below, Baranes & Oudeyer (2013);  Péré et al. (2018) ). They were initially designed to enable autonomous robots to explore and learn what effects can be produced by their actions, and how to control these effects. IMGEPs self-define goals in a goal space that represents important features of the outcomes of actions, such as the position reached by an arm. This allows the discovery of diverse novel effects within their goal representations. It was recently shown how deep neuronal auto-encoders enabled unsupervised learning of goal repre- sentations in IMGEPs from raw pixel perception of a robot's visual scene ( Laversanne-Finot et al., 2018 ). We propose to use a similar mechanism for automated discovery of patterns by unsupervised learning of a low-dimensional representation of features of self-organized patterns. This removes the need for human expert knowledge to define such representations. Moreover, a key ingredient for sample efficient exploration of IMGEPs for robotics has been the use of structured motion primitives to encode the space of body motions ( Pastor et al., 2013 ). We propose to use a similar mechanism to handle the generation of structured initial states in GOL-like complex systems, based on specialized recurrent neural networks (CPPNs) ( Stanley, 2006 ). In summary, we provide in this paper the following contributions: • We formulate the problem of automated discovery of diverse self-organized patterns in high-dimensional and complex game-of-life types of dynamical systems. • We show how to transpose POP-IMGEPs algorithms to address the associated joint chal- lenge of learning to represent interesting patterns and discovering them in a sample efficient manner. • We compare various approaches to define or learn goal space representations for the sample efficient discovery of diverse SLPs in a continuous GOL testbed. • We show that an extension of a state-of-the-art POP-IMGEP algorithm, with incremen- tal learning of a goal space using a deep auto-encoder, is equally efficient than a system pretrained on a hand-made database of patterns.

Section Title: RELATED WORK
  RELATED WORK Automated Discovery in Complex Systems Automated processes have been widely used to ex- plore complex dynamical systems. For example, evolutionary algorithms have been applied to search specific patterns or rules of cellular automata ( Mitchell et al., 1996 ;  Sapin et al., 2003 ). However, their objective is to optimize a specific goal instead of discovering a diversity of patterns. Another line of experiments represent active inquiry-based learning strategies which query which set of experiments to perform to improve a system model, i.e. a mapping from parameters to the system outcome. Such strategies have been used in biology ( King et al., 2004 ; 2009), chemistry ( Raccuglia et al., 2016 ;  Reizman et al., 2016 ;  Duros et al., 2017 ) and astrophysics ( Richards et al., 2011 ). However, these approaches have relied on expert knowledge, and focused on automated opti- Published as a conference paper at ICLR 2020 mization of a pre-defined target property. Here, we are interested to automatically discover and map a diversity of unseen patterns without prior knowledge of the system. An exception is the concurrent work of  Grizou et al. (2020) , which showed how a simple POP-IMGEP algorithm could be used to automate discovery of diverse patterns in oil-droplet systems. However, it used a low-dimensional input space, and a hand-defined low-dimensional representation of goal spaces, identified as a major limit of the system. Intrinsically motivated learning Intrinsically-motivated learning algorithms ( Baldassarre & Mirolli, 2013 ;  Baranes & Oudeyer, 2013 ) autonomously organize an agent's exploration curriculum in order to discover efficiently a maximally diverse set of outcomes the agent can produce in an un- known environment. They are inspired from the way children self-develop open repertoires of skills and learn world models. Intrinsically Motivated Goal Exploration Processes (IMGEPs) ( Baranes & Oudeyer, 2013 ;  Forestier et al., 2017 ) are a family of curiosity-driven algorithms developed to allow efficient exploration of high-dimensional complex real world systems. Population-based versions of these algorithms, which leverage episodic memory, hindsight learning, and structured dynamic motion primitives to parameterize policies, enable sample efficient acquisition of high-dimensional skills in real world robots ( Forestier et al., 2017 ;  Rolf et al., 2010 ). The discovered repertoires of di- verse behaviors can be reused to solve hard exploration downstream tasks ( Colas et al., 2018 ;  Conti et al., 2018 ). Recent work ( Laversanne-Finot et al., 2018 ;  Péré et al., 2018 ) studied how to auto- matically learn the goal representations with the use of deep variational autoencoders. However, training was done passively and in an early stage on a precollected set of available observations. Recent approaches ( Nair et al., 2018 ;  Pong et al., 2019 ) introduced the use of an online training of variational autoencoders VAEs to learn the important features of a goal space similar to the methods in this paper. However, these approaches focused on the problem of sequential decisions in MDPs, incurring a cost on sample efficiency. This problem is observed in various intrinsically motivated RL approaches ( Bellemare et al., 2016 ;  Burda et al., 2019b ). These approaches are orthogonal to the automated discovery framework considered here with independent experiments allowing the use of memory-based sample efficient methods. A related family of algorithms in evolutionary com- putation is novelty search ( Lehman & Stanley, 2008 ) and quality-diversity algorithms ( Pugh et al., 2016 ), which can be formalized as special kinds of population-based IMGEPs.

Section Title: Representation learning
  Representation learning We are using representation learning methods to learn autonomously goal spaces for IMGEPs. Representation learning aims at finding low-dimensional explanatory fac- tors representing high-dimensional input data ( Bengio et al., 2013 ). It is a key problem in many areas in order to understand the underlying structure of complex observations. Many state-of-the-art methods ( Tschannen et al., 2018 ) have built on top of Deep VAEs ( Kingma & Welling, 2013 ), using varying objectives and network architectures. However, studies of the interplay between represen- tation learning and autonomous data collection through exploration of an environment have been limited so far.

Section Title: ALGORITHMIC METHODS FOR AUTOMATED DISCOVERY
  ALGORITHMIC METHODS FOR AUTOMATED DISCOVERY

Section Title: POPULATION-BASED INTRINSICALLY MOTIVATED GOAL EXPLORATION PROCESSES
  POPULATION-BASED INTRINSICALLY MOTIVATED GOAL EXPLORATION PROCESSES An IMGEP is an algorithmic process generating a sequence of experiments to explore the param- eters of a system by targeting self-generated goals ( Fig. 1 ). It aims to maximize the diversity of observations from that system within a budget of N experiments. In population-based IMGEPs, an explicit memory of the history H of experiments and observations is used to guide the process. The systems are defined by three components. A parameter space Θ corresponding to the control- lable system parameters θ. An observation space O where an observation o is a vector representing all the signals captured from the system. For this paper, the observations are a time series of images which depict the morphogenesis of activity patterns. Finally, an unknown environment dynamic D: Θ → O which maps parameters to observations. To explore a system, an IMGEP uses a goal space T that represents relevant features of its obser- vations, computed by an encoding functionĝ = R(o). For an exploration of patterns, such features may describe their form or extension. The exploration process iterates N times through: 1) sample a goal from a goal sampling distribution g ∼ G(H); 2) infer corresponding parameter θ using a Published as a conference paper at ICLR 2020 parameter sampling policy Π = Pr(θ; g, H); 3) roll-out an experiment with θ, observe outcome o, compute encoding R(o); 4) store (θ, o, R(o)) in history H. The parameter sampling policy Π and in some cases the goal sampling distribution G take into account previous explorations stored in history H. Therefore, the history is first populated through exploring N init randomly sampled parameters. After this initial phase the described intrinsically motivated goal exploration process starts. Different goal and parameter sampling mechanisms can be used within this architecture ( Baranes & Oudeyer, 2013 ;  Forestier & Oudeyer, 2016 ). In the experiments below, goals are sampled uniformly over a hyperrectangle defined in T . The hyperrectangle is chosen large enough to allow a sampling of a large goal diversity. The parameters are sampled by 1) given a goal, selecting the parameter from the history whose corresponding outcome is most similar in the goal space; 2) then mutating it by a random process.

Section Title: ONLINE LEARNING OF GOAL SPACES WITH DEEP AUTO-ENCODERS
  ONLINE LEARNING OF GOAL SPACES WITH DEEP AUTO-ENCODERS For IMGEPs the definition of the goal space T and its corresponding encoder R are a critical part, because it biases exploration of the target system. One approach is to define a goal space by selecting features manually, for example by using computer vision algorithms to detect the positions of a pattern and its form. The diversity found by the IMGEPs will then be biased along these pre-defined features. A limit of this approach is its requirement of expert knowledge to select helpful features, particularly problematic in environments where experts do not know in advance what features are important, or how to formulate them. Another approach is to learn goal space features by unsupervised representation learning. The aim is to learn a mapping R(o) from the raw sensor observations o to a compact latent vector z ∈ R d . This latent mapping can be used as a goal space where a latent vector z = g is interpreted as a goal. Previous IMGEP approaches already learned successfully their goal spaces with VAEs ( Laversanne- Finot et al., 2018 ;  Péré et al., 2018 ). However, the goal spaces were learned before the start of the exploration from a prerecorded dataset of observations from the target environment. During the exploration the learned representations were kept fixed. A problem with this pretraining approach is that it limits the possibilities to discover novel patterns beyond the distribution of pretraining examples, and requires expert knowledge. In this paper we attempt to address this problem by continuously adapting the learned representation to the novel observations encountered during the exploration process. For this purpose, we propose an online goal space learning IMGEP (IMGEP-OGL), which learns the goal space incrementally during the exploration process (Algorithm 1). The training procedure of the VAE is integrated in the goal sampling exploration process by first initializing the VAE with random weights (Appendix B.6). The VAE network is then trained every K explorations for E epochs on the observation collected in the history H. Importance sampling is used to give more weight to recently discovered patterns by using a weighted random sampler. It samples for 50% of the training batch samples patterns from the last K iterations and for the other 50% patterns from all other previous iterations.

Section Title: STRUCTURING THE PARAMETER SPACE IN IMGEPS: FROM DMPS TO CPPNS
  STRUCTURING THE PARAMETER SPACE IN IMGEPS: FROM DMPS TO CPPNS A key role in the generation of patterns in dynamical systems is their initial state A t=1 . IMGEPs sample these initial states and apply random perturbations to them during the exploration. For the experiments in this paper this state is a two-dimensional grid with 256 × 256 cells. Performing directly a random sampling of the 256 × 256 grid cells results in initial patterns that resemble white noise. Such random states result mainly in the emergence of global patterns that spread over the whole state space, complicating the search for spatially localized patterns. This effect is analogous to a similar problem in the exploration of robot controllers. Direct sampling of actions for individual actuators at a microscopic time scale is usually inefficient. A key ingredient for sample efficient exploration has been the use of structured primitives (dynamic motion primitives - DMPs) to encode the space of possible body motions ( Pastor et al., 2013 ). We solved the sampling problem for the initial states by transposing the idea of structured primitives. Indeed, "actions" consist here in deciding the parameters of an experiment, including the initial state. We propose to use compositional pattern producing networks (CPPNs) ( Stanley, 2006 ) to produce structured initial patterns similar do DMPs. CPPNs are recurrent neural networks that allow the generation of structured initial states. (Appendix B.4, Fig. 14). They are defined by their network structure (number of neurons, connections between neurons) and their connection weights. Thus, instead of using directly an initial state as part of the parameters θ to control the dynamical system, a CPPN is used. If a system roll-out for the parameters θ are performed, then the initial state A t=1 is generated by the CPPN. Moreover, instead of sampling and mutating directly an initial state, the weights and structure of the CPPN are randomly generated and mutated. Please note, the number of parameters in θ is therefore not fixed and open-ended (yet starts small) because the structure and the number of weights of randomly sampled and mutated CPPNs differ.

Section Title: EXPERIMENTAL METHODS
  EXPERIMENTAL METHODS We describe here the continuous Game of Life (Lenia) we use as a testbed representing a large class of high-dimensional dynamical systems, as well as the experimental procedures, the evaluation methods used to measure diversity and detect SLPs, and the used algorithmic baselines and ablations. Implementation details and parameter settings for all procedures are given in Appendix B.

Section Title: CONTINOUS GAME OF LIFE AS A TESTBED
  CONTINOUS GAME OF LIFE AS A TESTBED Lenia ( Chan, 2019 ) is a continuous cellular automaton ( Wolfram, 1983 ) similar to Conway's Game of Life ( Gardener, 1970 ). Lenia, in particular, represents a high-dimensional complex dynamical system where diverse visual structures can self-organize and yet are hard to find by manual explo- ration. It features the richness of Turing-complete game-of-life models. It is therefore well suited to test the performance of pattern exploration algorithms for unknown and complex systems. The fact that GOL models have been used widely to study self-organization in various disciplines, ranging from physics to biology and economics ( Bak et al., 1989 ), also supports their generality and potential of reuse of our approach for discovery in other computational or wet high-dimensional systems. Lenia consists of a two-dimensional grid of cells A ∈ [0, 1] 256×256 where the state of each cell is a real-valued scalar activity A t (x) ∈ [0, 1]. The state of cells evolves over discrete time steps t (Fig. 2, a). The activity change is computed by integrating the activity of neighboring cells. Lenia's behavior is controlled by its initial pattern A t=1 and several settings that control the dynamics of the activity change (R, T, µ, σ, β 1 , β 2 , β 3 ). Lenia can be understood as a self-organizing morphogenetic system. Its parameters for the initial pattern A t=1 and dynamics control determine the development of morphological patterns. Lenia can produce diverse patterns with different dynamics (stable, non-stable or chaotic). Most interesting, spatially localized coherent patterns that resemble in their shapes microscopic animals can emerge (Fig. 2, b, c). These pattern types, which we will denote "animals" as a short name, are a key reason scientists have used GOL models to study theories of the origins of life ( Gardener, 1970 ;  Beer, 2004 ). Therefore, in our evaluation method based on measures of diversity (see below), we will in particular study the performance of IMGEPs, and the impact of using various approaches for goal space representation, on finding a diversity of animal patterns. We implemented for this purpose different pattern classifiers to analyze the exploration results. Initially we differentiate between dead and alive patterns. A pattern is dead if the activity of all cells are either 0 or 1. Alive patterns are separated into animals and non-animals. Animals are a connected areas of positive activity which are finite, i.e. which do not infinitely cross several borders. All other patterns are non-animals whose activity usually spreads over the whole state space.

Section Title: EVALUATION BASED ON THE DIVERSITY OF PATTERNS
  EVALUATION BASED ON THE DIVERSITY OF PATTERNS The algorithms are evaluated based on their discovered diversity of patterns. Diversity is measured by the spread of the exploration in an analytic behavior space. This space is externally defined by the experimenter as in previous evaluation approaches in the IMGEP literature. For example, in  Péré et al. (2018) , the diversity of discovered effects of a robot that manipulates objects is measured by binning the space of object positions and counting the number of bins discovered. A difference here is that the experimenter does not have access to an easily interpretable hand-defined low-dimensional representation of possible patterns, equivalent to the cartesian coordinate of rigid objects. The space of raw observations O, i.e. the final Lenia patterns A t=200 , is also too high-dimensional for a mean- ingful measure of spread in it. We constructed therefore an external evaluation space. First, a latent representation space was build through the training of a β-VAE ( Higgins et al., 2017 ) to learn the important features over a large dataset of 42500 Lenia patterns identified during the many exper- iments over all evaluated algorithms. This large dataset enabled to cover a diversity of patterns orders of magnitude larger than what could be found in any single algorithm experiment, which ex- perimental budget was order of magnitude smaller. We then augmented that space by concatenating hand-defined features (the same features were used for a hand-defined goal space IMGEP). For each experiment, all explored patterns were projected into the analytic behavior space. The diversity of the patterns is then measured by discretizing the space into bins of equal size by splitting each dimension into 7 sections (results were found to be robust to the number of bins per dimension, see Appendix B.7). This results in 7 13 bins. The number of bins in which at least one explored entity falls is used as a measure for diversity. We also measured the diversity in the space of parameters Θ by constructing an analytic parameter space. The 15 features of this space consisted of Lenia's parameters (R, T , µ, σ, β 1 , β 2 , β 3 ) and the latent representation of a β-VAE. The β-VAE was trained on a large dataset of initial Lenia states (A t=1 ) used over the experimental campaign. This diversity measures also used 7 bins per dimension.

Section Title: ALGORITHMS
  ALGORITHMS The exploration behaviors of different IMGEP algorithms were evaluated and compared to a random exploration. The IMGEP variants differ in their way how the goal space is defined or learned.

Section Title: Random exploration
  Random exploration The IMGEP variants were compared to a random exploration that sampled randomly for each of the N exploration iterations the parameters θ including the initial state A t=1 .

Section Title: IMGEP-HGS - Goal exploration with a hand-defined goal space
  IMGEP-HGS - Goal exploration with a hand-defined goal space The first IMGEP uses a hand- defined goal space that is composed of 5 features used in  Chan (2019) . Each feature measures a certain property of the final pattern A t=200 that emerged in Lenia: 1) the sum over the activity of all cells, 2) the number of activated cells, 3) the density of the activity center, 4) an asymmetry measure of the pattern and 5) a distribution measure of the pattern.

Section Title: IMGEP-PGL - Goal exploration with a pretrained goal space
  IMGEP-PGL - Goal exploration with a pretrained goal space For this IMGEP variant the goal space was learned with a β-VAE approach on training data before the exploration process started. The training set consisted of 558 Lenia patterns: half were animals that have been manually identi- fied by  Chan (2019) ; the other half randomly generated with CPPNs (see Section 4.4). IMGEP-OGL - Goal exploration with online learning of the goal space: Algorithm 1. IMGEP-RGS - Goal exploration with a random goal space: An ablated IMGEP using a goal space based on the encoder of a VAE with random weights.

Section Title: EXPERIMENTAL PROCEDURE AND HYPERPARAMETERS
  EXPERIMENTAL PROCEDURE AND HYPERPARAMETERS For each algorithm 10 independent repetitions of the exploration experiment were conducted. Each experiment consisted of N = 5000 exploration iterations. This number was chosen to be compatible with the application of the algorithms in physical experimental setups similar to  Grizou et al. (2020) , planned in future work. For IMGEP variants the first N init = 1000 iterations used random parameter sampling to initialize their histories H. For the following 4000 iterations each IMGEP approach sampled a goal g via an uniform distribution over its goal space. The ranges for sampling in the hand- Published as a conference paper at ICLR 2020 defined goal space (HGS) are defined in Table 3 (Appendix B.5). The ranges for the β-VAE based goal spaces (PGL, OGL) were set to [−3, 3] for each of their latent variables. Then, the parameter θ k from a previous exploration in H was selected whose reached goalĝ k had the minimum euclidean distance to the current goal g within the goal space. This parameter was then mutated to generate the parameter θ that was explored. The parameters θ consisted of a CPPN (Section 3.3) that generates the initial state A t=1 for Lenia and the settings defining Lenia's dynamics: θ = [CPPN → A t=1 , R, T, µ, σ, β 1 , β 2 , β 3 ]. CPPNs were initialized and mutated by a random process that defines their structure and connection weights as done by  Stanley (2006) . The random initialization of the other Lenia settings for the dynamics was done by an uniform distribution and their mutation by a Gaussian distribution around the original values. The meta parameters to initialize and mutate the parameters were the same for all algorithms. They were manually chosen without optimizing them for a specific algorithm.

Section Title: RESULTS
  RESULTS We address several questions evaluating the ability of IMGEP algorithms to identify a diverse set of patterns, and in particular diverse "animal" patterns (i.e. spatially localized patterns).

Section Title: Does goal exploration outperform random parameter exploration?
  Does goal exploration outperform random parameter exploration? In robotics/agents contexts where scenes are populated with rigid objects, various forms of goal exploration algorithms outper- form random parameter exploration ( Laversanne-Finot et al., 2018 ). We checked whether this still holds in continuous GOL which have very different properties. Measures of the diversity in the analytic behavior space confirmed the advantage of IMGEPs with hand-designed (HGS) or learned goal spaces (PGL/OGL) over random explorations (Fig. 3, b). The organization resulting from goal exploration is also visible through the diversity in the space of parameters. IMGEPs focus their exploration on subspaces that are useful for targeting new goals. In contrast, random parameter exploration is unguided, resulting in a higher diversity in the parameter space (Fig. 3, b). What is the impact of learning a goal space vs. using random or hand-defined features? We compared also the performance of random VAE goal spaces (RGS) to learned goal spaces (PGL/OGL). For reinforcement learning problems, using intrinsic reward functions based on random features of the observations can result in a high or boosted performance (Burda et al., 2019a;b). In our context however, using random features (RGS) collapsed the performance of goal exploration, and did not even outperform random parameter exploration for all kinds of behavioral diversity ( Fig. 3 ). Results also show that hand-defined features (HGS) produced significantly less global di- versity and less "animal" diversity than using learned features (PGL/OGL). However, HGS found an equal diversity of "non-animals". These results show that in this domain, the goal-space has a critical influence on the type and diversity of patterns discovered. Furthermore, unsupervised learn- ing is an efficient approach to discover a diversity of diverse patterns, i.e. both efficient at finding diverse animals and diverse non-animals. Is pretraining on a database of expert patterns necessary for efficient discovery of diverse animals? A possibility to bias exploration towards patterns of interest, such as "animals", is to pretrain a goal space with a pattern dataset hand-made by an expert. Here PGL is pretrained with a dataset containing 50% animals. This leads PGL to discover a high diversity of animals. How- ever, the new online approach (OGL) is as efficient as PGL to discover diverse patterns (Fig. 3, b,c,d). Taken together, these results uncover an interesting bias of using learned features with a VAE architecture, which strongly incentivizes efficient discovery of diverse spatially localized patterns.

Section Title: How do goal space representations differ
  How do goal space representations differ We analyzed the goal spaces of the different IMGEP variants to understand their behavior by visualizing their reached goals in a two-dimensional space. T-SNE ( Maaten & Hinton, 2008 ) was used to reduce the high-dimensional goal spaces. The hand-defined (HGS) and learned (OGL) goal spaces show strong differences between each other ( Fig. 4 ). We believe this explains their different abilities to find either a high diversity of non-animals or animals (Fig. 3, c, d). The goal space of the HGS shows large areas and several clusters for non- animal patterns (Fig. 4, a). Animals form only few and nearby clusters. Thus, the hand-defined features seem poor to discriminate and describe animal patterns in Lenia. As a consequence, when goals are uniformly sampled within this goal space during the exploration process, then more goals are generated in regions that describe non-animals. This can explain why HGS explored a higher diversity of non-animal patterns but only a low diversity of animal patterns. In contrast, features learned by OGL capture better factors that differentiate animal patterns. This is indicated by the several clusters of animals that span a wide area in its goal space (Fig. 4, b). We attribute this effect to the difficulty of VAEs to capture sharp details ( Zhao et al., 2017 ). They therefore represent mainly the general form of the patterns but not their fine-grained structures. Animals differ often in their form whereas non-animals occupy often the whole cell grid and differ in their fine-grained details. The goal spaces learned by VAEs seem therefore better suited for exploring diverse sets of animal patterns.

Section Title: CONCLUSION
  CONCLUSION We formulated a novel application area for machine learning: the problem of automatically discover- ing self-organized patterns in complex dynamical systems with high-dimensions both in the param- eter space and in the observation space. We showed that this problem calls for advanced methods re- quiring the dynamic interaction between sample efficient autonomous exploration and unsupervised representation learning. We demonstrated that population-based IMGEPs are a promising algorith- mic framework to address this challenge, by showing how it can discover diverse self-organized patterns in a continuous GOL. In particular, we introduced a new approach for learning a goal space representation online via data collected during the exploration process. It enables sample efficient discovery of diverse sets of animal-like patterns, similar to those identified by human experts and yet without relying on such prior expert knowledge ( Fig. 2 ). We also analyzed the impact of goal space representations on the diversity and types of discovered patterns. The continuous game of life shares many properties with other artificial or natural complex systems, explaining why GOL models have been used in many disciplines to study self-organization, see  Bak et al. (1989) . We therefore believe this study shows the potential of IMGEPs for automated discovery in other systems encountered in physics, chemistry or even computer animation. In further work, we aim to apply this approach in robotized wet experiments such as the one presented in  Grizou et al. (2020)  addressing the fundamental understanding of how proto-cells can self-organize. We are also working together with bio-chemists to map the space of behaviors of certain complex biochemistry systems for which no appropriate model exists. Once such a map has been discovered, it can be used to optimize the system for target properties by leveraging the diversity of patterns found through the unsupervised discovery process.

```
