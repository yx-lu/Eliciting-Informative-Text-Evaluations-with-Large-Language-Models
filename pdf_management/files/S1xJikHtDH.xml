<article article-type="research-article"><front><article-meta><title-group><article-title>Under review as a conference paper at ICLR 2020 IMPROVING MODEL COMPATIBILITY OF GENERATIVE ADVERSARIAL NETWORKS BY BOUNDARY CALIBRATION</article-title></title-group><abstract><p>Generative Adversarial Networks (GANs) is a powerful family of models that learn an underlying distribution to generate synthetic data. Many existing studies of GANs focus on improving the realness of the generated image data for visual applications, and few of them concern about improving the quality of the gener- ated data for training other classifiers-a task known as the model compatibility problem. Literature also show that some GANs often prefer generating 'easier' synthetic data that are far from the boundaries of the classifiers, and refrain from generating near-boundary data, which are known to play an important roles in training the classifiers. To improve GAN in terms of model compatibility, we propose Boundary-Calibration GANs (BCGANs), which leverage the boundary information from a set of pre-trained classifiers using the original data. In par- ticular, we introduce an auxiliary Boundary-Calibration loss (BC-loss) into the generator of GAN to match the statistics between the posterior distributions of original data and generated data with respect to the boundaries of the pre-trained classifiers. The BC-loss is provably unbiased and can be easily coupled with dif- ferent GAN variants to improve their model compatibility. Experimental results demonstrate that BCGANs not only generate realistic images like original GANs but also achieves superior model compatibility than the original GANs.</p></abstract></article-meta></front><body><sec><title>INTRODUCTION</title><p>The success of machine learning relies on not only the advances of different models (e.g. deep learning) but also data with sufficient quality and quantity. Nowadays, companies spend tremendous efforts and expense collecting data to build their products. To better solve complicated real-world problems with public or third-party machine learning experts, many companies now needs release some data sets for competitions (e.g. Kaggle) or proof-of-concept purposes. However, considering the costs of collecting data, companies may not be willing to release the dataset if possible. As a result, a technique which can generate synthetic data with properties similar to the original data is in demand. To be specific, we are looking for generating a dataset with the property that machine learning models trained on the generated dataset can exhibit similar performance to ones trained on the original data. This property is called model compatibility (<xref ref-type="bibr" rid="b21">Park et al., 2018</xref>) or machine learning efficacy (<xref ref-type="bibr" rid="b4">Xu et al., 2019</xref>). The organizations can share the generated data with high model compatibility to the public and enjoy the solution derived from it without leaking the real dataset.</p><p>When it comes to data generation, generative adversarial networks (GANs, <xref ref-type="bibr" rid="b4">Goodfellow et al. 2014</xref>) is the most popular family of generative algorithms because of its impressive performance on gen- erating realistic images (<xref ref-type="bibr" rid="b11">Karras et al., 2018</xref>). In GANs, the generator is trained via minimizing a neural network (discriminator) defined probability divergence (<xref ref-type="bibr" rid="b4">Goodfellow et al., 2014</xref>; <xref ref-type="bibr" rid="b0">Arjovsky et al., 2017</xref>; <xref ref-type="bibr" rid="b19">Nowozin et al., 2016</xref>). In addition to image generation, GANs are also widely used in other applications, such as style transfer (<xref ref-type="bibr" rid="b10">Isola et al., 2017</xref>; <xref ref-type="bibr" rid="b10">Zhu et al., 2017</xref>; <xref ref-type="bibr" rid="b12">Kim et al., 2017</xref>) and image processing (<xref ref-type="bibr" rid="b22">Pathak et al., 2016</xref>; <xref ref-type="bibr" rid="b14">Ledig et al., 2017</xref>; <xref ref-type="bibr" rid="b1">Chang et al., 2017</xref>), and generating differ- ent types of data, including time series (<xref ref-type="bibr" rid="b17">Luo et al., 2018</xref>; <xref ref-type="bibr" rid="b1">Chang et al., 2019</xref>), text (<xref ref-type="bibr" rid="b15">Yu et al., 2017</xref>; <xref ref-type="bibr" rid="b23">Press et al., 2017</xref>), point clouds (<xref ref-type="bibr" rid="b1">Li et al., 2018</xref>), voxels (<xref ref-type="bibr" rid="b27">Wu et al., 2016</xref>) and tabular data (<xref ref-type="bibr" rid="b21">Park et al., 2018</xref>; <xref ref-type="bibr" rid="b4">Xu et al., 2019</xref>).</p></sec><sec><title>Under review as a conference paper at ICLR 2020</title><p>Although GANs are versatile as mentioned above, most of their development focus on the metrics such as quality and diversity of the data <xref ref-type="bibr" rid="b25">Salimans et al. (2016)</xref>; <xref ref-type="bibr" rid="b8">Heusel et al. (2017)</xref>; <xref ref-type="bibr" rid="b16">Lucic et al. (2018)</xref>. Generating high model compatibility data via GANs is still under explored. The pioneering work (<xref ref-type="bibr" rid="b4">Xu et al., 2019</xref>) first shows that data generated from conditional GANs (<xref ref-type="bibr" rid="b4">Mirza &amp; Osindero, 2014</xref>) enjoys better model compatibility than VAEs (<xref ref-type="bibr" rid="b13">Kingma &amp; Welling, 2013</xref>). So we wonder can we improve the model compatibility if we consider information from the models trained on the original data? For example, Wasserstein GAN (<xref ref-type="bibr" rid="b0">WGAN, Arjovsky et al. 2017</xref>) performs a mean- matching between the distribution of real data and generated data. However, only mean-matching is sometimes not enough to learn the whole distribution especially for those boundary cases. Appar- ently, if a GAN knows the boundary between different classes, it may be able to generate instances which are close to the boundary with correct labels. These boundary points will guide a classifier to learn the correct decision boundary.</p><p>In this work, we try to improve GANs with regards to model compatibility in classification problems. We use a set of pre-trained classifiers to obtain multiple decision boundaries. Then use an auxiliary loss function called Boundary-Calibration loss (BC-loss) to calibrate the generating distribution according to the decision boundaries of these pre-trained classifiers. The main contributions of this work are:</p><p>&#8226; In Section 2, we propose a way to evaluate model compatibility in classification problems. We consider a variety of machine learning algorithms and average the performance to ob- tain a comprehensive metric.</p><p>&#8226; In Section 4, we propose a loss function called Boundary-Calibration loss (BC-loss) which helps typical GANs to learn a distribution with better model compatibility. The loss con- siders the decision boundaries of pre-trained classifiers and minimizes the maximum mean discrepancy (<xref ref-type="bibr" rid="b15">MMD, Gretton et al. 2012</xref>) between the original dataset and the generated dataset. In addition, we show that optimizing the BC-loss would not change the optimal solution of the original GAN, but it reduces the feasible set to ensure the model compati- bility.</p><p>&#8226; In Section 5, we demonstrate how BC-loss affects the boundary of the generated data with a two-dimensional toy dataset. We also show that the BC-loss improves model compatibility of the generated data with different types of classifiers and a variety of datasets. Finally, we inspect the feature selection results to examine how the interpretation of machine learning models may be effected.</p><p>Last, in Section 3, we discuss some works which are similar to our work and describe how does our work differ from them.</p></sec><sec><title>MODEL COMPATIBILITY IN CLASSIFICATION</title><p>In this work, we focus on generating data for fully-supervised classification learning. Given a dataset D = {(x i , y i )} n i=1 , where x i &#8712; X represents features of an instance, y i = f (x i ) &#8712; Y represents the corresponding label of x i according f : X &#8594; Y, and (x i , y i ) &#8764; P D , a learning algorithm A : (X , Y) n &#8594; H learns a hypothesis h &#8712; H to approximate the mapping function, i.e. A(D) = h &#8776; f . Our goal is to obtain a generator G which generates a synthetic dataset D = {(x j , y j )} m j=1 such that A(D ) = h &#8776; h. We call this property model compatibility as proposed in <xref ref-type="bibr" rid="b21">Park et al. (2018)</xref>.</p><p>To measure the model compatibility of a generated dataset quantitatively, we consider the perfor- mance of a classifier trained on the generated dataset comparing to the one trained on the real dataset. We evaluate the accuracy on a separate test dataset to indicate the performance of a given classifier. In addition, we calculate relative accuracy by scaling the test accuracy of the classifier trained on the generated dataset by the accuracy of the classifier trained on the real dataset. The relative accuracy allows us to average the results from different machine learning algorithms more fairly. The final evaluation is :</p><p>Under review as a conference paper at ICLR 2020 where A is a set of learning algorithms , D (t) = {(x (t) i , y (t) i )} N i=1 is the test dataset, and acc(h, D (t) ) is the accuracy of hypothesis h on test data D (t) . We can determine A as a wide variety of learning algorithms to make the metric provide a more comprehensive measurement of model compatibility.</p></sec><sec><title>RELATED WORK</title><p>Research about generating data for classification can be divided into two categories: formulation and architecture. For formulation, Conditional GAN (<xref ref-type="bibr" rid="b0">CGAN, Mirza &amp; Osindero 2014</xref> ) is an intuitive way to generate instances with corresponding labels. We can learn the distribution of labels by counting and sample the instances from CGAN conditionally. Auxiliary Classifier GAN (<xref ref-type="bibr" rid="b0">ACGAN, Odena et al. 2017</xref>) is considered as a better way for conditional generation. It uses an auxiliary classifier to provide information about the boundary between each classes. However, ACGAN has been proved that the objective is biased so it tends to generate data with lower entropy for the auxiliary classifier (<xref ref-type="bibr" rid="b26">Shu et al., 2017</xref>). Thus, the lose of instances near the decision boundary may worsen the model compatibility. In this work, we use CGAN along with the proposed BC-loss to generate data with model compatibility.</p><p>On the other hand, the other line of research focuses on generating data with different network archi- tecture or data processing procedure. Recent works that also consider model compatibility are Table GAN (<xref ref-type="bibr" rid="b21">Park et al., 2018</xref>) and Tabular GAN (<xref ref-type="bibr" rid="b4">Xu et al., 2019</xref>). Table GAN focuses on the privacy of generated data and thus their is a trade off between privacy and model compatibility. To achieve privacy preserving, they do not improve the model compatibility compared to the original GAN. On the other hand, Tabular GAN puts emphasis on increasing model compatibility of generated data. They propose a framework with a more complicated data processing procedure and use LSTM to better parameterize the target distribution. In contrast to these works, our work focus on the formu- lation of GANs and can be applied to most variants of GANs, including Table-GAN and Tabular GAN. Moreover, while these former works only focus on tabular data, our BC-loss is applicable to generate image datasets as well.</p><p>Some GAN variants are named similarly to our work but they pay attention to different problems. For example, the boundary described in boundary-seeking GAN (<xref ref-type="bibr" rid="b9">Hjelm et al., 2017</xref>) means the de- cision boundary of the discriminator rather than the decision boundary for the supervised labels. To the best of our knowledge, we are the first work trying to improve model compatibility by modifying the formulation of GANs.</p></sec><sec><title>BOUNDARY-CALIBRATION GAN</title><p>To achieve better model compatibility of GAN, we propose an auxiliary GAN loss which we call boundary-calibration loss (or BC-loss). We assume that we have a set of pre-trained classifiers which are well-trained on the original dataset. The BC-loss helps GANs to calibrate the distribution with respect to the distribution of decision values predicted by pre-trained classifiers. The calibra- tion leads to more accurate data generation near the decision boundary and thus enabling a machine learning algorithm to learn a similar hypothesis to one that learns from the original dataset. To ease the complexity of learning to generate (x, y) jointly, we infer P (y) by counting the proportion of each class in the original dataset and train a conditional generator G such that G(z, y) &#8764; P X |y , where P X |y is the conditional data distribution and z &#8764; P Z is the initial randomness such as Gaus- sian distribution. Therefore we can generate (x, y) by sampling y &#8764; P (y) and G(z, y).</p></sec><sec><title>BOUNDARY CALIBRATION</title><p>Given a pre-trained classifier C, we hope the generated dataset will adopt the same statistics as the original dataset while considering the decision boundary of C. To include the information about the boundary, we calculate posterior P C (y | x i ) from the decision values predicted by the classifier. In practice, we can apply a softmax function to the outputs of a classifier to obtain the posterior. The posterior provides information of an instance from the classifier's aspect. Therefore, given the real dataset X = {x 1 , x 2 , ..., x n }, we can obtain a set of posterior vector C(X) = (P C (y | x 1 ), P C (y | x 2 ), ..., P C (y | x n )). To generate data X with the same distribution of posteriors to the boundary, Under review as a conference paper at ICLR 2020 we match the statistics of C(X) and C(X ) by optimizing a distance M :</p><p>Here M can be any distance metric which measures the distance between two sets of samples. In statistics, distinguishing whether two sets of samples are from the same distribution is called Two- Sample Test. A classical solution to two-sample test is kernel maximum mean discrepancy (MMD, <xref ref-type="bibr" rid="b5">Gretton et al. 2012</xref>). The idea is to compare the statistics between the two sets of samples. If the statistics are similar then these two sets might be sampled from the same distribution. Given two sets of samples X = {x i } n i=1 and Y = {y j } n j=1 , an unbiased estimator of MMD with kernel k is defined as:M</p><p>In practice, we use Gaussian kernel k(x, x ) = exp( x &#8722; x 2 ) in MMD since Gaussian kernel is a characteristic kernel which ensures that the distance is zero if and only if the two distributions are the same (<xref ref-type="bibr" rid="b5">Gretton et al., 2012</xref>).</p><p>The BC-loss can be applied in generator of any GAN variants to improve the model compatibility. In addition, to better fit the real unknown boundary, we can use multiple classifiers to calibrate the distributions from different aspects. As a result, for a loss function of generator L G , we can modify the loss to be:L G = L G + &#955; |C| C&#8712;CM k (C(X), C(G(Z, Y))) (4) where Z is a set of noises, C is a set of pre-trained classifiers and &#955; is a hyper-parameter to control the weight of BC-loss.</p></sec><sec><title>ANALYSIS OF OPTIMAL SOLUTION</title><p>Next we prove that adding our proposed BC-loss would not change the optimal solution of the original objective. Here we assume the loss of the generator L G achieves its optimal value in the its GAN objectives L G if and only if the distribution of G(z, y) recovers P X |y for all y &#8712; Y, which holds for the vanilla GAN (<xref ref-type="bibr" rid="b4">Goodfellow et al., 2014</xref>) and most of other GAN variants. Theorem 1 (<xref ref-type="bibr" rid="b5">Gretton et al. 2012</xref>). Given a kernel k, if k is a characteristic kernel, then M k (P, Q) = 0 &#8656;&#8658; P = Q. Theorem 2 (Equivalence of optimal solution). G is an optimal solution of L G &#8656;&#8658; G is an optimal solution ofL G Proof. (&#8658;) According to the assumption, G is an optimal solution of L G implies G(Z, y) recovers P X |y for all y &#8712; Y. Therefore, P C(X) = P C(G(Z,Y)) and M k (P C(X) , P C(G(Z,Y)) ) = 0 by Theo- rem 1. NowL G = L G + 0 = L G and G is an optimal solution of L G , so G is also an optimal solution ofL G .</p><p>(&#8656;) Since L BC &#8805; 0, we haveL G = L G + L BC &#8805; L G . From above, we knowL G (G) = 0 if G = P X . Thus, for an optimal solution G * , 0 &#8805;L G (G * ) &#8805; L G (G * ) &#8805; 0, which implie&#349; L G (G * ) = L G (G * ) = 0. Therefore, G * is also an optimal solution of L G .</p><p>The proof shows that the proposed BC-loss does not change the optimal solution of the original optimization problem. However, we can consider BC-loss as a Lagrangian constraint which restricts the solution to a subspace where the generator owns higher model compatibility .</p></sec><sec><title>COMPARISON TO MMD GAN</title><p>MMD GAN (<xref ref-type="bibr" rid="b1">Li et al., 2017</xref>) is a variant of GAN where the generator tries to minimize the MMD between generated data and original data and the discriminator learns a kernel which maximizes the MMD. Though the formulation of MMD GAN and BC-loss are similar, they still do not con- flict because MMD GAN do not known the information about the classifier and the objective of Under review as a conference paper at ICLR 2020 MMD GAN would not lead the discriminator to a classifier. Therefore, BC-loss may still improve MMD GAN by guiding the generator to not generate points across the boundary. To understand the improvement in MMD GAN from BC-loss, we use MMD GAN as one of the baselines in our experiments.</p></sec><sec><title>EXPERIMENTS</title><p>In this section, we use a toy dataset to illustrate how the proposed method improves the model compatibility. To be more realistic, we provide more comprehensive results for four different real- world dataset from UCI dataset repository (<xref ref-type="bibr" rid="b3">Dua &amp; Graff, 2017</xref>): Adult, Connect-4, Covertype and Sensorless. We then show our method is also applicable in image dataset: MNIST and Cifar10 without losing the image quality. In addition, we investigate the results of feature selections on the generated dataset to see whether the generated data can preserve the interpretation of machine learning models.</p></sec><sec><title>EXPERIMENTAL SETTINGS</title></sec><sec><title>EVALUATION</title><p>In this work, we focus on model compatibility of generated datasets. We use a wide variety of machine learning algorithms including linear SVM, decision tree (DT), random forest (RF), and multi-layer perception (MLP) to evaluate the model compatibility. As described in Section 2, we evaluate the relative accuracy for each type of machine learning model, where the relative accuracy is calculated by dividing the accuracy of classifier trained on generated data to the accuracy of classifier trained on original data.</p></sec><sec><title>COMPARED METHODS</title><p>We take Wasserstein GAN (WGAN) and MMD GAN as our baselines to evaluate the effective- ness of the proposed boundary-calibration technique. We denotes their counterparts with BC-loss as BWGAN and BMMDGAN respectively. All of the methods use gradient penalty to enforce the Lipschitz constraint on the discriminator (<xref ref-type="bibr" rid="b6">Gulrajani et al., 2017</xref>; <xref ref-type="bibr" rid="b1">Li et al., 2017</xref>). To achieve condi- tional data generation as described in Section 4, we add an embedding layer to learn the embedding vector for each class. The embedding vector is concatenated as additional input features for both generators and discriminators on UCI datasets. For image datasets, the embedding vectors are used as described in <xref ref-type="bibr" rid="b4">Mirza &amp; Osindero (2014)</xref>.</p></sec><sec><title>2D TOY DATASET</title><p>We use a 2D toy dataset with two classes to illustrate the results generated by different GAN methods in <xref ref-type="fig" rid="fig_0">Figure 1</xref>. Figure 2a shows the distribution of the original training data. We use these generated data to train a random forest and depict the decision boundary by different background color. From Figure 2b, we can see that although ACGAN can make use of the auxiliary classifier during training, Under review as a conference paper at ICLR 2020 it learns a biased distribution that push the generated data away from the boundary. The large margin between the two clusters brings more uncertainty to the decision boundary and thus leads to worse test accuracy. In Figure 2c, WGAN approximates the original distribution well in the center part of the two cluster, but do not get a clear boundary between the two classes. It generates some ambiguous points near the boundary that would confuse the classifier. Finally, our BWGAN generates points near the boundary more precisely, as shown in Figure 2c.</p></sec><sec><title>UCI DATASET</title><p>We evaluate our proposed BC-GAN on four datasets from UCI repository. The attributes of the datasets can be found in Appendix A. Discrete features are processed to one-hot encoding and con- tinuous features are scaled to [0, 1]. For each dataset, we train six multi-layer perceptrons with a random split of half of training data as pre-trained classifiers. In these experiments, generators and discriminators are consist of 3 fully-connected hidden layer with 128 units. A logistic function is applied to the output layer of generators to generate features within 0 and 1. The weight of BC-loss is set to be &#955; = 100 for all datasets. <xref ref-type="table" rid="tab_0">Table 1</xref> summarize the comparison between different methods. We calculate the relative accuracy of different machine learning models mentioned in Section 5.1 and average the relative accuracy to indicate the model compatibility of generated data for each dataset. The table shows that the proposed BC-loss improves the accuracy of classifiers generally compared to original WGAN and MMD GAN. Moreover, ACGAN performs worst on three out of four datasets and exhibit a signifi- cant deficiency though it is proved to have the state-of-the-art generation quality. This again prove that the biased objective of ACGAN worsen the model compatibility seriously.The breakdown re- sults and real accuracy are provided in Appendix B.</p><p>To further investigate the advantage of boundary-calibration, we visualize the generated results of Sensorless in <xref ref-type="fig" rid="fig_1">Figure 2</xref>. We train a fully-connected neural network with a 2-units hidden layer before the output layer to project the generated samples to a 2-dimensional embedding space. The projec- tion classifier is well-trained and achieves over 99% testing accuracy so we can use it to determine whether a sample is generated with incorrect label. The figure shows that there are less mislabeled data generated by BWGAN, especially at the center and the bottom-left region. The fact indicates that boundary-calibration helps GANs generate labeled data more accurately, which may lead to the improvement of classification accuracy.</p></sec><sec><title>INTERPRETABILITY</title><p>In addition to accuracy, it is also important that the model trained on generated data should give us the same interpretation of a model trained on the original data. We investigate the interpretability by two common feature selection techniques. First, we train two random forests on the generated and original dataset respectively. Each random forest can provide the importances of the features. We evaluate the consistency of interpretation by calculating precision at Kth, which means how many features ranked top-k in random forest trained on original data are in the top-k importance feature of the random forest trained on generated data. The results are shown in <xref ref-type="table" rid="tab_1">Table 2</xref>. We provide the results of training a classifier on the same original data with a different random seed as REAL for comparison. The effect of BC-loss is not significant in this aspect. However, the scores of ACGAN drop seriously, which means training a classifier on data generated by ACGAN is somehow dangerous because the meaning of model may be totally different.</p><p>Another way to select feature is training a linear model with 1 regularization. In <xref ref-type="table" rid="tab_2">Table 3</xref> we use linear SVM with 1 regularization to select features. Then we calculate the F1 score of features selected by classifiers trained on generated data to known how similar between the two sets of features selected by classifiers trained on original and generated dataset. The results again shows that using boundary-calibration does not has significant effect to feature selection and ACGAN is not proper to generated data for training.</p></sec><sec><title>IMAGE DATASET</title><p>We further use MNIST and CIFAR-10 dataset to investigate the effectiveness of boundary- calibration on image datasets. For MNIST, we train six 4-layer convolution neural networks (CNN) with random sampling half of training data as pre-trained classifiers, and use the same classifier set in Section 5.1 to evaluate model compatibility. For CIFAR-10, we use ResNet56v2 (<xref ref-type="bibr" rid="b7">He et al., 2016</xref>) to obtain three pre-trained classifier and evaluate on CNN and ResNet56v2. In both task, we use DCGAN (<xref ref-type="bibr" rid="b24">Radford et al., 2016</xref>) as network structure in all GANs. The weight of BC-loss is set to be &#955; = 1 for these two datasets. <xref ref-type="table" rid="tab_3">Table 4</xref> and <xref ref-type="table" rid="tab_4">Table 5</xref> show the relative accuracy of classifiers trained on generated data. The pro- posed BWGAN still outperforms WGAN with better accuracy in general. The results generated by WGAN and BWGAN are pictured in <xref ref-type="fig" rid="fig_2">Figure 3</xref>. The Inception score and Frechet Inception Distance (FID) for CIFAR-10 are also provided in the caption of <xref ref-type="fig" rid="fig_2">Figure 3</xref>. Though the difference of quality between the images generated from WGAN and BWGAN is not significant in visual, the quantita- tive scores for quality of generated samples of CIFAR-10 are slightly improved. The results indicate that even though our method seems not improve the image quality, it is still able to improve the model compatibility without losing image quality.</p></sec><sec><title>DISCUSSION</title><p>We introduce an auxiliary loss in GANs which improves the model compatibility of generated dataset. We prove the new loss is unbiased and is applicable to all variants of GAN to improve model compatibility. We further demonstrate that our method has clear advantages with a variety of machine learning models trained on generated dataset. In addition, we investigate the results of feature selection and found that the BC-loss doesn't effect the interpretation of machine learn- ing models. While this work only focus on classification problem, generating data for regression problem is also worth studying. We hope our work will open the path for GANs with better model compatibility so that synthetic data can be more useful in practice.</p><p>Under review as a conference paper at ICLR 2020</p></sec><sec id="figures"><title>Figures</title><fig id="fig_0"><object-id>fig_0</object-id><label>Figure 1:</label><caption><title>Figure 1:</title><p>A toy dataset generated by different GAN methods. Figure (a) is the original training data and the others are data generated by ACGAN, WGAN and our BWGAN respectively. The background color indicates the decision boundary of a random forest trained on corresponding data. The captions show the test accuracy of the random forest.</p></caption><graphic /><graphic /><graphic /><graphic /><graphic /><graphic /><graphic /><graphic /></fig><table-wrap id="tab_0"><label>Table 1:</label><caption><title>Table 1:</title><p>Summary result of model compatibility evaluate on UCI datasets. The numbers are relative accuracy.</p></caption><table><tbody><tr><td /></tr></tbody></table></table-wrap><fig id="fig_1"><object-id>fig_1</object-id><label>Figure 2:</label><caption><title>Figure 2:</title><p>2D visualization of real and generated Sensorless dataset. The mislabeled points are emphasized with border lines. The background color indicates the spaces of each class according to the projection classifier.</p></caption><graphic /><graphic /><graphic /><graphic /><graphic /><graphic /><graphic /><graphic /></fig><table-wrap id="tab_1"><label>Table 2:</label><caption><title>Table 2:</title><p>Precision at K of feature importance ranking compared to the feature importance ranking obtained from the original dataset</p></caption><table><tbody><tr><td /></tr></tbody></table></table-wrap><table-wrap id="tab_2"><label>Table 3:</label><caption><title>Table 3:</title><p>F1 score of feature selection by 1 -regularized linear SVM</p></caption><table><tbody><tr><td /></tr></tbody></table></table-wrap><fig id="fig_2"><object-id>fig_2</object-id><label>Figure 3:</label><caption><title>Figure 3:</title><p>Gnerated samples from WGAN and our BWGAN. The images in the same column are in the same category.</p></caption><graphic /><graphic /><graphic /><graphic /><graphic /><graphic /><graphic /><graphic /></fig><table-wrap id="tab_3"><label>Table 4:</label><caption><title>Table 4:</title><p>Breakdown results on MNIST dataset.</p></caption><table><tbody><tr><td /></tr></tbody></table></table-wrap><table-wrap id="tab_4"><label>Table 5:</label><caption><title>Table 5:</title><p>Breakdown results on CIFAR- 10 dataset.</p></caption><table><tbody><tr><td /></tr></tbody></table></table-wrap></sec></body><back><ref-list id="ref-list-1"><ref id="b0"><element-citation publication-type="journal"><article-title>Wasserstein GAN</article-title><source>CoRR</source><year>2017</year><person-group person-group-type="author"><name><surname>References Mart&#237;n Arjovsky</surname><given-names>Soumith</given-names></name><name><surname>Chintala</surname><given-names>L&#233;on</given-names></name><name><surname>Bottou</surname><given-names /></name></person-group></element-citation></ref><ref id="b1"><element-citation publication-type="journal"><article-title>One network to solve them all-solving linear inverse problems using deep projection models</article-title><source>Proceedings of the IEEE International Conference on Computer Vision</source><year>2017</year><fpage>5888</fpage><lpage>5897</lpage><person-group person-group-type="author"><name><surname>Rick</surname><given-names>J H</given-names></name><name><surname>Chang</surname><given-names>Chun-Liang</given-names></name><name><surname>Li</surname><given-names>Barnabas</given-names></name><name><surname>Poczos</surname><given-names /></name><name><surname>Bvk Vijaya Kumar</surname><given-names>Aswin</given-names></name><name><surname>Sankara- Narayanan</surname><given-names /></name></person-group></element-citation></ref><ref id="b2"><element-citation publication-type="journal"><article-title>Kernel change-point de- tection with auxiliary deep generative models</article-title><source>arXiv preprint arXiv:1901.06077</source><year>2019</year><person-group person-group-type="author"><name><surname>Chang</surname><given-names>Wei-Cheng</given-names></name><name><surname>Li</surname><given-names>Chun-Liang</given-names></name><name><surname>Yang</surname><given-names>Yiming</given-names></name><name><surname>P&#243;czos</surname><given-names>Barnab&#225;s</given-names></name></person-group></element-citation></ref><ref id="b3"><element-citation publication-type="journal"><source>UCI machine learning repository</source><year>2017</year><person-group person-group-type="author"><name><surname>Dua</surname><given-names>Dheeru</given-names></name><name><surname>Graff</surname><given-names>Casey</given-names></name></person-group></element-citation></ref><ref id="b4"><element-citation publication-type="journal"><article-title>Generative adversarial nets</article-title><source>Advances in Neural Information Processing Systems</source><year>2014</year><person-group person-group-type="author"><name><surname>Goodfellow</surname><given-names>Ian J</given-names></name><name><surname>Pouget-Abadie</surname><given-names>Jean</given-names></name><name><surname>Mirza</surname><given-names>Mehdi</given-names></name><name><surname>Xu</surname><given-names>Bing</given-names></name><name><surname>Warde-Farley</surname><given-names>David</given-names></name><name><surname>Ozair</surname><given-names>Sherjil</given-names></name><name><surname>Courville</surname><given-names>Aaron C</given-names></name><name><surname>Bengio</surname><given-names>Yoshua</given-names></name></person-group></element-citation></ref><ref id="b5"><element-citation publication-type="journal"><article-title>A kernel two-sample test</article-title><source>J. Mach. Learn. Res.</source><year>2012</year><person-group person-group-type="author"><name><surname>Gretton</surname><given-names>Arthur</given-names></name><name><surname>Borgwardt</surname><given-names>Karsten M</given-names></name><name><surname>Rasch</surname><given-names>Malte J</given-names></name><name><surname>Sch&#246;lkopf</surname><given-names>Bernhard</given-names></name><name><surname>Smola</surname><given-names>Alexander J</given-names></name></person-group></element-citation></ref><ref id="b6"><element-citation publication-type="journal"><article-title>Im- proved training of wasserstein gans</article-title><source>Advances in Neural Information Processing Systems</source><year>2017</year><person-group person-group-type="author"><name><surname>Gulrajani</surname><given-names>Ishaan</given-names></name><name><surname>Ahmed</surname><given-names>Faruk</given-names></name><name><surname>Arjovsky</surname><given-names>Mart&#237;n</given-names></name><name><surname>Dumoulin</surname><given-names>Vincent</given-names></name><name><surname>Courville</surname><given-names>Aaron C</given-names></name></person-group></element-citation></ref><ref id="b7"><element-citation publication-type="journal"><source>Computer Vision - ECCV 2016 - 14th European Conference, Amsterdam, The Nether- lands, October 11-14, 2016, Proceedings, Part IV</source><person-group person-group-type="author"><name><surname>He</surname><given-names>Kaiming</given-names></name><name><surname>Zhang</surname><given-names>Xiangyu</given-names></name><name><surname>Ren</surname><given-names>Shaoqing</given-names></name><name><surname>Sun</surname><given-names>Jian</given-names></name></person-group></element-citation></ref><ref id="b8"><element-citation publication-type="journal"><article-title>Gans trained by a two time-scale update rule converge to a local nash equilibrium</article-title><source>Advances in Neural Information Processing Systems</source><year>2017</year><fpage>6626</fpage><lpage>6637</lpage><person-group person-group-type="author"><name><surname>Heusel</surname><given-names>Martin</given-names></name><name><surname>Ramsauer</surname><given-names>Hubert</given-names></name><name><surname>Unterthiner</surname><given-names>Thomas</given-names></name><name><surname>Nessler</surname><given-names>Bernhard</given-names></name><name><surname>Hochreiter</surname><given-names>Sepp</given-names></name></person-group></element-citation></ref><ref id="b9"><element-citation publication-type="journal"><article-title>Boundary-seeking generative adversarial networks</article-title><source>arXiv preprint arXiv:1702.08431</source><year>2017</year><person-group person-group-type="author"><name><surname>R Devon Hjelm</surname><given-names>Paul</given-names></name><name><surname>Jacob</surname><given-names>Tong</given-names></name><name><surname>Che</surname><given-names>Adam</given-names></name><name><surname>Trischler</surname><given-names>Kyunghyun</given-names></name><name><surname>Cho</surname><given-names>Yoshua</given-names></name><name><surname>Bengio</surname><given-names /></name></person-group></element-citation></ref><ref id="b10"><element-citation publication-type="journal"><article-title>Image-to-image translation with conditional adversarial networks</article-title><source>IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017</source><year>2017</year><fpage>5967</fpage><lpage>5976</lpage><person-group person-group-type="author"><name><surname>Isola</surname><given-names>Phillip</given-names></name><name><surname>Zhu</surname><given-names>Jun-Yan</given-names></name><name><surname>Zhou</surname><given-names>Tinghui</given-names></name><name><surname>Efros</surname><given-names>Alexei A</given-names></name></person-group></element-citation></ref><ref id="b11"><element-citation publication-type="journal"><article-title>Progressive growing of gans for im- proved quality, stability, and variation</article-title><source>In 6th International Conference on Learning Representa- tions, ICLR</source><year>2018</year><volume>2018</volume><person-group person-group-type="author"><name><surname>Karras</surname><given-names>Tero</given-names></name><name><surname>Aila</surname><given-names>Timo</given-names></name><name><surname>Laine</surname><given-names>Samuli</given-names></name><name><surname>Lehtinen</surname><given-names>Jaakko</given-names></name></person-group></element-citation></ref><ref id="b12"><element-citation publication-type="journal"><article-title>Learning to discover cross-domain relations with generative adversarial networks</article-title><source>Proceedings of the 34th Interna- tional Conference on Machine Learning, ICML</source><year>2017</year><volume>2017</volume><person-group person-group-type="author"><name><surname>Kim</surname><given-names>Taeksoo</given-names></name><name><surname>Cha</surname><given-names>Moonsu</given-names></name><name><surname>Kim</surname><given-names>Hyunsoo</given-names></name><name><surname>Lee</surname><given-names>Jung Kwon</given-names></name><name><surname>Kim</surname><given-names>Jiwon</given-names></name></person-group></element-citation></ref><ref id="b13"><element-citation publication-type="journal"><article-title>Auto-encoding variational bayes</article-title><source>arXiv preprint arXiv:1312.6114</source><year>2013</year><person-group person-group-type="author"><name><surname>Diederik</surname><given-names>P</given-names></name><name><surname>Kingma</surname><given-names>Max</given-names></name><name><surname>Welling</surname><given-names /></name></person-group></element-citation></ref><ref id="b14"><element-citation publication-type="journal"><article-title>Photo-realistic sin- gle image super-resolution using a generative adversarial network</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2017</year><fpage>4681</fpage><lpage>4690</lpage><person-group person-group-type="author"><name><surname>Ledig</surname><given-names>Christian</given-names></name><name><surname>Theis</surname><given-names>Lucas</given-names></name><name><surname>Husz&#225;r</surname><given-names>Ferenc</given-names></name><name><surname>Caballero</surname><given-names>Jose</given-names></name><name><surname>Cunningham</surname><given-names>Andrew</given-names></name><name><surname>Acosta</surname><given-names>Alejandro</given-names></name><name><surname>Aitken</surname><given-names>Andrew</given-names></name><name><surname>Tejani</surname><given-names>Alykhan</given-names></name><name><surname>Totz</surname><given-names>Johannes</given-names></name><name><surname>Wang</surname><given-names>Zehan</given-names></name></person-group></element-citation></ref><ref id="b15"><element-citation publication-type="journal"><article-title>MMD GAN: towards deeper understanding of moment matching network</article-title><source>Advances in Neural Information Processing Systems</source><year>2017</year><person-group person-group-type="author"><name><surname>Li</surname><given-names>Chun-Liang</given-names></name><name><surname>Chang</surname><given-names>Wei-Cheng</given-names></name><name><surname>Cheng</surname><given-names>Yu</given-names></name><name><surname>Yang</surname><given-names>Yiming</given-names></name><name><surname>P&#243;czos</surname><given-names>Barnab&#225;s</given-names></name></person-group></element-citation></ref><ref id="b16"><element-citation publication-type="journal"><article-title>Point cloud gan. arXiv preprint arXiv:1810.05795, 2018. Under review as a conference paper at ICLR 2020 Mario Lucic, Karol Kurach, Marcin Michalski, Sylvain Gelly, and Olivier Bousquet. Are gans created equal? a large-scale study</article-title><source>Advances in neural information processing systems</source><year>2018</year><fpage>700</fpage><lpage>709</lpage><person-group person-group-type="author"><name><surname>Li</surname><given-names>Chun-Liang</given-names></name><name><surname>Zaheer</surname><given-names>Manzil</given-names></name><name><surname>Zhang</surname><given-names>Yang</given-names></name><name><surname>Poczos</surname><given-names>Barnabas</given-names></name><name><surname>Salakhutdinov</surname><given-names>Ruslan</given-names></name></person-group></element-citation></ref><ref id="b17"><element-citation publication-type="journal"><article-title>Multivariate time series imputation with generative adversarial networks</article-title><source>Advances in Neural Information Processing Systems</source><year>2018</year><fpage>1596</fpage><lpage>1607</lpage><person-group person-group-type="author"><name><surname>Luo</surname><given-names>Yonghong</given-names></name><name><surname>Cai</surname><given-names>Xiangrui</given-names></name><name><surname>Zhang</surname><given-names>Ying</given-names></name><name><surname>Xu</surname><given-names>Jun</given-names></name></person-group></element-citation></ref><ref id="b18"><element-citation publication-type="journal"><article-title>Conditional generative adversarial nets</article-title><source>arXiv preprint arXiv:1411.1784</source><year>2014</year><person-group person-group-type="author"><name><surname>Mirza</surname><given-names>Mehdi</given-names></name><name><surname>Osindero</surname><given-names>Simon</given-names></name></person-group></element-citation></ref><ref id="b19"><element-citation publication-type="journal"><article-title>f-gan: Training generative neural samplers using variational divergence minimization</article-title><source>Advances in neural information processing systems</source><year>2016</year><fpage>271</fpage><lpage>279</lpage><person-group person-group-type="author"><name><surname>Nowozin</surname><given-names>Sebastian</given-names></name><name><surname>Cseke</surname><given-names>Botond</given-names></name><name><surname>Tomioka</surname><given-names>Ryota</given-names></name></person-group></element-citation></ref><ref id="b20"><element-citation publication-type="journal"><article-title>Conditional image synthesis with auxil- iary classifier gans</article-title><source>Proceedings of the 34th International Conference on Machine Learning, ICML</source><year>2017</year><fpage>2642</fpage><lpage>2651</lpage><person-group person-group-type="author"><name><surname>Odena</surname><given-names>Augustus</given-names></name><name><surname>Olah</surname><given-names>Christopher</given-names></name><name><surname>Shlens</surname><given-names>Jonathon</given-names></name></person-group></element-citation></ref><ref id="b21"><element-citation publication-type="journal"><article-title>Data synthesis based on generative adversarial networks</article-title><source>PVLDB</source><year>2018</year><person-group person-group-type="author"><name><surname>Park</surname><given-names>Noseong</given-names></name><name><surname>Mohammadi</surname><given-names>Mahmoud</given-names></name><name><surname>Gorde</surname><given-names>Kshitij</given-names></name><name><surname>Jajodia</surname><given-names>Sushil</given-names></name><name><surname>Park</surname><given-names>Hongkyu</given-names></name><name><surname>Kim</surname><given-names>Youngmin</given-names></name></person-group></element-citation></ref><ref id="b22"><element-citation publication-type="journal"><article-title>Context encoders: Feature learning by inpainting</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2016</year><fpage>2536</fpage><lpage>2544</lpage><person-group person-group-type="author"><name><surname>Pathak</surname><given-names>Deepak</given-names></name><name><surname>Krahenbuhl</surname><given-names>Philipp</given-names></name><name><surname>Donahue</surname><given-names>Jeff</given-names></name><name><surname>Darrell</surname><given-names>Trevor</given-names></name><name><surname>Efros</surname><given-names>Alexei A</given-names></name></person-group></element-citation></ref><ref id="b23"><element-citation publication-type="journal"><article-title>Language generation with re- current generative adversarial networks without pre-training</article-title><source>arXiv preprint arXiv:1706.01399</source><year>2017</year><person-group person-group-type="author"><name><surname>Press</surname><given-names>Ofir</given-names></name><name><surname>Bar</surname><given-names>Amir</given-names></name><name><surname>Bogin</surname><given-names>Ben</given-names></name><name><surname>Berant</surname><given-names>Jonathan</given-names></name><name><surname>Wolf</surname><given-names>Lior</given-names></name></person-group></element-citation></ref><ref id="b24"><element-citation publication-type="journal"><article-title>Unsupervised representation learning with deep convolutional generative adversarial networks</article-title><source>In 4th International Conference on Learning Rep- resentations, ICLR</source><year>2016</year><volume>2016</volume><person-group person-group-type="author"><name><surname>Radford</surname><given-names>Alec</given-names></name><name><surname>Metz</surname><given-names>Luke</given-names></name><name><surname>Chintala</surname><given-names>Soumith</given-names></name></person-group></element-citation></ref><ref id="b25"><element-citation publication-type="journal"><article-title>Improved techniques for training gans</article-title><source>Advances in Neural Information Processing Systems</source><year>2016</year><person-group person-group-type="author"><name><surname>Salimans</surname><given-names>Tim</given-names></name><name><surname>Goodfellow</surname><given-names>Ian J</given-names></name><name><surname>Zaremba</surname><given-names>Wojciech</given-names></name><name><surname>Cheung</surname><given-names>Vicki</given-names></name><name><surname>Radford</surname><given-names>Alec</given-names></name><name><surname>Chen</surname><given-names>Xi</given-names></name></person-group></element-citation></ref><ref id="b26"><element-citation publication-type="journal"><article-title>Ac-gan learns a biased distribution</article-title><source>NIPS Workshop on Bayesian Deep Learning</source><year>2017</year><person-group person-group-type="author"><name><surname>Shu</surname><given-names>Rui</given-names></name><name><surname>Bui</surname><given-names>Hung</given-names></name></person-group></element-citation></ref><ref id="b27"><element-citation publication-type="journal"><article-title>Learning a prob- abilistic latent space of object shapes via 3d generative-adversarial modeling</article-title><source>Advances in neural information processing systems</source><year>2016</year><fpage>82</fpage><lpage>90</lpage><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Jiajun</given-names></name><name><surname>Zhang</surname><given-names>Chengkai</given-names></name><name><surname>Xue</surname><given-names>Tianfan</given-names></name><name><surname>Freeman</surname><given-names>Bill</given-names></name><name><surname>Tenenbaum</surname><given-names>Josh</given-names></name></person-group></element-citation></ref><ref id="b28"><element-citation publication-type="journal"><article-title>Modeling tabular data using conditional gan</article-title><source>arXiv preprint arXiv:1907.00503</source><year>2019</year><person-group person-group-type="author"><name><surname>Xu</surname><given-names>Lei</given-names></name><name><surname>Skoularidou</surname><given-names>Maria</given-names></name><name><surname>Cuesta-Infante</surname><given-names>Alfredo</given-names></name><name><surname>Veeramachaneni</surname><given-names>Kalyan</given-names></name></person-group></element-citation></ref><ref id="b29"><element-citation publication-type="journal"><article-title>Seqgan: Sequence generative adversarial nets with policy gradient</article-title><source>Proceedings of the Thirty-First AAAI Conference on Artificial Intelli- gence</source><year>2017</year><person-group person-group-type="author"><name><surname>Yu</surname><given-names>Lantao</given-names></name><name><surname>Zhang</surname><given-names>Weinan</given-names></name><name><surname>Wang</surname><given-names>Jun</given-names></name><name><surname>Yu</surname><given-names>Yong</given-names></name></person-group></element-citation></ref><ref id="b30"><element-citation publication-type="journal"><article-title>Unpaired image-to-image translation using cycle-consistent adversarial networks</article-title><source>IEEE International Conference on Computer Vision, ICCV</source><year>2017</year><volume>2017</volume><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>Jun-Yan</given-names></name><name><surname>Park</surname><given-names>Taesung</given-names></name><name><surname>Isola</surname><given-names>Phillip</given-names></name><name><surname>Efros</surname><given-names>Alexei A</given-names></name></person-group></element-citation></ref></ref-list></back></article>