Title:
```
Published as a conference paper at ICLR 2020 PROGRESSIVE LEARNING AND DISENTANGLEMENT OF HIERARCHICAL REPRESENTATIONS
```
Abstract:
```
Learning rich representation from data is an important task for deep generative models such as variational auto-encoder (VAE). However, by extracting high-level abstractions in the bottom-up inference process, the goal of preserving all factors of variations for top-down generation is compromised. Motivated by the concept of "starting small", we present a strategy to progressively learn independent hi- erarchical representations from high- to low-levels of abstractions. The model starts with learning the most abstract representation, and then progressively grow the network architecture to introduce new representations at different levels of abstraction. We quantitatively demonstrate the ability of the presented model to improve disentanglement in comparison to existing works on two benchmark data sets using three disentanglement metrics, including a new metric we proposed to complement the previously-presented metric of mutual information gap. We fur- ther present both qualitative and quantitative evidence on how the progression of learning improves disentangling of hierarchical representations. By drawing on the respective advantage of hierarchical representation learning and progressive learning, this is to our knowledge the first attempt to improve disentanglement by progressively growing the capacity of VAE to learn hierarchical representations 1 .
```

Figures/Tables Captions:
```
Figure 1: Progressive learning of hierarchical representations. White blocks and solid lines are VAE models at the current progression. α is a fade-in coefficient for blending in the new network com- ponent. Gray circles and dash line represents (optional) constraining of the future latent variables.
Figure 2: Quantitative comparison of disentanglement metrics. Each point is annotated by the β value and averaged over top three best random seeds for the given β on the give model. Left to right: reconstruction errors vs. disentanglement metrics of factor, MIG, and MIG-sup, a higher value indicating a better disentanglement in each metric.
Figure 3: MIG vs. MIG-sup following a similar presentation in Fig. 2. A better disentanglement should have higher MIG and higher MIG-sup, locating at the top-right quadrant of the plot.
Figure 4: Traversing each latent dimension in pro-VLAE (β = 8), VLAE (β = 10), and teacher- student model. The hierarchy of the latent variables is noted by brackets on the side.
Figure 5: Progressive learning of hierarchical representations. At each progression and for each z l , the row of images are generated by randomly sampling from its prior distributions while fixing the other latent variables (this is NOT traversing). The green bar at each row tracks the mutual information I(x; z l ), while the total mutual information I(x; z) is labeled on top.
Figure 6: Visualization of hierarchical features learnt for MNIST data. Each sub-figure is generated by randomly sampling from the prior distribution of z l at one abstraction level while fixing the others. The original latent code is inferred from a image with digit "0". From left to right: z 3 encodes the highest abstraction: digit identity; z 2 encodes stroke width; and z 1 encodes other digit styles.
Figure 7: Visualization of hierarchical features learnt for CelebA data. Each subfigure is generated by traversing along a selected latent dimension in each row within each hierarchy of z l 's. From left to right: latent variables z 4 to z 1 progressively learn major (e.g., gender in z 4 and smile in z 3 ) to minor representations (e.g. wavy-hair in z 2 and eye-shadow in z 1 ) in a disentangled manner.
```

Main Content:
```

Section Title: INTRODUCTION
  INTRODUCTION Variational auto-encoder (VAE), a popular deep generative model (DGM), has shown great promise in learning interpretable and semantically meaningful representations of data ( Higgins et al. (2017) ;  Chen et al. (2018) ;  Kim & Mnih (2018) ;  Gyawali et al. (2019) ). However, VAE has not been able to fully utilize the depth of neural networks like its supervised counterparts, for which a fundamental cause lies in the inherent conflict between the bottom-up inference and top-down generation process ( Zhao et al. (2017) ;  Li et al. (2016) ): while the bottom-up abstraction is able to extract high-level representations helpful for discriminative tasks, the goal of generation requires the preservation of all generative factors that are likely at different abstraction levels. This issue was addressed in recent works by allowing VAEs to generate from details added at different depths of the network, using either memory modules between top-down generation layers ( Li et al. (2016) ), or hierarchical latent representations extracted at different depths via a variational ladder autoencoder ( VLAE, Zhao et al. (2017) ). However, it is difficult to learn to extract and disentangle all generative factors at once, especially at different abstraction levels. Inspired by human cognition system,  Elman (1993)  suggested the im- portance of "starting small" in two aspects of the learning process of neural networks: incremental input in which a network is trained with data and tasks of increasing complexity, and incremental memory in which the network capacity undergoes developmental changes given fixed external data and tasks - both pointing to an incremental learning strategy for simplifying a complex final task. Indeed, the former concept of incremental input has underpinned the success of curriculum learning ( Bengio et al. (2015) ). In the context of DGMs, various stacked versions of generative adversarial networks (GANs) have been proposed to decompose the final task of high-resolution image gener- ation into progressive sub-tasks of generating small to large images ( Denton et al. (2015) ;  Zhang Published as a conference paper at ICLR 2020 et al. (2018) ). The latter aspect of "starting small" with incremental growth of network capacity is less explored, although recent works have demonstrated the advantage of progressively growing the depth of GANs for generating high-resolution images ( Karras et al. (2018) ; Wang et al. (2018)). These works, so far, have focused on progressive learning as a strategy to improve image generation. We are motivated to investigate the possibility to use progressive learning strategies to improve learn- ing and disentangling of hierarchical representations. At a high level, the idea of progressively or sequentially learning latent representations has been previously considered in VAE. In  Gregor et al. (2015) , the network learned to sequentially refine generated images through recurrent networks. In  Lezama (2019) , a teacher-student training strategy was used to progressively increase the number of latent dimensions in VAE to improve the generation of images while preserving the disentangling ability of the teacher model. However, these works primarily focus on progressively growing the capacity of VAE to generate, rather than to extract and disentangle hierarchical representations. In comparison, in this work, we focus on 1) progressively growing the capacity of the network to extract hierarchical representations, and 2) these hierarchical representations are extracted and used in generation from different abstraction levels. We present a simple progressive training strategy that grows the hierarchical latent representations from different depths of the inference and generation model, learning from high- to low-levels of abstractions as the capacity of the model architecture grows. Because it can be viewed as a progressive strategy to train the VLAE presented in  Zhao et al. (2017) , we term the presented model pro-VLAE. We quantitatively demonstrate the ability of pro-VLAE to improve disentanglement on two benchmark data sets using three disentanglement metrics, including a new metric we proposed to complement the metric of mutual information gap (MIG) previously presented in  Chen et al. (2018) . These quantitative studies include comprehensive comparisons to β-VAE ( Higgins et al. (2017) ), VLAE ( Zhao et al. (2017) ), and the teacher-student strategy as presented in ( Lezama (2019) ) at different values of the hyperparameter β. We further present both qualitative and quantitative evidence that pro-VLAE is able to first learn the most abstract representations and then progressively disentangle existing factors or learn new factors at lower levels of abstraction, improving disentangling of hierarhical representations in the process.

Section Title: RELATED WORKS
  RELATED WORKS A hierarchy of feature maps can be naturally formed in stacked discriminative models ( Zeiler & Fergus (2014) ). Similarly, in DGM, many works have proposed stacked-VAEs as a common way to learn a hierarchy of latent variables and thereby improve image generation ( Sønderby et al. (2016) ;  Bachman (2016) ;  Kingma et al. (2016) ). However, this stacked hierarchy is not only difficult to train as the depths increases ( Sønderby et al. (2016) ;  Bachman (2016) ), but also has an unclear benefit for learning either hierarchical or disentangled representations: as shown in  Zhao et al. (2017) , when fully optimized, it is equivalent to a model with a single layer of latent variables. Alternatively, in- stead of a hierarchy of latent variables, independent hierarchical representations at different abstrac- tion levels can be extracted and used in generation from different depths of the network ( Rezende et al. (2014) ;  Zhao et al. (2017) ). A similar idea was presented in  Li et al. (2016)  to generate lost details from memory and attention modules at different depths of the top-down generation process. The presented work aligns with existing works ( Rezende et al. (2014) ;  Zhao et al. (2017) ) in learning independent hierarchical representation from different levels of abstraction, and we look to facilitate this learning by progressively learning the representations from high- to low-levels. Progressive learning has been successful for high-quality image generation, mostly in the setting of GANs. Following the seminar work of  Elman (1993) , these progressive strategies can be loosely grouped into two categories. Mostly, in line with incremental input, several works have proposed to divide the final task of image generation into progressive tasks of generating low-resolution to high-resolution images with multi-scale supervision ( Denton et al. (2015) ;  Zhang et al. (2018) ). Alternatively, in line with incremental memory, a small number of works have demonstrated the ability to simply grow the architecture of GANs from a shallow network with limited capacity for generating low-resolution images, to a deep network capable of generating super-resolution images ( Karras et al. (2018) ; Wang et al. (2018)). This approach was also shown to be time-efficient since the early-stage small networks require less time to converge comparing to training a full network from the beginning. This latter group of works provided compelling evidence for the benefit of pro- gressively growing the capacity of a network to generate images, although its extension for growing the capacity of a network to learn hierarchical representations has not been explored.

Section Title: Published as a conference paper at ICLR 2020
  Published as a conference paper at ICLR 2020 Limited work has considered incremental learning of representations in VAE. In  Gregor et al. (2015) , recurrent networks with attention mechanisms were used to sequentially refines the details in gen- erated images. It however focused on the generation performance of VAE without considering the learned representations. In  Lezama (2019) , a teacher-student strategy was used to progressively grow the dimension of the latent representations in VAE. Its fundamental motivation was that, given a teacher model that has learned to effectively disentangle major factors of variations, progressively learning additional nuisance variables will improve generation without compromising the disentan- gling ability of the teacher - the latter accomplished via a newly-proposed Jacobian supervision. The capacity of this model to grow, thus, is by design limited to the extraction of nuisance variables. In comparison, we are interested in a more significant growth of the VAE capacity to progressively learn and improve disentangling of important factors of variations which, as we will later demon- strate, is not what the model in  Lezama (2019)  is intended for. In addition, neither of these works considered learning different levels of abstractions at different depths of the network, and the pre- sented pro-VLAE provides a simpler training strategy to achieve progressive representation learning. Learning disentangled representation is a primary motivation of our work, and an important topic in VAE. Existing works mainly tackle this by promoting the independence among the learned latent factors in VAE ( Higgins et al. (2017) ;  Kim & Mnih (2018) ;  Chen et al. (2018) ). The presented progressive learning strategy provides a novel approach to improve disentangling that is different to these existing methods and a possibility to augment them in the future.

Section Title: METHODS
  METHODS

Section Title: MODEL: VAE WITH HIERARCHICAL REPRESENTATIONS
  MODEL: VAE WITH HIERARCHICAL REPRESENTATIONS We assume a generative model p(x, z) = p(x|z)p(z) for observed x and its latent variable z. To learn hierarchical representations of x, we decompose z into {z 1 , z 2 , ..., z L } with z l (l = 1, 2, 3, ..., L) from different abstraction levels that are loosely guided by the depth of neural net- work as in  Zhao et al. (2017) . We define the hierarchical generative model p θ as: Note that there is no hierarchical dependence among the latent variables as in common hierarchical latent variable models. Rather, similar to that in  Rezende et al. (2014)  and  Zhao et al. (2017) , z l 's are independent and each represents generative factors at an abstraction level not captured in other levels. We then define an inference model q φ to approximate the posterior as: q(z 1 , z 2 , ..., z L |x) = L l=1 q(z l |h l (x)), (2) where h l (x) represents a particular level of bottom-up abstraction of x. We parameterize p θ and q φ with an encoding-decoding structure and, as in  Zhao et al. (2017) , we approximate the abstraction level with the network depth. The full model is illustrated in Fig. 1(c), with a final goal to maximize a modified evidence lower bound (ELBO) of the marginal likelihood of data x: where KL denotes the Kullback-Leibler divergence, prior p(z) is set to isotropic Gaussian N (0, I) according to standard practice, and β is a hyperparameter introduced in  Higgins et al. (2017)  to promote disentangling, defaulting to the standrd ELBO objective when β = 1.

Section Title: PROGRESSIVE LEARNING OF HIERARCHICAL REPRESENTATION
  PROGRESSIVE LEARNING OF HIERARCHICAL REPRESENTATION We present a progressive learning strategy, as illustrated in  Fig. 1 , to achieve the final goal in equa- tion (3) by learning the latent variables z l progressively from the highest (l = L) to the lowest l = 1) level of abstractions. We start by learning the most abstraction representations at layer L as show in Fig. 1(a). In this case, our model degenerates to a vanilla VAE with latent variables z L at the deepest layer. We keep the dimension of z L small to start small in terms of the capacity to learn latent representations, where we define the inference model at progressive step s = 0 as: and the generative model as: g L = f d L (z L ), g l = f d l (g l+1 ), x = D(x; f d 0 (g 0 )), (5) where f e l , µ L , and σ L are parts of the encoder architecture, f d l are parts of the decoder architecture, and D is the distribution of x parametrized by f d 0 (g 0 ), which can be either Bernoulli or Gaus- sian depending on the data. Next, as shown in  Fig. 1 , we progressively grow the model to learn z L−1 , ..., z 2 , z 1 from high to low abstraction levels. At each progressive step s = 1, 2, ..., L − 1, we move down one abstraction level, and grow the inference model by introducing new latent code: Simultaneously, we grow the decoder such that it can generate with the new latent code as: g l = f d l ([m l (z l ); g l+1 ]), l = L − s, (7) where m l includes transposed convolution layers outputting a feature map in the same shape as g l+1 , and [·; ·] denotes a concatenation operation. The training objective at progressive step s is then: By replacing the full objective in equation (3) with a sequence of the objectives in equation (8) as the training progresses, we incrementally learn to extract and generate with hierarchical latent representations z l 's from high to low levels of abstractions. Once trained, the full model as shown in Fig. 1(c) will be used for inference and generation, and progressive processes are no loner needed.

Section Title: IMPLEMENTATION STRATEGIES
  IMPLEMENTATION STRATEGIES Two important strategies are utilized to implement the proposed progressive representation learning. First, directly adding new components to a trained network often introduce a sudden shock to the gradient: in VAEs, this often leads to the explosion of the variance in the latent distributions. To avoid this shock, we adopt the popular method of "fade-in" ( Karras et al. (2018) ) to smoothly blend the new and existing network components. In specific, we introduce a "fade-in" coefficient α to equations (6) and (7) when growing new components in the encoder and the decoder: z l ∼ N (µ l (αh l ), σ l (αh l )), g l = f d l ([αm l (z l ); g l+1 ]), (9) where α increases from 0 to 1 within a certain number of iterations (5000 in our experiments) since the addition of the new network components µ l ,σ l , and m l . Second, we further stabilize the training by weakly constraining the distribution of z l 's before they are added to the network. This can be achieved by a applying a KL penalty, modulated by a small coefficient γ, to all latent variables that have not been used in the generation at progressive step s: Published as a conference paper at ICLR 2020 where γ is set to 0.5 in our experiments. The final training objective at step s then becomes: Note that the latent variables at the hierarchy lower than L − s are neither meaningfully inferred nor used in generation at progressive step s, and L pre−trained merely intends to regularize the distribution of these latent variables before they are added to the network. In the experiments below, we use both "fade-in" and L pre−trained when implementing the progressive training strategy.

Section Title: DISENTANGLEMENT METRIC
  DISENTANGLEMENT METRIC Various quantitative metrics for measuring disentanglement have been proposed ( Higgins et al. (2017) ;  Kim & Mnih (2018) ;  Chen et al. (2018) ). For instance, the recently proposed MIG metrics ( Chen et al. (2018) ) measures the gap of mutual information between the top two latent dimensions that have the highest mutual information with a given generative factor. A low MIG score, therefore, suggests an undesired outcome that the same factor is split into multiple dimensions. However, if different generative factors are entangled into the same latent dimension, the MIG score will not be affected. Therefore, we propose a new disentanglement metric to supplement MIG by recognizing the entan- glement of multiple generative factors into the same latent dimension. We define MIG-sup as: 1 J J 1 I norm (z j ; v k (j) ) − max k =k (j) I norm (z j ; v k ) , (12) where z is the latent variables and v is the ground truth factors, k (j) = argmax k I norm (z j ; v k ), J is the number of meaningful latent dimensions, and I norm (z j ; v k ) is normalized mutual information I(z j ; v k )/H(v k ). Considering MIG and MIG-sup together will provide a more complete measure of disentanglement, accounting for both the splitting of one factor into multiple dimensions and the encoding of multiple factors into the same dimension. In an ideal disentanglement, both MIG and MIG-sup should be 1, recognizing a one-to-one relationship between a generative factor and a latent dimension. This would have a similar effect to the metric that was proposed in  Eastwood & Williams (2018) , although MIG-based metrics do not rely on training extra classifiers or regressors and are unbiased for hyperparameter settings. The factor metric ( Kim & Mnih (2018) ) also has similar properties with MIG-sup, although MIG-sup is stricter on penalizing any amount of other minor factors in the same dimension.

Section Title: EXPERIMENT
  EXPERIMENT We tested the presented pro-VLAE on four benchmark data sets: dSprites ( Matthey et al. (2017) ), 3DShapes ( Burgess & Kim (2018) ), MNIST ( LeCun et al. (1998) ), and CelebA ( Liu et al. (2015) ), where the first two include ground-truth generative factors that allow us to carry out comprehen- sive quantitative comparisons of disentangling metrics with existing models. In the following, we first quantitatively compare the disentangling ability of pro-VLAE in comparison to three existing models using three disentanglement metrics. We then analyze pro-VLAE from the aspects of how it learns progressively, its ability to disentangle, and its ability to learn abstractions at different levels.

Section Title: Comparisons in quantitative disentanglement metrics
  Comparisons in quantitative disentanglement metrics For quantitative comparisons, we consid- ered the factor metric in  Kim & Mnih (2018) , the MIG in  Chen et al. (2018) , and the MIG-sup pre- sented in this work. We compared pro-VLAE (changing β) with beta-VAE ( Higgins et al. (2017) ), VLAE ( Zhao et al. (2017) ) as a hierarchical baseline without progressive training, and the teacher- student model ( Lezama (2019) ) as the most related progressive VAE without hierarchical represen- tations. All models were considered at different values of β except the teacher-student model: the comparison of β-VAE, VLAE, and the presented pro-VLAE thus also provides an ablation study on the effect of learning hierarchical representations and doing so in a progressive manner. For fair comparisons, we strictly required all models to have the same number of latent variables and the same number of training iterations. For instance, if a hierarchical model has three layers that each has three latent dimensions, a non-hierarchical model will have nine latent dimensions; if a progressive method has three progressive steps with 15 epochs of training each, a non-progressive method will be trained for 45 epochs. Three to five experiments were conducted for each model at each β value, and the average of the top three is used for reporting the quantitative results in  Fig. 2 . As shown, for MIG and MIG-sup, VLAE generally outperformed β-VAE at most β values, while pro-VLAE showed a clear margin of improvement over both methods. With the factor metric, pro- VLAE was still among the top performers, although with a smaller margin and a larger overlap with VLAE on 3DShapes, and with β-VAE (β = 10) on dSprites. The teacher-student strategy with Jacobian supervision in general had a low to moderate disentangling score, especially on 3DShapes. This is consistent with the original motivation of the method for progressively learning nuisance variables after the teacher learns to disentangle effectively, rather than progressively disentangling hierarchical factors of variations as intended by pro-VLAE. Note that pro-VLAE in general per- formed better with a smaller value of β (β < 20), suggesting that progressive learning already had an effect of promoting disentangling and a high value of β may over-promote disentangling at the expense of reconstruction quality.  Fig. 3  shows MIG vs. MIG-sup scores among the tested models. As shown, results from pro-VLAE were well separated from the other three models at the right top quadrant of the plots, obtaining simultaneously high MIG and MIG-sup scores as a clear evidence for improved disentangling ability.  Fig. 4  provides images generated by traversing each latent dimension using the best pro-VLAE (β = 8), the best VLAE (β = 10), and the teacher-student model on 3DShapes data. As shown, pro-VLAE learned to disentangle the object, wall, and floor color in the deepest layer; the following hierarchy of representations then disentangled objective scale, orientation, and shape, while the lowest-level of abstractions ran out of meaningful generative factors to learn. In comparison, the VLAE distributed six generative factors over the nine latent dimensions, where color was split across the hierarchy and sometimes entangled with the object scale (in z 2 ). The teacher-student model was much less disentangled, which we will delve into further in the following section.

Section Title: Information flow during progressive learning
  Information flow during progressive learning To further understand what happened during pro- gressive learning, we use mutual information I(x, z l ) as a surrogate to track the amount of informa- tion learned in each hierarchy of latent variables z l during the progressive learning. We adopted the approach in  Chen et al. (2018)  to empirically estimate the mutual information by stratified sampling.  Fig. 5  shows an example from 3DShapes. At progressive step 0, pro-VAE was only learning the deepest latent variables in z 3 , discovering most of the generative factors including color, objective shape, and orientation entangled within z 3 . At progressive step 1, interestingly, the model was able to "drag" out shape and rotation factors from z 3 and disentangle them into z 2 along with a new scale factor. Thus I(x; z3) decreased from 10.59 to 6.94 while I(x; z2) increased from 0.02 to 5.98 in this progression, while the total mutual information I(x; z) increased from 10.61 to 12.84, suggesting the overall learning of more detailed information. Since 3DShapes only has 6 factors, the lowest-level representation z 1 had nothing to learn in progressive step 2, and the allocation of mutual information remained nearly unchanged. Note that the sum of I(x, z l )'s does not equal to I(x, z) and I over = L 1 I(x, z l ) − I(x, z) suggests the amount of information that is entangled. In comparison, the teacher-student model was less effective in progressively dragging entangled representations to newly added latent dimensions, as suggested by the slowing changing of I(x, z l )'s during progression and the larger value of I over . This suggests that, since the teacher-student model was motivated for progressively learning nuisance variables, the extent to which its capacity can grow for learning new representations is limited by two fundamental causes: 1) because it increases the dimension of the same latent vectors at the same depth, the growth of the network capacity is limited in comparison to pro-VLAE, and 2) the Jacobian supervision further restricts the student model to maintain the same disentangling ability of the teacher model.

Section Title: Disentangling hierarchical representations
  Disentangling hierarchical representations We also qualitatively examined pro-VLAE on data with both relatively simple (MNIST) and complex (CelebA) factors of variations, all done in un- supervised training. On MNIST ( Figure 6 ), while the deepest latent representations encoded the highest-level features in terms of digit identity, the representations learned at shallower levels en- coded changes in writing styles. In  Figure 7 , we show the latent representation progressively learned in CelebA from the highest to lowest levels of abstractions, along with disentangling within each level demonstrated by traversing one selected dimension at a time. These dimensions are selected as examples associated with clear semantic meanings. As shown, while the deepest latent rep- resentation z 4 learned to disentangle high-level features such as gender and race, the shallowest representation z 1 learned to disentangle low-level features such as eye-shadow. Moreover, the num- ber of distinct representations learned decreased from deep to shallow layers. While demonstrating disentangling by traversing each individual latent dimension or by hierarchically-learned represen- tations has been separately reported in previous works ( Higgins et al. (2017) ;  Zhao et al. (2017) ), to our knowledge this is the first time the ability of a model to disentangle individual latent factors in a hierarchical manner has been demonstrated. This provides evidence that the presented progressive strategy of learning can improve the disentangling of first the most abstract representations followed by progressively lower levels of abstractions.

Section Title: CONCLUSION
  CONCLUSION In this work, we present a progressive strategy for learning and disentangling hierarchical represen- tations. Starting from a simple VAE, the model first learn the most abstract representation. Next, the model learn independent representations from high- to low-levels of abstraction by progres- sively growing the capacity of the VAE deep to shallow. Experiments on several benchmark data sets demonstrated the advantages of the presented method. An immediate future work is to include stronger guidance for allocating information across the hierarchy of abstraction levels, either through external multi-scale image supervision or internal information-theoretic regularization strategies.

```
