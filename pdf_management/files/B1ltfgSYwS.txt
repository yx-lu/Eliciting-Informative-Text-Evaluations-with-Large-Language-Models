Title:
```
Under review as a conference paper at ICLR 2020 FEW-SHOT ONE-CLASS CLASSIFICATION VIA META- LEARNING
```
Abstract:
```
Although few-shot learning and one-class classification (OCC), i.e. learning a bi- nary classifier with data from only one class, have been separately well studied, their intersection remains rather unexplored. Our work addresses the few-shot OCC problem and presents a meta-learning approach that requires only few data examples from only one class to adapt to unseen tasks. The proposed method builds upon the model-agnostic meta-learning (MAML) algorithm (Finn et al., 2017) and learns a model initialization particularly suited for learning few-shot OCC tasks. This is done by explicitly optimizing for a parameter initialization which only requires a few gradient steps with one-class minibatches to yield a performance increase on class-balanced test data. We provide a theoretical anal- ysis that explains why our approach works in the few-shot OCC scenario, while other meta-learning algorithms, including MAML, fail. Empirical results on six datasets from the image and time-series domains show that our method substan- tially outperforms both, classical OCC and few-shot classification approaches, and demonstrate the ability to quickly learn unseen tasks from only few normal class samples. Moreover, we successfully learn anomaly detectors for a real-world ap- plication on sensor readings recorded during industrial manufacturing of work- pieces with a CNC milling machine using a few examples from the normal class.
```

Figures/Tables Captions:
```
Table 1: Test accuracies (in %) computed on the class-balanced test sets of the test tasks of Mini- ImageNet (1), Omniglot (2), MT-MNIST with T test = T 0 (3) and STS-Sawtooth (4). One-class adaptation sets (c = 0%) are used, unless otherwise specified.
Table 2: Test accuracies (in %) computed on the class-balanced test sets of the test tasks of MiniIm- ageNet (1), Omniglot (2), MT-MNIST with T test = T 0 (3) and STS-Sawtooth (4). The results are shown for models without BN (top) and with BN (bottom). One-class adaptation sets (c = 0%) are used, unless otherwise specified.
Table 3: Test F1-scores of OC-MAML on finishing (F i ) and roughing (R j ) operations of the CNC- MMD dataset, when only K = 10 normal examples are available (c = 0%). The ± shows 95% confidence intervals over 150 tasks sampled from the test operations (not used for meta-training).
```

Main Content:
```

Section Title: INTRODUCTION
  INTRODUCTION The anomaly detection (AD) task ( Chandola et al., 2009 ;  Aggarwal, 2015 ) consists in differentiat- ing between normal and abnormal data samples. AD applications are common in various domains that involve different data types, including medical diagnosis ( Prastawa et al., 2004 ), cybersecurity ( Garcia-Teodoro et al., 2009 ) and quality control in industrial manufacturing ( Scime & Beuth, 2018 ). Due to the rarity of anomalies, the data underlying AD problems exhibits high class-imbalance. Therefore, AD problems are usually formulated as one-class classification (OCC) problems ( Moya et al., 1993 ), where either only a few or no anomalous data samples are available for training the model ( Khan & Madden, 2014 ). While most of the developed approaches ( Khan & Madden, 2014 ) require a substantial amount of normal data to yield good generalization, in many real-world ap- plications, e.g. in industrial manufacturing, only small datasets are available. Data scarcity can have many reasons: data collection itself might be expensive, e.g. in healthcare, or happens only gradually, such as in a cold-start situation. To enable learning from few examples, various viable meta-learning approaches ( Lake et al., 2011 ;  Ravi & Larochelle, 2016 ;  Finn et al., 2017 ) have been developed. However, they rely on having examples from each of the classification task's classes, which prevents their application to OCC tasks. To the best of our knowledge, the few-shot OCC (FS-OCC) problem has only been addressed by  Kozerawski & Turk (2018)  in the image domain. Our contribution is threefold: Firstly, we show that classical OCC approaches fail in the few-shot data regime. Secondly, we provide a theoretical analysis showing that classical gradient-based meta- learning algorithms do not yield initializations suitable for OCC tasks and that second-order deriva- tives are needed to optimize for such initializations. Thirdly, we propose one-class model-agnostic meta-learning (OC-MAML), a data-domain-agnostic algorithm that quickly learns FS-OCC tasks, to serve as a first, simple and strong baseline for future research in the understudied FS-OCC problem. OC-MAML builds upon model-agnostic meta-learning (MAML) ( Finn et al., 2017 ), which is a meta-learning method that explicitly optimizes for few-shot learning and yields a model initialization Under review as a conference paper at ICLR 2020 that enables quick adaptation to a new task using only few of its datapoints. Like MAML, OC- MAML yields model parameters that are easily adaptable to unseen tasks. The difference is that the model initialization delivered by OC-MAML is particularly suited for adaptation to OCC tasks and hence requires few examples from only one class of the target task for good adaptation. We provide a theoretical analysis that shows that OC-MAML explicitly optimizes for parameter initializations which yield performance increase on class-balanced test data by taking only a few gradient steps with one-class minibatches. This is done by maximizing the inner product of gradients computed on different minibatches with different class-imbalance rates. While recent meta-learning approaches focused on the few-shot learning problem, i.e. learning to learn with few examples, we extend their use to the OCC problem, i.e. learning to learn with examples from only one class. We empirically validate our theoretical analysis on six datasets from the image and time-series domains, and demonstrate the robustness and maturity of our approach for real-world application by successfully testing it on a real-world dataset of sensor readings recorded during manufacturing of metal workpieces with a CNC milling machine.

Section Title: APPROACH
  APPROACH

Section Title: PROBLEM STATEMENT
  PROBLEM STATEMENT Our goal is to learn a one-class classification (OCC) task using only a few examples from the normal class. In the following, we first discuss the unique challenges of the few-shot one-class classification (FS-OCC) problem. Subsequently, we formulate the FS-OCC problem as a meta-learning problem. In order to perform one-class classification, i.e. differentiate between in-class and out-of-class ex- amples, approximating a generalized decision boundary for the normal class is necessary. Learning such a class decision boundary in the few-shot regime can be especially challenging for the follow- ing reasons. On the one hand, if the model overfits to the few available datapoints, the class decision boundary would be too restrictive, which would prevent generalization to unseen examples. As a result, some normal samples would be predicted as anomalies. On the other hand, if the model over- fits to the majority class, e.g. predicting almost everything as normal, the class decision boundary would overgeneralize, and out-of-class (anomalous) examples would not be detected. In our meta-learning problem formulation, we assume access to data from classification tasks T train i sampled from a task distribution p(T ) related to our target OCC tasks. In the few-shot classification context, N -way K-shot learning tasks are usually used to test the learning procedure, in our case the model initialization, yielded by the meta-learning algorithm. An N -way K-shot classification task includes K examples from each of the N classes that are used for learning this task, after which the trained classifier is tested on a disjoint set of data ( Vinyals et al., 2016 ). When the target task is an OCC task, only examples from one class are available for training, which can be viewed as a 1-way K-shot classification task. In order to align with the AD problem, the available examples have to belong to the normal (majority) class, which usually has a lower variance than the anoma- lous (minority) class. This problem formulation is a prototype for a practical use case where an application-specific anomaly detector is needed and only few normal class examples are available.

Section Title: MODEL-AGNOSTIC META-LEARNING
  MODEL-AGNOSTIC META-LEARNING Model-agnostic meta-learning (MAML) ( Finn et al., 2017 ) is an optimization-based meta-learning algorithm upon which we build in our present work. MAML learns a model initialization that enables quick adaptation to unseen tasks using only few data samples. For that, MAML trains a model explicitly for few-shot learning on tasks T i coming from the same task distribution p(T ) as the unseen target task T test . In order to assess the model's adaptation ability to unseen tasks, the available tasks are divided into mutually disjoint task sets: one for meta-training S tr , one for meta- validation S val and one for meta-testing S test . Each task T i is divided into two disjoint sets of data, each of which is used for a particular MAML operation: D tr is used for adaptation and D val is used for validation, i.e. evaluating the adaptation. The adaptation procedure of a model f θ to a particular task T i consists in taking one (or more) gradient descent step(s) using few datapoints sampled from D tr . We also refer to the adaptation updates as inner loop updates.

Section Title: Under review as a conference paper at ICLR 2020
  Under review as a conference paper at ICLR 2020 A good measure for the suitability of the initialization parameters θ for few-shot adaptation to a considered task T i is the loss L val Ti (f θ i ), which is computed on the validation set D val using the task-specific adapted model f θ i . In order to optimize for few-shot learning, the model parameters θ are updated by minimizing the aforementioned loss across all meta-training tasks. This update, called the outer loop update, can be expressed as: θ ← θ − β∇ θ Ti∼p(T ) L val Ti (f θ i ), (1) where β is the learning rate used for the outer loop. In order to avoid meta-overfitting, i.e. overfitting to the meta-training tasks, model selection can be done via conducting validation episodes using tasks from S val throughout meta-training. At meta-test time, the few-shot adaptation to unseen tasks from S test is evaluated. We note that, in the case of few-shot classification, K datapoints from each class are sampled from D tr for the adaptation, during training, validation and testing.

Section Title: ONE-CLASS MODEL-AGNOSTIC META-LEARNING
  ONE-CLASS MODEL-AGNOSTIC META-LEARNING

Section Title: ALGORITHM
  ALGORITHM The primary contribution of our work is to show that second-order gradient-based meta-learning is a viable approach to the underexplored few-shot one-class classification (FS-OCC) problem. We achieve this by adequately modifying the objective of the adaptation step, i.e. the inner loop up- dates, of the MAML algorithm. We choose to build upon gradient-based meta-learning algorithms, because these were shown to be universal learning algorithm approximators ( Finn & Levine, 2017 ), which means that they could approximate a learning algorithm tailored for FS-OCC. As explained in Section 2.2, MAML optimizes explicitly for few-shot adaptation by creating and using auxil- iary tasks that have the same characteristic as the target tasks, in this case tasks that include only few datapoints for training. Analogously, OC-MAML trains explicitly for quick adaptation to OCC tasks by creating OCC auxiliary tasks for meta-training. Concretely, this is done by modifying the class-imbalance rate (CIR) of the inner loop data batches to match the one of the test task. The meta-training procedure of OC-MAML is described in Algorithm 1 in Appendix A. As described in Section 1, OCC problems are binary classification scenarios where only few or no minority class samples are available. In order to address both of theses cases, we introduce a hyperparameter (c) which sets the CIR of the batch sampled for the inner updates. Hereby, c gives the percentage of the samples belonging to the minority (anomalous) class w.r.t. the total number of samples, e.g. setting c = 0% means only majority class samples are contained in the data batch. We focus on this latter extreme case, where no anomalous samples are available for learning. The key difference between MAML and OC-MAML is in the sampling operation of the inner loop batch (operation 5 in Algorithm 1 in Appendix A). By reducing the size of the batch used for the adaptation (via the hyperparameter K), MAML trains for few-shot adaptation. OC-MAML extends this approach to train for few-shot one-class adaptation by reducing the CIR of the batch used for adaptation (via the hyperparameter c). In order to evaluate the performance of the adapted model on both classes, we use a class-balanced validation batch B for the outer loop updates. This way, we maximize the performance of the model in recognizing both classes after having seen examples from only one class during adaptation. Using OCC tasks for adaptation during meta-training favors model initializations that enable a quick adaptation to OCC tasks over those that require class- balanced tasks. From a representation learning standpoint, OC-MAML learns representations that are not only broadly suitable for the data underlying p(T ), but also particularly suited for OCC tasks. In Section 2.3.2, we discuss the unique characteristics of the model initializations yielded by OC-MAML and explain why adapting first-order meta-learning algorithms to the OCC scenario does not yield the targeted results.

Section Title: THEORETICAL ANALYSIS: WHY DOES OC-MAML WORK ?
  THEORETICAL ANALYSIS: WHY DOES OC-MAML WORK ? In this section we give a theoretical explanation of why OC-MAML works and why it is a more suitable approach than MAML for the few-shot one-class classification (FS-OCC) problem. To address the latter problem, we aim to find a model parameter initialization, from which adaptation using few data examples from only one class yields a good performance on both classes, i.e. good Under review as a conference paper at ICLR 2020 generalization to the class-balanced task. We additionally demonstrate that adapting first-order meta- learning algorithms, e.g. First-Order MAML (FOMAML) ( Finn et al., 2017 ) and Reptile ( Nichol & Schulman, 2018 ), to the OCC scenario as done in OC-MAML, does not yield initializations with the desired characteristics, as it is the case for OC-MAML. By using a Taylor series expansion, Nichol & Schulman (2018) approximate the gradient used in the MAML update. For simplicity of exposition, in Equation 2 we give their results for the case where only 2 gradient-based updates are performed, i.e. one adaptation update on a minibatch including K datapoints from D tr and one meta-update on a minibatch including Q datapoints from D val . We use the same notation used by Nichol & Schulman (2018), where g i and H i denote the gradient and Hessian computed on the i th minibatch at the initial parameter point φ 1 , and α gives the learning rate. Here it is assumed that the same learning rate is used for the adaptation and meta-updates. In Equation 2 Nichol & Schulman (2018) demonstrate that MAML partially optimizes for increas- ing the inner product of the gradients computed on different minibatches. In fact, when gradients from different minibatches have a positive inner product, taking a gradient step using one of them yields a performance increase on the other ( Nichol & Schulman, 2018 ). Equation 2 holds also for OC-MAML. However, in OC-MAML the minibatches 1 and 2 have different class-imbalance rates (CIRs), since the first minibatch includes data from only one class and the second minibatch is class- balanced. Hence, it optimizes for increasing the inner product of the gradients computed on different minibatches with different CIRs, while MAML does the same but for different minibatches with the same CIR, namely c = 50%. Consequently, OC-MAML optimizes for a parameter initialization from which taking one (or few) gradient step(s) with one-class minibatch(es) results in a perfor- mance increase on class-balanced data. In contrast, MAML optimizes for a parameter initialization that requires class-balanced minibatches to yield the same effect (Figure 1 in Appendix A). When adapting to OCC tasks, however, only examples from one class are available. We conclude, there- fore, that using minibatches with different CIRs for meta-training, as done in OC-MAML, yields parameter initializations that are more suitable for adapting to OCC tasks. A natural question is whether applying our modification of MAML, i.e. using only data from the normal class for adaptation during meta-training, to other gradient-based meta-learning algorithms would yield the same desired effect. We investigate this for First-Order MAML (FOMAML) ( Finn et al., 2017 ) and Reptile ( Nichol & Schulman, 2018 ). FOMAML is a first-order approximation of MAML, which ignores the second derivative terms. Reptile is also a first-order meta-learning algorithm that learns an initialization that enables fast adaptation to test tasks using only few ex- amples from each class. In the following we demonstrate that adapting the FOMAML and Reptile algorithms to the one-class classification scenario, to which we will refer as OC-FOMAML and OC- Reptile, does not result in optimizing for an initialization suitable for OCC tasks, as it is the case for OC-MAML. We note that for OC-Reptile, the first (N − 1) batches contain examples from only one class and the last (N th ) batch is class-balanced. The approximated gradients used in the FOMAML and Reptile updates are given by Equations 3 and 4 ( Nichol & Schulman, 2018 ), respectively. We note that these equations hold also for OC-FOMAML and OC-Reptile. By taking the expectation over minibatch sampling E τ,1,2 for a meta-training task τ and two class-balanced minibatches, Nichol & Schulman (2018) establish that E τ,1,2 [H 1 g 2 ] = E τ,1,2 [H 2 g 1 ]. Averaging the two sides of the latter equation results in the following: Equation 5 shows that, in expectation, FOMAML and Reptile, like MAML, optimize for increasing the inner product of the gradients computed on different minibatches with the same CIR. How- ever, when the minibatches 1 and 2 have different CIRs, which is the case for OC-FOMAML and OC-Reptile, E τ,1,2 [H 1 g 2 ] = E τ,1,2 [H 2 g 1 ] and therefore E τ,1,2 [H 2 g 1 ] = 1 2 E τ,1,2 [ ∂(g1.g2) ∂φ1 ]. Hence, Under review as a conference paper at ICLR 2020 even though, similarly to OC-MAML, OC-FOMAML and OC-Reptile use minibatches with differ- ent CIRs for meta-training, contrarily to OC-MAML, they do not optimize for increasing the inner product of the gradients computed on different minibatches with different CIRs. The second deriva- tive term H 1 g 2 is, thus, necessary to optimize for an initialization from which performance increase on a class-balanced task is yielded by taking few gradient steps using only data from one class.

Section Title: RELATED WORKS
  RELATED WORKS Our proposed method addresses the few-shot one-class classification (FS-OCC) problem, i.e. solv- ing binary classification problems using only few datapoints from only one class. To the best of our knowledge, this problem was only addressed by  Kozerawski & Turk (2018) , and exclusively in the image data domain.  Kozerawski & Turk (2018)  train a feed-forward neural network (FFNN) to learn a transformation from feature vectors, extracted by a CNN pre-trained on ILSVRC 2014 ( Russakovsky et al., 2015 ), to SVM decision boundaries. Hereby, the FFNN is trained on ILSVRC 2012. At test time, an SVM boundary is inferred by using one image of one class from the test task which is then used to classify the test examples. This approach is specific to the image domain since it relies on the availability of very large, well annotated datasets and uses data augmentation tech- niques specific to the image domain, e.g. mirroring. OC-MAML offers a more general approach to FS-OCC since it is data-domain-agnostic. In fact, it does not require a pre-trained feature extraction model, which might not be available for some data domains, e.g. sensor readings.

Section Title: FEW-SHOT CLASSIFICATION
  FEW-SHOT CLASSIFICATION Recent few-shot classification approaches may be broadly categorized in optimization-based meth- ods ( Ravi & Larochelle, 2016 ;  Finn et al., 2017 ;  Nichol & Schulman, 2018 ) and metric-based meth- ods ( Koch, 2015 ;  Vinyals et al., 2016 ;  Snell et al., 2017 ;  Sung et al., 2018 ). The optimization-based approaches aim to learn an optimization algorithm ( Ravi & Larochelle, 2016 ) and/or a parameter initialization ( Finn et al., 2017 ;  Nichol & Schulman, 2018 ), that is tailored for few-shot learning. Metric-based techniques learn a metric space where samples belonging to the same class are close together, which facilitates few-shot classification ( Koch, 2015 ;  Vinyals et al., 2016 ;  Snell et al., 2017 ;  Sung et al., 2018 ).  Rusu et al. (2018)  develops a hybrid method that combines the advantages of both categories. Prior meta-learning approaches to few-shot classification addressed the N-way K-shot classification problem described in Section 2.1, i.e they only consider neatly class-balanced test classification tasks. Optimization-based techniques require these samples to finetune the learned initialization. In the metric-based methods, these samples are necessary to compute class prototypes ( Snell et al., 2017 ), embeddings needed for verification ( Koch, 2015 ) or relation scores ( Sung et al., 2018 ). Our approach, however, requires only samples from one of the test task's classes for learning. Moreover, while the evaluation of the previous approaches in the classification context was limited to the image domain, we additionally validate OC-MAML on datasets from the time-series domain.

Section Title: ONE-CLASS CLASSIFICATION
  ONE-CLASS CLASSIFICATION Classical OCC approaches rely on SVMs ( Schölkopf et al., 2001 ; Tax & Duin, 2004) to distinguish between normal and abnormal samples.  Pal & Foody (2010)  show that the classification accuracy of SVMs decreases with an increasing number of input features, particularly when small datasets are available for training. Hybrid approaches combining SVM-based techniques with feature extractors were developed to compress the input samples in lower dimensional representations ( Xu et al., 2015 ;  Erfani et al., 2016 ;  Andrews et al., 2016 ). Fully deep methods that jointly perform the feature extraction step and the OCC step have also been developed ( Ruff et al., 2018 ). Another category of approaches to OCC uses the reconstruction error of antoencoders ( Hinton & Salakhutdinov, 2006 ) trained with only normal class examples as an anomaly score ( Hawkins et al., 2002 ;  An & Cho, 2015 ;  Chen et al., 2017 ). Yet, determining a decision threshold for such an anomaly score requires labeled data from both classes. Further more recent techniques rely on GANs ( Goodfellow et al., 2014 ) to perform OCC ( Schlegl et al., 2017 ;  Ravanbakhsh et al., 2017 ;  Sabokrou et al., 2018 ). The aforementioned hybrid and fully deep approaches require a considerable amount of data from the OCC task to train the typically highly parametrized models to learn features specific to the normal class. By leveraging auxiliary OCC tasks and explicitly optimizing for few-shot learning, OC-MAML learns a representation that can be adapted to unseen OCC task with only few exaples.

Section Title: EXPERIMENTAL EVALUATION
  EXPERIMENTAL EVALUATION The conducted experiments 1 aim to address the following key questions: (a) How does OC-MAML perform compared to classical one-class classification (OCC) approaches in the few-shot (FS) data regime? (b) Does using OCC tasks for meta-training improve the adaptation to such tasks, as it is the case for few-shot tasks ( Finn et al., 2017 ), and do our theoretical findings (Section 2.3.2) about the differences between the MAML and OC-MAML initializations hold in practice? (c) How does OC-MAML compare to the first-order meta-learning algorithms adapted to the OCC scenario, i.e. OC-FOMAML and OC-Reptile (Section 2.3.2)? (d) How does OC-MAML perform in FS-OCC problems from the time-series domain, which is understudied in the few-shot learning literature?

Section Title: BASELINES AND DATASETS
  BASELINES AND DATASETS This section provides information about the baselines and datasets we use in our experimental evalu- ation. We compare OC-MAML to the classical one-class classification (OCC) approaches One-Class SVM (OC-SVM) ( Schölkopf et al., 2001 ) and Isolation Forest (IF) ( Liu et al., 2008 ) (Question (a)), which we fit to the adaptation set of the test task. Here, we apply PCA to reduce the dimensionality of the data, by choosing the minimum number of eigenvectors so that at least 95% of the variance is preserved as done by  Erfani et al. (2016) . We additionally tune the inverse length scale γ by using 10% of the test set, as done by  Ruff et al. (2018) , which gives OC-SVM a supervised advantage, compared to the other methods. For a fairer comparison to OC-MAML, where these latter methods also benefit from the meta-training and meta-validation tasks, we additionally train them on em- beddings inferred by feature extractors learned on these tasks. Here, we train two types of feature extractors on the meta-training tasks: one is trained in a Multi-Task-Learning (MTL) setting and the other trained using the "Finetune" baseline (FB) ( Triantafillou et al., 2019 ). FB is a few-shot classification approach, where one multi-class classifier is trained with all the classes available in all meta-training tasks, after which, an output layer is finetuned with the few available examples of the target task on top of the learned feature extractor. Moreover, we compare OC-MAML to class-balanced meta-learning algorithms, namely MAML, FOMAML and Reptile, as well as first- order meta-learning algorithms adapted to the OCC scenario, i.e. OC-FOMAML and OC-Reptile (Questions (b) and (c)). Experimental details are provided in Appendix B. We evaluate our approach on six datasets, including 3 from the image domain and 3 from the time- series domain. In the image domain we use 2 few-shot learning benchmark datasets, namely Mini- ImageNet ( Ravi & Larochelle, 2016 ) and Omniglot ( Lake et al., 2015 ), and 1 OCC benchmark dataset, the Multi-Task MNIST (MT-MNIST) dataset. To adapt the datasets to the OCC scenario, we create binary classification tasks, where the normal class contains examples from one class of the initial dataset and the anomalous class contains examples from multiple other classes. We create 9 different datasets based on MNIST, where the meta-testing task of each dataset consists in differ- entiating between a certain digit and the others. We use the same (10 th ) task for meta-validation in all datasets. Since most of the time-series datasets for anomaly detection include data from only one domain and only one normal class, adapting them to the meta-learning problem formulation where several different tasks are required is not possible. Therefore, we create two synthetic time- series (STS) datasets, each including 30 synthetically generated time-series that underlie 30 different anomaly detection tasks, to assess the suitability of OC-MAML to time-series data (Question (d)). The time-series underlying the datasets are sawtooth waveforms (STS-Sawtooth) and sine func- tions (STS-Sine). We propose the STS-datasets as benchmark datasets for the few-shot (one-class) classification problem in the time-series domain. Finally, we validate OC-MAML on a real-world anomaly detection dataset of sensor readings recorded during industrial manufacturing using a CNC milling machine. Various consecutive roughing and finishing operations (pockets, edges, holes, sur- face finish) were performed on ca. 100 aluminium workpieces to record the CNC Milling Machine Data (CNC-MMD). In Appendix C, we give details about all 6 datasets, the task creation procedures adopted to adapt them to the OCC case, as well as the generation of the STS-datasets.

Section Title: RESULTS AND DISCUSSION
  RESULTS AND DISCUSSION Our results of the comparison between OC-MAML and the classical OCC approaches on the 3 im- age datasets and on the STS-Sawtooth dataset are summarized in  Table 1 . OC-MAML consistently outperforms all baselines across all datasets and on both adaptation set sizes. While FB and MTL yield relatively good performance when adapting to class-balanced tasks (c = 50%), they com- pletely fail in adapting to OCC tasks. On the MT-MNIST dataset and the STS-Sawtooth dataset, some of the baselines that combine a feature extractor and a shallow model yield high performance, when the adaptation set size is K = 10. Our results of the comparison between OC-MAML and the classical few-shot classification approaches on the 3 image datasets and on the STS-Sawtooth dataset are summarized in  Table 2 . The results on the other 8 MT-MNIST datasets and on the STS-Sine dataset are presented in Appendix D and are consistent with the results in  Tables 1  and 2. We observe that OC-MAML consistently outperforms the other meta-learning algorithms with a substantial margin on all datasets and for both adaptation set sizes. This confirms our theoretical findings (Section 2.3.2) that the initializations yielded by class-balanced meta-learning algorithms as well as OC-FOMAML and OC-Reptile are not optimized for adaptation using data from only one class. These latter yield test accuracies close to 50% showing that they overfitted to the normal class ( Table 2  (top)). In an attempt to increase the performance of the other meta-learning algorithms in the OCC scenario, we add a batch normalization (BN) ( Ioffe & Szegedy, 2015 ) layer immediately before the output layer of the network. This BN operation standardizes the latent features using the mean and standard deviation of the K datapoints available for adaptation, which all belong to the normal class. As a result, this layer would output features with mean close to 0 and standard deviation close to 1 for normal class examples. In contrast, anomalous examples would yield features with other statistics, which simplifies their detection. We hypothesize that by enforcing a mapping of the data to a latent space standardized only by examples from the normal class, the anomalies would clearly fall out of the normal-class-distribution, making their detection easier. We note that the BN layer is used during meta-training as well. Hereby, we fix the learnable scaling (γ) and centering (β) parameters of the BN layer to 1 and 0, respectively, to prevent it from shifting the standard distribution. We find that this simple modification increases the performance of the other meta-learning algo- rithms on all image datasets. However, OC-MAML without BN still yields the highest results, with only one exception. The higher performance increase when a bigger adaptation set is available (K = 10) confirms our hypothesis that enforcing a mapping of the data to a latent space standardized only by examples from the normal class makes the detection of the anomalies easier. In fact, using more examples yields more accurate mean and standard deviation measures, which enables a better approximation of the distribution of the normal class, and hence leads to an improved detection of the anomalies. We also tested these algorithms on networks including a trainable BN layer after each convolutional layer. This yielded comparable results to just adding one non-trainable BN layer Under review as a conference paper at ICLR 2020 before the output layer. Even though some of the meta-learning algorithms and OCC approaches sometimes outperform OC-MAML ( Tables 2 , 5, 8, 9), they do not consistently yield high perfor- mance in learning FS-OCC tasks across several datasets, as it is the case for OC-MAML. We note that this happens only on few MT-MNIST datasets and explain that by the high overlap between the digit classes underlying the meta-training and meta-testing tasks in the MT-MNIST datasets. The results of OC-MAML experiments on the CNC-MMD dataset are presented in  Table 3 . We compute F1-scores for evaluation since the test sets are class-imbalanced. OC-MAML consistently achieves high F1-scores across the 6 different milling processes. This high model performance on the minority class, i.e. in detecting anomalous data samples, is reached by using only K = 10 non-anomalous data samples (c = 0%). These results show that OC-MAML yielded a parameter initialization suitable for learning OCC tasks in the time-series data domain. Moreover, the high performance reached show the maturity of this method for industrial real-world applications.

Section Title: CONCLUSION
  CONCLUSION This work addressed the novel and challenging problem of few-shot one-class classification (FS- OCC) and introduced OC-MAML, a robust meta-learning approach to FS-OCC problems that learns model parameters which are easily adaptable to unseen tasks using few examples from only one class. We demonstrated the viability of our method on six datasets from the image time-series domains, including a real-world dataset of industrial sensor readings, where it significantly out- performed classical OCC and few-shot classification methods. Future works could investigate an unsupervised approach to FS-OCC, as done by  Hsu et al. (2018)  in the class-balanced scenario. Under review as a conference paper at ICLR 2020

```
