<article article-type="research-article"><front><article-meta><title-group><article-title>LATION EXTRACTION USING PRE-TRAINED LANGUAGE MODELS</article-title></title-group><abstract><p>Named entity recognition (NER) and relation extraction (RE) are two important tasks in information extraction and retrieval (IE &amp; IR). Recent work has demon- strated that it is beneficial to learn these tasks jointly, which avoids the propagation of error inherent in pipeline-based systems and improves performance. However, state-of-the-art joint models typically rely on external natural language process- ing (NLP) tools, such as dependency parsers, limiting their usefulness to domains (e.g. news) where those tools perform well. The few neural, end-to-end mod- els that have been proposed are trained almost completely from scratch. In this paper, we propose a neural, end-to-end model for jointly extracting entities and their relations which does not rely on external NLP tools and which integrates a large, pre-trained language model. Because the bulk of our model's parameters are pre-trained and we eschew recurrence for self-attention, our model is fast to train. On 5 datasets across 3 domains, our model matches or exceeds state-of-the-art performance, sometimes by a large margin.</p></abstract></article-meta></front><body><sec><title>INTRODUCTION</title><p>The extraction of named entities (named entity recognition, NER) and their semantic relations (rela- tion extraction, RE) are key tasks in information extraction and retrieval (IE &amp; IR). Given a sequence of text (usually a sentence), the objective is to identify both the named entities and the relations between them. This information is useful in a variety of NLP tasks such as question answering, knowledge base population, and semantic search (<xref ref-type="bibr" rid="b8">Jiang, 2012</xref>). In the biomedical domain, NER and RE facilitate large-scale biomedical data analysis, such as network biology (<xref ref-type="bibr" rid="b13">Zhou et al., 2014</xref>), gene prioritization (<xref ref-type="bibr" rid="b1">Aerts et al., 2006</xref>), drug repositioning (<xref ref-type="bibr" rid="b15">Wang &amp; Zhang, 2013</xref>) and the creation of curated databases (Li et al., 2015). In the clinical domain, NER and RE can aid in disease and treat- ment prediction, readmission prediction, de-identification, and patient cohort identification (<xref ref-type="bibr" rid="b15">Miotto et al., 2017</xref>).</p><p>Most commonly, the tasks of NER and RE are approached as a pipeline, with NER preceding RE. There are two main drawbacks to this approach: (1) Pipeline systems are prone to error propagation between the NER and RE systems. (2) One task is not able to exploit useful information from the other (e.g. the type of relation identified by the RE system may be useful to the NER system for determining the type of entities involved in the relation, and vice versa). More recently, joint models that simultaneously learn to extract entities and relations have been proposed, alleviating the aforementioned issues and achieving state-of-the-art performance (<xref ref-type="bibr" rid="b16">Miwa &amp; Sasaki, 2014</xref>; <xref ref-type="bibr" rid="b16">Miwa &amp; Bansal, 2016</xref>; <xref ref-type="bibr" rid="b7">Gupta et al., 2016</xref>; <xref ref-type="bibr" rid="b10">Li et al., 2016</xref>; <xref ref-type="bibr" rid="b0">2017</xref>; Zhang et al., 2017; <xref ref-type="bibr" rid="b0">Adel &amp; Sch&#252;tze, 2017</xref>; <xref ref-type="bibr" rid="b2">Bekoulis et al., 2018a</xref>;b; <xref ref-type="bibr" rid="b18">Nguyen &amp; Verspoor, 2019</xref>; Li et al., 2019).</p><p>Many of the proposed joint models for entity and relation extraction rely heavily on external natural language processing (NLP) tools such as dependency parsers. For instance, <xref ref-type="bibr" rid="b16">Miwa &amp; Bansal (2016)</xref> propose a recurrent neural network (RNN)-based joint model that uses a bidirectional long-short term memory network (BiLSTM) to model the entities and a tree-LSTM to model the relations be- tween entities; <xref ref-type="bibr" rid="b10">Li et al. (2017)</xref> propose a similar model for biomedical text. The tree-LSTM uses dependency tree information extracted using an external dependency parser to model relations be- tween entities. The use of these external NLP tools limits the effectiveness of a model to domains Under review as a conference paper at ICLR 2020 (e.g. news) where those NLP tools perform well. As a remedy to this problem, <xref ref-type="bibr" rid="b2">Bekoulis et al. (2018a)</xref> proposes a neural, end-to-end system that jointly learns to extract entities and relations without relying on external NLP tools. In <xref ref-type="bibr" rid="b2">Bekoulis et al. (2018b)</xref>, they augment this model with ad- versarial training. <xref ref-type="bibr" rid="b18">Nguyen &amp; Verspoor (2019)</xref> propose a different, albeit similar end-to-end neural model which makes use of deep biaffine attention (<xref ref-type="bibr" rid="b6">Dozat &amp; Manning, 2016</xref>). Li et al. (2019) ap- proach the problem with multi-turn question answering, posing templated queries to a BERT-based QA model (<xref ref-type="bibr" rid="b4">Devlin et al., 2018</xref>) whose answers constitute extracted entities and their relations and achieve state-of-the-art results on three popular benchmark datasets.</p><p>While demonstrating strong performance, end-to-end systems like <xref ref-type="bibr" rid="b2">Bekoulis et al. (2018a</xref>;b) and <xref ref-type="bibr" rid="b18">Nguyen &amp; Verspoor (2019)</xref> suffer from two main drawbacks. The first is that most of the models parameters are trained from scratch. For large datasets, this can lead to long training times. For small datasets, which are common in the biomedical and clinical domains where it is particularly challenging to acquire labelled data, this can lead to poor performance and/or overfitting. The sec- ond is that these systems typically contain RNNs, which are sequential in nature and cannot be parallelized within training examples. The multi-pass QA model proposed in Li et al. (2019) allevi- ates these issues by incorporating a pre-trained language model, BERT (<xref ref-type="bibr" rid="b4">Devlin et al., 2018</xref>), which eschews recurrence for self-attention. The main limitation of their approach is that it relies on hand- crafted question templates to achieve maximum performance. This may become a limiting factor where domain expertise is required to craft such questions (e.g., for biomedical or clinical corpora). Additionally, one has to create a question template for each entity and relation type of interest.</p><p>In this study, we propose an end-to-end model for joint NER and RE which addresses all of these issues. Similar to past work, our model can be viewed as a mixture of a NER module and a RE module (<xref ref-type="fig" rid="fig_0">Figure 1</xref>). Unlike most previous works, we include a pre-trained, transformer-based lan- guage model, specifically BERT (<xref ref-type="bibr" rid="b4">Devlin et al., 2018</xref>), which achieved state-of-the-art performance across many NLP tasks. The weights of the BERT model are fine-tuned during training, and the entire model is trained in an end-to-end fashion.</p><p>Our main contributions are as follows: (1) Our solution is truly end-to-end, relying on no hand- crafted features (e.g. templated questions) or external NLP tools (e.g. dependency parsers). (2) Our model is fast to train (e.g. under 10 minutes on a single GPU for the CoNLL04 corpus), as most of its parameters are pre-trained and we avoid recurrence. (3) We match or exceed state-of-the-art performance for joint NER and RE on 5 datasets across 3 domains.</p></sec><sec><title>THE MODEL</title><p><xref ref-type="fig" rid="fig_0">Figure 1</xref> illustrates the architecture of our approach. Our model is composed of an NER module and an RE module. The NER module is identical to the one proposed by <xref ref-type="bibr" rid="b4">Devlin et al. (2018)</xref>. For a given input sequence s of N word tokens w 1 , w 2 , . . ., w N , the pre-trained BERT BASE model first produces a sequence of vectors, x (NER) 1 , x (NER) 2 , . . ., x (NER) N which are then fed to a feed-forward neural network (FFNN) for classification.</p><p>The output size of this layer is the number of BIOES-based NER labels in the training data, |C (NER) |. In the BIOES tag scheme, each token is assigned a label, where the B- tag indicates the beginning of an entity span, I- the inside, E- the end and S- is used for any single-token entity. All other tokens are assigned the label O.</p><p>During training, a cross-entropy loss is computed for the NER objective, L NER = &#8722; N n=1 log e s (NER) n C (NER) c e s (NER) n,c (2) where s (NER) n is the predicted score that token n &#8712; N belongs to the ground-truth entity class and s (NER) n,c is the predicted score for token n belonging to the entity class c &#8712; C (NER) . Under review as a conference paper at ICLR 2020 In the RE module, the predicted entity labels are obtained by taking the argmax of each score vector s (NER) 1 , s (NER) 2 , . . ., s (NER) N . The predicted entity labels are then embedded to produce a sequence of fixed-length, continuous vectors, e (NER) 1 , e (NER) 2 , . . ., e (NER) N which are concatenated with the hidden states from the final layer in the BERT model and learned jointly with the rest of the models parameters.</p><p>Following <xref ref-type="bibr" rid="b16">Miwa &amp; Bansal (2016)</xref> and <xref ref-type="bibr" rid="b18">Nguyen &amp; Verspoor (2019)</xref>, we incrementally construct the set of relation candidates, R, using all possible combinations of the last word tokens of predicted entities, i.e. words with E- or S- labels. An entity pair is assigned to a negative relation class (NEG) when the pair has no relation or when the predicted entities are not correct. Once relation candidates are constructed, classification is performed with a deep bilinear attention mechanism (<xref ref-type="bibr" rid="b6">Dozat &amp; Manning, 2016</xref>), as proposed by <xref ref-type="bibr" rid="b18">Nguyen &amp; Verspoor (2019)</xref>.</p><p>To encode directionality, the mechanism uses FFNNs to project each x (RE) i into head and tail vector representations, corresponding to whether the i th word serves as head or tail argument of the relation.</p><p>These projections are then fed to a biaffine classifier,</p><p>where U is an m &#215; |C (RE) | &#215; m tensor, W is a |C (RE) | &#215; (2 * m) matrix, and b is a bias vector. Here, m is the size of the output layers of FFNN head and FFNN tail and C (RE) is the set of all relation classes (including NEG). During training, a second cross-entropy loss is computed for the RE objective</p><p>Under review as a conference paper at ICLR 2020 where s (RE) r is the predicted score that relation candidate r &#8712; R belongs to the ground-truth relation class and s (RE) r,c is the predicted score for relation r belonging to the relation class c &#8712; C (RE) . The model is trained in an end-to-end fashion to minimize the sum of the NER and RE losses.</p></sec><sec><title>ENTITY PRETRAINING</title><p>In <xref ref-type="bibr" rid="b16">Miwa &amp; Bansal (2016)</xref>, entity pre-training is proposed as a solution to the problem of low- performance entity detection in the early stages of training. It is implemented by delaying the training of the RE module by some number of epochs, before training the entire model jointly. Our implementation of entity pretraining is slightly different. Instead of delaying training of the RE module by some number of epochs, we weight the contribution of L RE to the total loss during the first epoch of training L = L NER + &#955; L RE (10) where &#955; is increased linearly from 0 to 1 during the first epoch and set to 1 for the remaining epochs. We chose this scheme because the NER module quickly achieves good performance for all datasets (i.e. within one epoch). In early experiments, we found this scheme to outperform a delay of a full epoch.</p></sec><sec><title>IMPLEMENTATION</title><p>We implemented our model in PyTorch (<xref ref-type="bibr" rid="b20">Paszke et al., 2017</xref>) using the BERT BASE model from the PyTorch Transformers library 1 . Our model is available at our GitHub repository 2 . Furthermore, we use NVIDIAs automatic mixed precision (AMP) library Apex 3 to speed up training and reduce memory usage without affecting task-specific performance.</p></sec><sec><title>EXPERIMENTAL SETUP</title></sec><sec><title>DATASETS AND EVALUATION</title><p>To demonstrate the generalizability of our model, we evaluate it on 5 commonly used benchmark corpora across 3 domains. All corpora are in English. Detailed corpus statistics are presented in Table A.1 of the appendix. The Automatic Content Extraction (ACE04) corpus was introduced by <xref ref-type="bibr" rid="b5">Doddington et al. (2004)</xref>, and is commonly used to benchmark NER and RE methods. There are 7 entity types and 7 relation types. ACE05 builds on ACE04, splitting the Physical relation into two classes (Physical and Part- Whole), removing the Discourse relation class and merging Employment-Membership-Subsidiary and Person-Organization-Affiliation into one class (Employment-Membership-Subsidiary).</p><p>For ACE04, we follow <xref ref-type="bibr" rid="b16">Miwa &amp; Bansal (2016)</xref> by removing the Discourse relation and evaluating our model using 5-fold cross-validation on the bnews and nwire subsets, where 10% of the data was held out within each fold as a validation set. For ACE05, we use the same test split as <xref ref-type="bibr" rid="b16">Miwa &amp; Bansal (2016)</xref>. We use 5-fold cross-validation on the remaining data to choose the hyperparameters. Once hyperparameters are chosen, we train on the combined data from all the folds and evaluate on the test set. For both corpora, we report the micro-averaged F 1 score. We obtained the pre-processing scripts from <xref ref-type="bibr" rid="b16">Miwa &amp; Bansal (2016)</xref> 4 .</p></sec><sec><title>CONLL04</title><p>The CoNLL04 corpus was introduced in <xref ref-type="bibr" rid="b23">Roth &amp; Yih (2004)</xref> and consists of articles from the Wall Street Journal (WSJ) and Associated Press (AP). There are 4 entity types and 5 relation types. We use the same test set split as <xref ref-type="bibr" rid="b16">Miwa &amp; Sasaki (2014)</xref> 5 . We use 5-fold cross-validation on the remaining data to choose hyperparameters. Once hyperparameters are chosen, we train on the com- bined data from all folds and evaluate on the test set, reporting the micro-averaged F 1 score.</p></sec><sec><title>ADE</title><p>The adverse drug event corpus was introduced by <xref ref-type="bibr" rid="b8">Gurulingappa et al. (2012)</xref> to serve as a benchmark for systems that aim to identify adverse drug events from free-text. It consists of the abstracts of medical case reports retrieved from PubMed 6 . There are two entity types, Drug and Adverse effect and one relation type, Adverse drug event.</p><p>Similar to previous work (<xref ref-type="bibr" rid="b10">Li et al., 2016</xref>; <xref ref-type="bibr" rid="b0">2017</xref>; <xref ref-type="bibr" rid="b2">Bekoulis et al., 2018b</xref>), we remove &#8764;130 relations with overlapping entities and evaluate our model using 10-fold cross-validation, where 10% of the data within each fold was used as a validation set, 10% as a test set and the remaining data is used as a train set. We report the macro F 1 score averaged across all folds. The 2010 i2b2/VA dataset was introduced by <xref ref-type="bibr" rid="b25">Uzuner et al. (2011)</xref> for the 2010 i2b2/Va Workshop on Natural Language Processing Challenges for Clinical Records. The workshop contained an NER task focused on the extraction of 3 medical entity types (Problem, Treatment, Test) and an RE task for 8 relation types.</p><p>In the official splits, the test set contains roughly twice as many examples as the train set. To increase the number of training examples while maintaining a rigorous evaluation, we elected to perform 5- fold cross-validation on the combined data from both partitions. We used 10% of the data within each fold as a validation set, 20% as a test set and the remaining data was used as a train set. We report the micro F 1 score averaged across all folds.</p><p>To the best of our knowledge, we are the first to evaluate a joint NER and RE model on the 2010 i2b2/VA dataset. Therefore, we decided to compare to scores obtained by independent NER and RE systems. We note, however, that the scores of independent RE systems are not directly comparable to the scores we report in this paper. This is because RE is traditionally framed as a sentence-level classification problem. During pre-processing, each example is permutated into processed examples containing two "blinded" entities and labelled for one relation class. E.g. the example: "His PCP had recently started ciprofloxacin TREATMENT for a UTI PROBLEM " becomes "His PCP had recently started @TREATMENT$ for a @PROBLEM$", where the model is trained to predict the target relation type, "Treatment is administered for medical problem" (TrAP).</p><p>This task is inherently easier than the joint setup, for two reasons: relation predictions are made on ground-truth entities, as opposed to predicted entities (which are noisy) and the model is only required to make one classification decision per pre-processed sentence. In the joint setup, a model must identify any number of relations (or the lack thereof) between all unique pairs of predicted entities in a given input sentence. To control for the first of these differences, we report scores from our model in two settings, once when predicted entities are used as input to the RE module, and once when ground-truth entities are used.</p></sec><sec><title>HYPERPARAMETERS</title><p>Besides batch size, learning rate and number of training epochs, we used the same hyperparameters across all experiments (see Table A.2). Similar to <xref ref-type="bibr" rid="b4">Devlin et al. (2018)</xref>, learning rate and batch size were selected for each dataset using a minimal grid search (see See Table A.3).</p></sec><sec><title>Under review as a conference paper at ICLR 2020</title><p>One hyperparameter selected by hand was the choice of the pre-trained weights used to initialize the BERT BASE model. For general domain corpora, we found the cased BERT BASE weights from <xref ref-type="bibr" rid="b4">Devlin et al. (2018)</xref> to work well. For biomedical corpora, we used the weights from BioBERT (<xref ref-type="bibr" rid="b4">Lee et al., 2019</xref>), which recently demonstrated state-of-the-art performance for biomedical NER, RE and QA. Similarly, for clinical corpora we use the weights provided by <xref ref-type="bibr" rid="b12">Peng et al. (2019)</xref>, who pre-trained BERT BASE on PubMed abstracts and clinical notes from MIMIC-III 7 .</p></sec><sec><title>RESULTS</title></sec><sec><title>JOINTLY LEARNING NER AND RE</title><p><xref ref-type="table" rid="tab_0">Table 1</xref> shows our results in comparison to previously published results, grouped by the domain of the evaluated corpus. We find that on every dataset besides i2b2, our model improves NER performance, for an average improvement of &#8764;2%. This improvement is particularly large on the ACE04 and ACE05 corpora (3.98% and 2.41% respectively). On i2b2, our joint model performs within 0.29% of the best independent NER solution.</p><p>For relation extraction, we outperform previous methods on 2 datasets and come within &#8764;2% on both ACE05 and CoNLL04. In two cases, our performance improvement is substantial, with im- provements of 4.59% and 10.25% on the ACE04 and ADE corpora respectively. For i2b2, our score is not directly comparable to previous systems (as discussed in section 3.1.4) but will facilitate future comparisons of joint NER and RE methods on this dataset. By comparing overall performance, we find that our approach achieves new state-of-the-art performance for 3 popular benchmark datasets (ACE04, ACE05, ADE) and comes within 0.2% for CoNLL04.</p></sec><sec><title>ABLATION ANALYSIS</title><p>To determine which training strategies and components are responsible for our models performance, we conduct an ablation analysis on the CoNLL04 corpus (<xref ref-type="table" rid="tab_1">Table 2</xref>). We perform five different abla- tions: (a) Without entity pre-training (see section 2.1), i.e. the loss function is given by equation 9.</p><p>(b) Without entity embeddings, i.e. equation 3 becomes x (RE) i = x (NER) i . (c) Replacing the two feed-forward neural networks, FFNN head and FFNN tail with a single FFNN (see equation 4 and 5).</p><p>(d) Removing FFNN head and FFNN tail entirely. (e) Without the bilinear operation, i.e. equation 7 becomes a simple linear transformation.</p><p>Removing FFNN head and FFNN tail has, by far, the largest negative impact on performance. Inter- estingly, however, replacing FFNN head and FFNN tail with a single FFNN has only a small negative impact. This suggests that while these layers are very important for model performance, using dis- tinct FFNNs for the projection of head and tail entities (as opposed to the same FFNN) is relatively much less important. The next most impactful ablation was entity pre-training, suggesting that low-performance entity detection during the early stages of training is detrimental to learning (see section 2.1). Finally, we note that the importance of entity embeddings is surprising, as a previous study has found that entity embeddings did not help performance on the CoNLL04 corpus (<xref ref-type="bibr" rid="b2">Bekoulis et al., 2018a</xref>), although their architecture was markedly different. We conclude that each of our ablated components is necessary to achieve maximum performance.</p></sec><sec><title>ANALYSIS OF THE WORD-LEVEL ATTENTION WEIGHTS</title><p>One advantage of including a transformer-based language model is that we can easily visualize the attention weights with respect to some input. This visualization is useful, for example, in detect- ing model bias and locating relevant attention heads (<xref ref-type="bibr" rid="b26">Vig, 2019</xref>). Previous works have used such visualizations to demonstrate that specific attention heads mark syntactic dependency relations and that lower layers tend to learn more about syntax while higher layers tend to encode more semantics (<xref ref-type="bibr" rid="b22">Raganato &amp; Tiedemann, 2018</xref>).</p><p>In <xref ref-type="fig" rid="fig_1">Figure 2</xref> we visualize the attention weights of select layers and attention heads from an instance of BERT fine-tuned within our model on the CoNLL04 corpus. We display four patterns that are easily Under review as a conference paper at ICLR 2020 To facilitate further analysis of our learned model, we make available Jupyter and Google Colabora- tory notebooks on our GitHub repository 8 , where users can use multiple views to explore the learned attention weights of our models. We use the BertViz library (<xref ref-type="bibr" rid="b26">Vig, 2019</xref>) to render the interactive, HTML-based views and to access the attention weights used to plot the heat maps.</p></sec><sec><title>DISCUSSION AND CONCLUSION</title><p>In this paper, we introduced an end-to-end model for entity and relation extraction. Our key contri- butions are: (1) No reliance on any hand-crafted features (e.g. templated questions) or external NLP tools (e.g. dependency parsers). (2) Integration of a pre-trained, transformer-based language model.</p><p>(3) State-of-the-art performance on 5 datasets across 3 domains. Furthermore, our model is inher- ently modular. One can easily initialize the language model with pre-trained weights better suited for a domain of interest (e.g. BioBERT for biomedical corpora) or swap BERT for a comparable language model (e.g. XLNet (Yang et al., 2019)). Finally, because of (2), our model is fast to train, converging in approximately 1 hour or less on a single GPU for all datasets used in this study.</p><p>Our model out-performed previous state-of-the-art performance on ADE by the largest margin (6.53%). While exciting, we believe this corpus was particularly easy to learn. The majority of sentences (&#8764;68%) are annotated for two entities (drug and adverse effect, and one relation (adverse drug event). Ostensibly, a model should be able to exploit this pattern to get near-perfect perfor- mance on the majority of sentences in the corpus. As a test, we ran our model again, this time using ground-truth entities in the RE module (as opposed to predicted entities) and found that the model very quickly reached almost perfect performance for RE on the test set (&#8764;98%). As such, high performance on the ADE corpus is not likely to transfer to real-world scenarios involving the large-scale annotation of diverse biomedical articles.</p><p>In our experiments, we consider only intra-sentence relations. However, the multiple entities within a document generally exhibit complex, inter-sentence relations. Our model is not currently capable of extracting such inter-sentence relations and therefore our restriction to intra-sentence relations will limit its usefulness for certain downstream tasks, such as knowledge base creation. We also ignore the problem of nested entities, which are common in biomedical corpora. In the future, we would like to extend our model to handle both nested entities and inter-sentence relations. Finally, given that multilingual, pre-trained weights for BERT exist, we would also expect our model's performance to hold across multiple languages. We leave this question to future work.</p><p>Under review as a conference paper at ICLR 2020</p></sec><sec id="figures"><title>Figures</title><fig id="fig_0"><object-id>fig_0</object-id><label>Figure 1:</label><caption><title>Figure 1:</title><p>Joint named entity recognition (NER) and relation extraction (RE) model architecture.</p></caption><graphic /><graphic /></fig><table-wrap id="tab_0"><label>Table 1:</label><caption><title>Table 1:</title><p>Comparison to previously published F 1 scores for joint named entity recognition (NER) and relation extraction (RE). Ours (gold): our model, when gold entity labels are used as input to the RE module. Ours: full, end-to-end model (see section 2). Bold: best scores. Subscripts denote standard deviation across three runs. &#8710;: difference to our overall score.</p></caption><table><tbody><tr><td /></tr></tbody></table></table-wrap><table-wrap id="tab_1"><label>Table 2:</label><caption><title>Table 2:</title><p>Ablation experiment results on the CoNLL04 corpus. Scores are reported as a micro- averaged F 1 score on the validation set, averaged across three runs of 5-fold cross-validation. (a) Without entity pre-training (section 2.1). (b) Without entity embeddings (eq. 3). (c) Using a single FFNN in place of FFNN head and FFNN tail (eq. 4 and 5) (d) Without FFNN head and FFNN tail (e) Without the bilinear operation (eq. 7). Bold: best scores. Subscripts denote standard deviation across three runs. &#8710;: difference to the full models score.</p></caption><table><tbody><tr><td /></tr></tbody></table></table-wrap><fig id="fig_1"><object-id>fig_1</object-id><label>Figure 2:</label><caption><title>Figure 2:</title><p>Visualization of the attention weights from select layers and heads of BERT after it was fine-tuned within our model on the CoNLL04 corpus. Darker squares indicate larger atten- tion weights. Attention weights are shown for the input sentence: "Ruby fatally shot Oswald two days after Kennedy was assassinated.". The CLS and SEP tokens have been removed. Four major patterns are displayed: paying attention to the next word (first image from the left) and previous word (second from the left), paying attention to the word itself (third from the left) and the end of the sentence (fourth from the left).</p></caption><graphic /><graphic /><graphic /><graphic /><graphic /><graphic /><graphic /><graphic /><graphic /><graphic /></fig></sec></body><back><ref-list id="ref-list-1"><ref id="b0"><element-citation publication-type="journal"><article-title>Global normalization of convolutional neural networks for joint entity and relation classification</article-title><source>Proceedings of the 2017 Conference on Empirical Meth- ods in Natural Language Processing, Copenhagen, Denmark</source><person-group person-group-type="author"><name><surname>References</surname><given-names>Heike</given-names></name><name><surname>Adel</surname><given-names>Hinrich</given-names></name><name><surname>Sch&#252;tze</surname><given-names /></name></person-group></element-citation></ref><ref id="b1"><element-citation publication-type="journal"><article-title>Gene prioritization through genomic data fusion</article-title><source>Nature Biotechnology</source><year>2006</year><volume>24</volume><issue>5</issue><fpage>537</fpage><lpage>544</lpage><person-group person-group-type="author"><name><surname>Stein Aerts</surname><given-names>Diether</given-names></name><name><surname>Lambrechts</surname><given-names>Sunit</given-names></name><name><surname>Maity</surname><given-names>Peter</given-names></name><name><surname>Van Loo</surname><given-names>Bert</given-names></name><name><surname>Coessens</surname><given-names>Frederik De</given-names></name><name><surname>Smet</surname><given-names>Leon-Charles</given-names></name><name><surname>Tranchevent</surname><given-names>Bart De</given-names></name><name><surname>Moor</surname><given-names>Peter</given-names></name><name><surname>Marynen</surname><given-names>Bassem</given-names></name><name><surname>Hassan</surname><given-names>Peter</given-names></name><name><surname>Carmeliet</surname><given-names>Yves</given-names></name><name><surname>Moreau</surname><given-names /></name></person-group></element-citation></ref><ref id="b2"><element-citation publication-type="journal"><article-title>Joint entity recognition and relation extraction as a multi-head selection problem</article-title><source>Expert Systems with Applications</source><year>2018</year><volume>114</volume><fpage>34</fpage><lpage>45</lpage><person-group person-group-type="author"><name><surname>Bekoulis</surname><given-names>Giannis</given-names></name><name><surname>Deleu</surname><given-names>Johannes</given-names></name><name><surname>Demeester</surname><given-names>Thomas</given-names></name><name><surname>Develder</surname><given-names>Chris</given-names></name></person-group></element-citation></ref><ref id="b3"><element-citation publication-type="journal"><article-title>Adversarial training for multi-context joint entity and relation extraction</article-title><source>arXiv preprint arXiv:1808.06876</source><year>2018</year><person-group person-group-type="author"><name><surname>Bekoulis</surname><given-names>Giannis</given-names></name><name><surname>Deleu</surname><given-names>Johannes</given-names></name><name><surname>Demeester</surname><given-names>Thomas</given-names></name><name><surname>Develder</surname><given-names>Chris</given-names></name></person-group></element-citation></ref><ref id="b4"><element-citation publication-type="journal"><article-title>Bert: Pre-training of deep bidirectional transformers for language understanding</article-title><source>arXiv preprint arXiv:1810.04805</source><year>2018</year><person-group person-group-type="author"><name><surname>Devlin</surname><given-names>Jacob</given-names></name><name><surname>Chang</surname><given-names>Ming-Wei</given-names></name><name><surname>Lee</surname><given-names>Kenton</given-names></name><name><surname>Toutanova</surname><given-names>Kristina</given-names></name></person-group></element-citation></ref><ref id="b5"><element-citation publication-type="journal"><article-title>The automatic content extraction (ACE) program - tasks, data, and evaluation. In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC'04), Lisbon, Portugal, May 2004</article-title><source>European Language Resources Association (ELRA)</source><person-group person-group-type="author"><name><surname>Doddington</surname><given-names>George</given-names></name><name><surname>Mitchell</surname><given-names>Alexis</given-names></name><name><surname>Przybocki</surname><given-names>Mark</given-names></name><name><surname>Ramshaw</surname><given-names>Lance</given-names></name><name><surname>Strassel</surname><given-names>Stephanie</given-names></name><name><surname>Weischedel</surname><given-names>Ralph</given-names></name></person-group></element-citation></ref><ref id="b6"><element-citation publication-type="journal"><article-title>Deep biaffine attention for neural dependency parsing</article-title><source>arXiv preprint arXiv:1611.01734</source><year>2016</year><person-group person-group-type="author"><name><surname>Dozat</surname><given-names>Timothy</given-names></name><name><surname>Christopher</surname><given-names>D</given-names></name><name><surname>Manning</surname><given-names /></name></person-group></element-citation></ref><ref id="b7"><element-citation publication-type="journal"><article-title>Table filling multi-task recurrent neural net- work for joint entity and relation extraction</article-title><source>Proceedings of COLING 2016, the 26th Interna- tional Conference on Computational Linguistics: Technical Papers</source><year>2016</year><fpage>2537</fpage><lpage>2547</lpage><person-group person-group-type="author"><name><surname>Gupta</surname><given-names>Pankaj</given-names></name><name><surname>Sch&#252;tze</surname><given-names>Hinrich</given-names></name><name><surname>Andrassy</surname><given-names>Bernt</given-names></name></person-group></element-citation></ref><ref id="b8"><element-citation publication-type="journal"><article-title>Development of a benchmark corpus to support the automatic extraction of drug-related adverse effects from medical case reports</article-title><source>Journal of Biomedi- cal Informatics</source><year>2012</year><volume>45</volume><issue>5</issue><fpage>885</fpage><lpage>892</lpage><person-group person-group-type="author"><name><surname>Gurulingappa</surname><given-names>Harsha</given-names></name><name><surname>Rajput</surname><given-names>Abdul Mateen</given-names></name><name><surname>Roberts</surname><given-names>Angus</given-names></name><name><surname>Fluck</surname><given-names>Juliane</given-names></name><name><surname>Hofmann- Apitius</surname><given-names>Martin</given-names></name><name><surname>Toldo</surname><given-names>Luca</given-names></name></person-group></element-citation></ref><ref id="b9"><element-citation publication-type="journal"><article-title>Biobert: pre-trained biomedical language representation model for biomedical text mining</article-title><source>arXiv preprint arXiv:1901.08746</source><year>2019</year><person-group person-group-type="author"><name><surname>Lee</surname><given-names>Jinhyuk</given-names></name><name><surname>Yoon</surname><given-names>Wonjin</given-names></name><name><surname>Kim</surname><given-names>Sungdong</given-names></name><name><surname>Kim</surname><given-names>Donghyeon</given-names></name><name><surname>Kim</surname><given-names>Sunkyu</given-names></name><name><surname>Ho So</surname><given-names>Chan</given-names></name><name><surname>Kang</surname><given-names>Jae- Woo</given-names></name></person-group></element-citation></ref><ref id="b10"><element-citation publication-type="journal"><article-title>Joint models for extracting adverse drug events from biomedical text</article-title><source>IJCAI</source><year>2016</year><fpage>2838</fpage><lpage>2844</lpage><person-group person-group-type="author"><name><surname>Li</surname><given-names>Fei</given-names></name><name><surname>Zhang</surname><given-names>Yue</given-names></name><name><surname>Zhang</surname><given-names>Meishan</given-names></name><name><surname>Ji</surname><given-names>Donghong</given-names></name></person-group></element-citation></ref><ref id="b11"><element-citation publication-type="journal"><article-title>A neural joint model for entity and relation extraction from biomedical text</article-title><source>BMC bioinformatics</source><year>2017</year><volume>18</volume><issue>1</issue><fpage>198</fpage><lpage>198</lpage><person-group person-group-type="author"><name><surname>Li</surname><given-names>Fei</given-names></name><name><surname>Zhang</surname><given-names>Meishan</given-names></name><name><surname>Fu</surname><given-names>Guohong</given-names></name><name><surname>Ji</surname><given-names>Donghong</given-names></name></person-group></element-citation></ref><ref id="b12"><element-citation publication-type="journal"><article-title>miR- Tex: A text mining system for miRNA-gene relation extraction</article-title><source>PLOS Computational Biology</source><year>2015</year><volume>11</volume><issue>9</issue><fpage>e1004391</fpage><lpage>e1004391</lpage><person-group person-group-type="author"><name><surname>Li</surname><given-names>Gang</given-names></name><name><surname>Ross</surname><given-names>Karen E</given-names></name><name><surname>Arighi</surname><given-names>Cecilia N</given-names></name><name><surname>Peng</surname><given-names>Yifan</given-names></name><name><surname>Wu</surname><given-names>Cathy H</given-names></name><name><surname>Vijay-Shanker</surname><given-names>K</given-names></name></person-group></element-citation></ref><ref id="b13"><element-citation publication-type="journal"><article-title>Entity-relation extraction as multi-turn question answering</article-title><source>arXiv preprint arXiv:1905.05529</source><year>2019</year><person-group person-group-type="author"><name><surname>Li</surname><given-names>Xiaoya</given-names></name><name><surname>Yin</surname><given-names>Fan</given-names></name><name><surname>Sun</surname><given-names>Zijun</given-names></name><name><surname>Li</surname><given-names>Xiayu</given-names></name><name><surname>Yuan</surname><given-names>Arianna</given-names></name><name><surname>Chai</surname><given-names>Duo</given-names></name><name><surname>Zhou</surname><given-names>Mingxin</given-names></name><name><surname>Li</surname><given-names>Jiwei</given-names></name></person-group></element-citation></ref><ref id="b14"><element-citation publication-type="journal"><article-title>Fixing weight decay regularization in adam</article-title><source>CoRR</source><year>2017</year><person-group person-group-type="author"><name><surname>Loshchilov</surname><given-names>Ilya</given-names></name><name><surname>Hutter</surname><given-names>Frank</given-names></name></person-group></element-citation></ref><ref id="b15"><element-citation publication-type="journal"><article-title>Deep learning for healthcare: review, opportunities and challenges</article-title><source>Briefings in bioinformatics</source><year>2017</year><volume>19</volume><issue>6</issue><fpage>1236</fpage><lpage>1246</lpage><person-group person-group-type="author"><name><surname>Miotto</surname><given-names>Riccardo</given-names></name><name><surname>Wang</surname><given-names>Fei</given-names></name><name><surname>Wang</surname><given-names>Shuang</given-names></name><name><surname>Jiang</surname><given-names>Xiaoqian</given-names></name><name><surname>Dudley</surname><given-names>Joel T</given-names></name></person-group></element-citation></ref><ref id="b16"><element-citation publication-type="journal"><article-title>End-to-end relation extraction using lstms on sequences and tree structures</article-title><source>arXiv preprint arXiv:1601.00770</source><year>2016</year><person-group person-group-type="author"><name><surname>Miwa</surname><given-names>Makoto</given-names></name><name><surname>Bansal</surname><given-names>Mohit</given-names></name></person-group></element-citation></ref><ref id="b17"><element-citation publication-type="journal"><article-title>Modeling joint entity and relation extraction with table repre- sentation</article-title><source>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</source><year>2014</year><fpage>1858</fpage><lpage>1869</lpage><person-group person-group-type="author"><name><surname>Miwa</surname><given-names>Makoto</given-names></name><name><surname>Sasaki</surname><given-names>Yutaka</given-names></name></person-group></element-citation></ref><ref id="b18"><element-citation publication-type="journal"><source>Advances in Information Retrieval</source><year>2019</year><fpage>729</fpage><lpage>738</lpage><person-group person-group-type="author"><name><surname>Dat Quoc Nguyen</surname><given-names>Karin</given-names></name><name><surname>Verspoor</surname><given-names /></name></person-group></element-citation></ref><ref id="b19"><element-citation publication-type="journal"><article-title>On the difficulty of training recurrent neural networks</article-title><source>International Conference on Machine Learning</source><year>2013</year><fpage>1310</fpage><lpage>1318</lpage><person-group person-group-type="author"><name><surname>Pascanu</surname><given-names>Razvan</given-names></name><name><surname>Mikolov</surname><given-names>Tomas</given-names></name><name><surname>Bengio</surname><given-names>Yoshua</given-names></name></person-group></element-citation></ref><ref id="b20"><element-citation publication-type="journal"><article-title>Automatic differentiation in PyTorch</article-title><source>NIPS Autodiff Workshop</source><year>2017</year><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>Adam</given-names></name><name><surname>Gross</surname><given-names>Sam</given-names></name><name><surname>Chintala</surname><given-names>Soumith</given-names></name><name><surname>Chanan</surname><given-names>Gregory</given-names></name><name><surname>Yang</surname><given-names>Edward</given-names></name><name><surname>Devito</surname><given-names>Zachary</given-names></name><name><surname>Lin</surname><given-names>Zeming</given-names></name><name><surname>Desmaison</surname><given-names>Alban</given-names></name><name><surname>Antiga</surname><given-names>Luca</given-names></name><name><surname>Lerer</surname><given-names>Adam</given-names></name></person-group></element-citation></ref><ref id="b21"><element-citation publication-type="journal"><article-title>Transfer learning in biomedical natural language pro- cessing: An evaluation of BERT and elmo on ten benchmarking datasets</article-title><source>CoRR</source><year>2019</year><person-group person-group-type="author"><name><surname>Peng</surname><given-names>Yifan</given-names></name><name><surname>Yan</surname><given-names>Shankai</given-names></name><name><surname>Lu</surname><given-names>Zhiyong</given-names></name></person-group></element-citation></ref><ref id="b22"><element-citation publication-type="journal"><article-title>An analysis of encoder representations in transformer- based machine translation</article-title><source>Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyz- ing and Interpreting Neural Networks for NLP</source><year>2018</year><fpage>287</fpage><lpage>297</lpage><person-group person-group-type="author"><name><surname>Raganato</surname><given-names>Alessandro</given-names></name><name><surname>Tiedemann</surname><given-names>J&#246;rg</given-names></name></person-group></element-citation></ref><ref id="b23"><element-citation publication-type="journal"><article-title>A linear programming formulation for global inference in natural language tasks</article-title><source>Proceedings of the Eighth Conference on Computational Natural Language Learning (CoNLL-2004) at HLT-NAACL 2004</source><year>2004</year><fpage>1</fpage><lpage>8</lpage><person-group person-group-type="author"><name><surname>Roth</surname><given-names>Dan</given-names></name><name><surname>Wen-Tau Yih</surname><given-names /></name></person-group></element-citation></ref><ref id="b24"><element-citation publication-type="journal"><article-title>Enhancing clinical concept extraction with con- textual embedding</article-title><source>CoRR</source><year>2019</year><person-group person-group-type="author"><name><surname>Si</surname><given-names>Yuqi</given-names></name><name><surname>Wang</surname><given-names>Jingqi</given-names></name><name><surname>Xu</surname><given-names>Hua</given-names></name><name><surname>Roberts</surname><given-names>Kirk</given-names></name></person-group></element-citation></ref><ref id="b25"><element-citation publication-type="journal"><article-title>i2b2/va challenge on concepts, assertions, and relations in clinical text</article-title><source>Journal of the American Medical Informatics Association</source><year>2010</year><volume>18</volume><issue>5</issue><fpage>552</fpage><lpage>556</lpage><person-group person-group-type="author"><name><surname>Uzuner</surname><given-names>Ozlem</given-names></name><name><surname>Brett</surname><given-names>R</given-names></name><name><surname>South</surname><given-names>Shuying</given-names></name><name><surname>Shen</surname><given-names>Scott L</given-names></name><name><surname>Duvall</surname><given-names /></name></person-group></element-citation></ref><ref id="b26"><element-citation publication-type="journal"><article-title>A multiscale visualization of attention in the transformer model</article-title><source>CoRR</source><year>2019</year><person-group person-group-type="author"><name><surname>Vig</surname><given-names>Jesse</given-names></name></person-group></element-citation></ref><ref id="b27"><element-citation publication-type="journal"><article-title>Rational drug repositioning by medical genetics</article-title><source>Nature Biotechnology</source><year>2013</year><volume>31</volume><issue>12</issue><fpage>1080</fpage><lpage>1082</lpage><person-group person-group-type="author"><name><surname>Zhong</surname><given-names>Yi</given-names></name><name><surname>Wang</surname><given-names>Hong-Yu</given-names></name><name><surname>Zhang</surname><given-names /></name></person-group></element-citation></ref><ref id="b28"><element-citation publication-type="journal"><article-title>Xlnet: Generalized autoregressive pretraining for language understanding</article-title><source>arXiv preprint arXiv:1906.08237</source><year>2019</year><person-group person-group-type="author"><name><surname>Yang</surname><given-names>Zhilin</given-names></name><name><surname>Dai</surname><given-names>Zihang</given-names></name><name><surname>Yang</surname><given-names>Yiming</given-names></name><name><surname>Carbonell</surname><given-names>Jaime</given-names></name><name><surname>Salakhutdinov</surname><given-names>Ruslan</given-names></name><name><surname>Le</surname><given-names>Quoc V</given-names></name></person-group></element-citation></ref><ref id="b29"><element-citation publication-type="journal"><article-title>End-to-end neural relation extraction with global optimization</article-title><source>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</source><year>2017</year><fpage>1730</fpage><lpage>1740</lpage><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Meishan</given-names></name><name><surname>Zhang</surname><given-names>Yue</given-names></name><name><surname>Fu</surname><given-names>Guohong</given-names></name></person-group></element-citation></ref><ref id="b30"><element-citation publication-type="journal"><article-title>Human symp- toms-disease network</article-title><source>Nature Communications</source><year>2014</year><volume>5</volume><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Xuezhong</given-names></name><name><surname>Menche</surname><given-names>Jrg</given-names></name><name><surname>Barab&#225;si</surname><given-names>Albert-L&#225;szl&#243;</given-names></name><name><surname>Sharma</surname><given-names>Amitabh</given-names></name></person-group></element-citation></ref></ref-list></back></article>