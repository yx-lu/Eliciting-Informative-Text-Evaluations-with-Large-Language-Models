Title:
```
Under review as a conference paper at ICLR 2020 COLLAPSED AMORTIZED VARIATIONAL INFERENCE FOR SWITCHING NONLINEAR DYNAMICAL SYSTEMS
```
Abstract:
```
We propose an efficient inference method for switching nonlinear dynamical sys- tems. The key idea is to learn an inference network which can be used as a proposal distribution for the continuous latent variables, while performing exact marginal- ization of the discrete latent variables. This allows us to use the reparameterization trick, and apply end-to-end training with stochastic gradient descent. We show that the proposed method can successfully segment time series data (including videos) into meaningful "regimes", by using the piece-wise nonlinear dynamics.
```

Figures/Tables Captions:
```
Figure 1: (a): Trajectory of a particle moving along a counter-clockwise route. The direction of motion is indicated by the arrow and the brightness, from lower to brighter intensity. (b) Ground truth segmentation into "regimes". Blue is moving straight, yellow is turning counter-clockwise, red is turning clockwise. (c) Segmentation learned by our SNLDS model. (d) Segmentation learned by baseline SLDS model. Note that to model the nonlinear dynamics, the SLDS model needs to use more segments.
Figure 2: Left: Illustration of the generative model. Dashed arrows indicate optional connections. Right: Illustration of the inference network. Solid black arrows share parameters θ with the generative model, solid blue arrows have parameters φ that are unique to q. The diamonds represent deterministic nodes computed with RNNs: h x t is a bidirectional RNN applied to x 1:T , and h z t is a unidrectional RNN applied to h x t−1 and z t−1 .
Figure 3: Segmentation on bouncing ball (left) and reacher task (right). From top to bottom: Row 1. ground truth of latent discrete states; Rows 2, 3, 4, 5, 6, 7. the posterior marginals, p(s t = k|x 1:T , z 1:T ), of SNLDS, SLDS, rSLDS, SVAE, KVAE, and Gumbel-Softmax SNLDS respectively, where lighter color represents higher probability. CompILE is not included because it represents a different model family that directly predicts the segment boundary without calculating posterior marginals at each time step.
Figure 4: Comparing the relative negative log-likelihood (left) and the frame-wise F 1 scores (right) on Dubins paths with 3 different annealing schedules. In the first run (green), the regularization coefficient and temperature start to decay at the very beginning of training. In the second run (red), the cross entropy regularization coefficients starts to decay at step 20, 000, while temperature annealing starts at step 40, 000. In the third run (blue), the coefficient decay starts at step 50, 000, while temperature annealing starts at step 100, 000.
Table 1: Quantitative comparisons (in % ±σ) for segmentation on bouncing ball and reacher task. We report the F 1 scores in percentage with mean and standard deviation over 5 runs. (S.P. for switching point, F.W. for frame-wise, the best mean is in bold.) The F 1 score for CompILE is adapted from Kipf et al. (2019), where only switching point F 1 score is provided. The F 1 score for KVAE is computed based on taking 'argmax' on the 'dynamics parameter network' as described in Fraccaro et al. (2017).
Table 2: Quantitative comparisons (in %) for S(N)LDS on Dubins path. For SLDS, F 1 scores with both greedy 1-to-1 matching (Greedy) and optimal merging (Merging) are provided. The switching point F 1 scores are estimated with both precise matching (Tol 0) or allowing at most 5-step displacement (Tol 5).
```

Main Content:
```

Section Title: INTRODUCTION
  INTRODUCTION Consider watching from above an airplane flying across country or a car driving through a field. The vehicle's motion is composed of straight, linear dynamics and curving, nonlinear dynamics. This is illustrated in fig. 1(a). In this paper, we propose a new inference algorithm for fitting switching nonlinear dynamical systems (SNLDS), which can be used to segment time series data as sequences of images, or lower dimensional signals, such as (x,y) locations into meaningful discrete temporal "modes" or "regimes". The transitions between these modes may correspond to the changes in internal goals of the agent (e.g., a mouse switching from running to resting, as in  Johnson et al. (2016) ) or may be caused by external factors (e.g., changes in the road curvature). Discovering such discrete modes is useful for scientific applications (c.f.,  Wiltschko et al. (2015) ;  Linderman et al. (2019) ) as well as for planning in the context of hierarchical reinforcement learning (c.f.,  Kipf et al. (2019) ). There has been extensive previous work, some of which we review in Section 2, on modeling temporal data using various forms of state space models (SSM). We are interested in the class of SSM which has both discrete and continuous latent variables, which we denote by s t and z t , where t is the discrete time index. The discrete state, s t ∈ {1, 2, . . . , K}, represents the mode of the system at time t, and the continuous state, z i ∈ R H , represents other factors of variation, such as location and velocity. The observed data is denoted by x t ∈ R D , and can either be a low dimensional projection of z t , such as the current location, or a high dimensional signal that is informative about z t , such as an image. We may optionally have observed input or control signals u t ∈ R U , which drive the system in addition to unobserved stochastic noise. We are interested in learning a generative model of the form Under review as a conference paper at ICLR 2020 p θ (s 1:T , z 1:T , x 1:T |u 1:T ) from partial observations, namely (x 1:T , u 1:T ). This requires inferring the posterior over the latent states, p θ (s 1:T , z 1:T |v 1:T ), where v t = (x t , u t ) contains all the visible variables at time t. For training purposes, we usually assume that we have multiple such trajectories, possibly of different lengths, but we omit the sequence indices from our notations for simplicity. This problem is very challenging, because the model contains both discrete and continuous latent variables (a so-called "hybrid system"), and has nonlinear transition and observation models. The main contribution of our paper is a new way to perform efficient approximate inference in this class of SNLDS models. The key observation is that, conditioned on knowing z 1:T as well as v 1:T , we can marginalize out s 1:T in linear time using the forward-backward algorithm. In particular, we can efficiently compute the gradient of the log marginal likelihood, ∇ s 1:T log p(s 1:T |z 1:T , v 1:T ), wherez 1:T is a posterior sample that we need for model fitting. To efficiently compute posterior samplesz 1:T , we learn an amortized inference network q φ (z 1:T |v 1:T ) for the "collapsed" NLDS model p(z 1:T , v 1:T ). The collapsing trick removes the discrete variables, and allows us to use the reparameterization trick for the continuous z. These tricks let us use stochastic gradient descent (SGD) to learn p and q jointly, as explained in Section 3. We can then use q as a proposal distribution inside a Rao-Blackwellised particle filter ( Doucet et al., 2000 ), although in this paper, we just use a single posterior sample, as is common with Variational AutoEncoders ( VAEs, Kingma & Welling (2014) ; Rezende et al. (2014)). Although the above "trick" allows us efficiently perform inference and learning, we find that in challenging problems (e.g., when the dynamical model p(z t |z t−1 , v t ) is very flexible), the model ignores the discrete latent variables, and does not perform mode switching. This is a form of "posterior collapse", similar to VAEs, where powerful decoders can cause the latent variables to be ignored, as explained in  Alemi et al. (2018) . Our second contribution is a new form of posterior regularization, which prevents the aforementioned problem and results in a significantly improved segmentation. We apply our method, as well as various existing methods, to two previously proposed low- dimensional time series segmentation problems, namely a 1d bouncing ball, and a 2d moving arm. In the 1d case, the dynamics are piecewise linear, and all methods perform perfectly. In the 2d case, the dynamics are piecewise nonlinear, and we show that our method infers much better segmentation than previous approaches for comparable computational cost. We also apply our method to a simple new video dataset (see  fig. 1  for an example), and find that it performs well, provided we use our proposed regularization method. In summary, our main contributions are • Learning switching nonlinear dynamical systems parameterized with neural networks by marginalizing out discrete variables. • Using entropy regularization and annealing to encourage discrete state transitions. • Demonstrating that the discrete states of nonlinear models are more interpretable.

Section Title: RELATED WORK
  RELATED WORK In this section, we briefly summarize some related work.

Section Title: STATE SPACE MODELS
  STATE SPACE MODELS We consider the following state space model: where s t ∈ {1, . . . , K} is the discrete hidden state, z t ∈ R L is the continuous hidden state, and x t ∈ R D is the observed output, as in fig. 2(a). For notational simplicity, we ignore any observed inputs or control signals u t , but these can be trivially added to our model. Note that the discrete state influences the latent dynamics z t , but we could trivially make it influence the observations x t as well. More interesting are which edges we choose to add as parents of the discrete state s t . We consider the case where s t depends on the previous discrete state, s t−1 , as in a Under review as a conference paper at ICLR 2020 hidden Markov model (HMM), but also depends on the previous observation, x t−1 . We can trivially depend on multiple previous observations; we assume first-order Markov for simplicity. This means that state changes do not have to happen "open loop", but instead may be triggered by signals from the environment. We can also condition z t on x t−1 , and s t on z t−1 . It is straightforward to handle such additional dependencies (shown by dashed lines in fig. 2(a)) in our inference method, which is not true for some of the other methods we discuss below. We still need to specify the functional forms of the conditional probability distributions. In this paper, we make the following fairly weak assumptions: where f x,z,s are nonlinear functions (MLPs or RNNs), N (·, ·) is a multivariate Gaussian distribution, Cat(·) is a categorical distribution, and S(·) is a softmax function. R ∈ R D×D and Q ∈ R H×H are learned covariance matrices for the Gaussian emission and transition noise. If f x and f z are both linear, and p(s t |s t−1 ) is first-order Markov without dependence on z t−1 , the model is called a switching linear dynamical system (SLDS). If we allow s t to depend on z t−1 , the model is called a recurrent SLDS ( Linderman et al., 2017 ;  Linderman & Johnson, 2017 ). We will compare to rSLDS in our experiments. If f z is linear, but f x is nonlinear, the model is sometimes called a "structured variational autoencoder" (SVAE) ( Johnson et al., 2016 ), although that term is ambiguous, since there are many forms of structure. We will compare to SVAEs in our experiments. If f z is a linear function, the model may need to use lots of discrete states in order to approximate the nonlinear dynamics, as illustrated in fig. 1(d). We therefore allow f z (and f x ) to be nonlinear. The resulting model is called a switching nonlinear dynamical system (SNLDS), or Nonlinear Regime- Switching State-Space Model (RSSSM) ( Chow & Zhang, 2013 ). Prior work typically assumes f z is a simple nonlinear model, such as polynomial regression. If we let f z be a very flexible neural network, there is a risk that the model will not need to use the discrete states at all. We discuss a solution to this in Section 3.3. The discrete dynamics can be modeled as a semi-Markov process, where states have explicit durations (see e.g.,  Duong et al. (2005) ;  Chiappa (2014) ). One recurrent, variational version is the recurrent hidden semi-Markov model (rHSMM,  Dai et al. (2017) ). Rather than having a stochastic continuous variable at every timestep, rHSMM instead stochastically switches between states with deterministic dynamics. The semi-Markovian structures in this work have an explicit maximum duration, which makes them less flexible. A revised method, ( Kipf et al., 2019 ), is able to better handle unknown Under review as a conference paper at ICLR 2020 durations, but produces a potentially infinite number of distinct states, each with deterministic dynamics. The deterministic dynamics of these works may limit their ability to handle noise.

Section Title: VARIATIONAL INFERENCE AND LEARNING
  VARIATIONAL INFERENCE AND LEARNING A common approach to learning latent variable models is to maximize the evidence lower bound (ELBO) on the log marginal likelihood (see e.g.,  Blei et al. (2016) ). This is given by log p(x) ≤ L(x; θ, φ) = E q φ (z,s|x) [log p θ (x, z, s) − log q φ (z, s|x)] , where q φ (z, s|x) is an approximate posterior. 1 Rather than computing q using optimization for each x, we can train an inference network, f φ (x), which emits the parameters of q. This is known as "amortized inference" (see e.g.,  Kingma & Welling (2014) ). If the posterior distribution q φ (z, s|x) is reparameterizable, then we can make the noise independent of φ, and hence apply the standard SGD to optimize θ, φ. Unfortunately, the discrete distribution p(s|x) is not reparameterizable. In such cases, we can either resort to higher variance methods for estimating the gradient, such as REINFORCE, or we can use continuous relaxations of the discrete variables, such as Gumbel Softmax ( Jang et al., 2017 ), Concrete ( Maddison et al., 2017b ), or combining both, such as REBAR ( Tucker et al., 2017 ). We will compare against a Gumbel-Softmax version of SNLDS in our experiments. The continuous relaxation approach was applied to SLDS models in ( Becker-Ehmck et al., 2019 ) and HSSM models in ( Liu et al., 2018a ;  Kipf et al., 2019 ). However, the relaxation can lose many of the benefits of having discrete variables ( Le et al., 2019 ). Relaxing the distribution to a soft mixture of dynamics results in the Kalman VAE (KVAE) model of  Fraccaro et al. (2017) . A concern is that soft models may use a mixture of dynamics for distinct ground truth states rather than assigning a distinct mode of dynamics at each step as a discrete model must do. We will compare to KVAE in our experiments. In Section 3, we propose a new method to avoid these issues, in which we collapse out s so that the entire model is differentiable. The SVAE model of  Johnson et al. (2016)  also uses the forward-backward algorithm to compute q(s|v); however, they assume the dynamics of z are linear Gaussian, so they can apply the Kalman smoother to compute q(z|v). Assuming linear dynamics can result in over-segmentation, as we have discussed. A forward-backward algorithm is applied once to the discrete states and once to the continuous states to compute a structured mean field posterior q(z)q(s). In contrast, we perform approximate inference for z using one forward-backward pass and then exact inference for s using a second pass, as we explain in Section 3.

Section Title: MONTE CARLO INFERENCE
  MONTE CARLO INFERENCE There is a large literature on using sequential Monte Carlo methods for inference in state space models (see e.g.,  Doucet & Johansen (2011) ). When the model is nonlinear (as in our case), we may need a lot of particles to get a good approximation, which can be expensive. We can often get better (lower variance) approximations by analytically marginalizing out some of the latent variables; the resulting method is called a "Rao Blackwellised particle filter" (RBPF). Prior work (e.g.,  Doucet et al. (2001) ) has applied RBPF to SLDS models, leveraging the fact that it is possible to marginalize out p(z|s, v) using the Kalman filter. It is also possible to compute the optimal proposal distribution for sampling from p(s t |s t−1 , v) in this case. However, this relies on the model being conditionally linear Gaussian. By contrast, we marginalize out p(s|z, v), so we can handle nonlinear models. In this case, it is hard to compute the optimal proposal distribution for sampling from p(z t |z t−1 , v), so instead we use variational inference to learn to approximate this.

Section Title: METHOD
  METHOD

Section Title: INFERENCE
  INFERENCE We use the following variational posterior: q φ,θ (z, s|x) = q φ (z|x)p θ (s|z, x), where p θ (s|z, x) is the exact posterior (under the generative model) computed using the forward-backward algorithm, Under review as a conference paper at ICLR 2020 and q φ (z|x) is defined below. To compute q φ (z|x), we first process x 1:T through a bidirectional RNN, whose state at time t is denoted by h x t . (As noted in  Krishnan et al. (2017) , due to the Markov assumptions of our model, we only need a backward RNN to summarize x t:T , rather a bidirectional RNN to summarize x 1:T , but we use the latter for simplicity.) We then use a forward (causal) RNN, whose state denoted by h z t , to compute the parameters of q(z t |z 1:t−1 , x 1:T ), where the hidden state is computed based on h z t−1 and h x t . This gives the following approximate posterior: fig. 2(b) for an illustration. We can draw a sample z 1:T ∼ q φ (z|x) sequentially, and then treat this as "soft evidence" for the HMM model. The (sample dependent) parameters used in the forward-backward algorithm are given by which can be used to compute the gradients of the log likelihood, as we discuss below.

Section Title: LEARNING
  LEARNING The evidence lower bound (ELBO) for a single sequence x is given by Because q φ (z) is reparameterizable, we can approximate the gradient as follows: ∇ θ,φ L(θ, φ) ≈ ∇ θ,φ log p θ (x,z) − ∇ φ log q φ (z|x) (7) wherez is a sample from the variational proposalz ∼ q φ (z 1 |x 1:T ) T t=2 q φ (z t |z t−1 , x 1:T ). The second term can be computed by applying backpropagation through time to the inference RNN. In the appendix, we show that the first term is given by

Section Title: ENTROPY REGULARIZATION AND TEMPERATURE ANNEALING
  ENTROPY REGULARIZATION AND TEMPERATURE ANNEALING When using expressive nonlinear functions (e.g. an RNN or MLP) to model p(z t |z t−1 , s t ), we found that the model only used a single discrete state, analogous to posterior collpase in VAEs (see e.g.,  Alemi et al. (2018) ). To encourage the model to utilize multiple states, we add an additional regularizing term to the ELBO that penalizes the KL divergence between the state posterior at each time step and a uniform prior p prior (s t = k) = 1/K ( Burke et al., 2019 ). We call this a cross-entropy regularizer: Our overall objective now becomes Note that 0 ≤ L CE ≤ ∞, so we need to choose the scale of β > 0 appropriately. To further smooth the optimization problem, we apply temperature annealing to the discrete state transitions, as follows: p(s t = k|s t−1 = j, x t−1 ) = S( p(st=k|st−1=j,xt−1) τ ), where τ is the temperature. At the beginning stage of training, β, τ are set to large values. Doing so ensures that all states are visited, and can explain the data equally well. Over time, we reduce the regularizers to 0 and temperature to 1, according to a fixed annealing schedule; this allows clusters to start to separate (c.f., Rose (1998)), as each regime learns its own local dynamical model. The overall approach is similar to multi-step pretraining, as used in prior papers such as the rSLDS paper ( Linderman et al., 2017 ), but our approach works in a continuous end-to-end fashion.

Section Title: EXPERIMENTS
  EXPERIMENTS In this section, we compare our method to various other methods that have been recently proposed for time series segmentation using latent variable models. Since it is hard to evaluate unsupervised learning methods, such as segmentation, we use three synthetic datasets, where we know the ground truth. In each case, we fit the model to the data, and then estimate the most likely hidden discrete state at each time step,ŝ t = arg max q(s t |x 1:T ). Since the model is unidentifiable, the state labels have no meaning, so we post-process them by applying the best permutation over labels so as to maximize the F 1 score across frames. Here the F 1 score is the harmonic mean of precision and recall, 2 × precision × recall/(precision + recall), where precision is the percentage of the predictions that match the ground truth states, and recall is the percentage of the ground truth states that match the predictions. We also compute the switching-point F 1 by only considering the frames where the ground truth state changes. This measure compliments the frame-wise F 1 , because it measures the accuracy in time. Since matching the exact time of the switch point is very hard in the unsupervised setting with noisy observations, we also consider a detected change point as correct, if it occurs within some small temporal interval around the ground truth as noted in Section 4.3.

Section Title: 1D BOUNCING BALL
  1D BOUNCING BALL In this section, we use a simple dataset from  Johnson et al. (2016) . The data encodes the location of a ball bouncing between two walls in a one dimensional space. The initial position and velocity are random, but the wall locations are constant. We apply our SNLDS model to this data, where f x and f z are both MLPs. We found that regularization was not necessary in this experiment. We also consider the case where f x and f z are linear (which corresponds to an SLDS model), the rSLDS model of  Linderman et al. (2017) , the SVAE model of  Johnson et al. (2016) , the Kalman VAE (KVAE) model of  Fraccaro et al. (2017)  and a Gumbel- Softmax version of SNLDS as described in Appendix A.2. We use the implementations of rSLDS, SVAE, and KVAE provided by the authors. As the data is generated by a simple piece-wise linear dynamics and all models we tested learn a perfect segmentation, as shown in Figure 3(a) and  Table 1 . This serves as a "sanity check" that we are able to use and implement the rSLDS, SVAE, KVAE and Gumbel-Softmax SNLDS code correctly. (See also Appendix A.3 for further analysis.) Note that the "true" number of discrete states is just 2, encoding whether the ball is moving up or down. We find that our method can learn to ignore irrelevant discrete states if they are not needed. This is presumably because we are maximizing the marginal likelihood since we sum over all hidden states, and this is known to encourage model simplicity due to the "Bayesian Occam's razor" effect ( Murray & Ghahramani, 2005 ). By contrast, with the other methods, we had to be more careful in setting K.

Section Title: 2D REACHER TASK
  2D REACHER TASK In this section, we consider a dataset proposed in the CompILE paper ( Kipf et al., 2019 ). The observations are sequences of 36 dimensional vectors, derived from the 2d locations of various static objects, and the 2d joint locations of a moving arm (see Appendix A.4 for details and a visualization). The ground truth discrete state for this task is the identity of the target that the arm is currently reaching for (i.e., its "goal"). We fit the same 6 models as above to this dataset. Since it is a much harder problem, we found that we needed to add regularization to our model to encourage it to switch states. Figure 3(b) visualizes the resulting segmentation (after label permutation) for a single example. We see that our SNLDS model matches the ground truth more closely than our SLDS model, as well as the rSLDS, SVAE, KVAE, and Gumbel-Softmax baselines. To compare performance quantitatively, we evaluate the models from 5 different training runs on the same held-out dataset of size 32, and compute the F 1 scores. We also report the F 1 number from CompILE. The CompILE paper uses an iterative segmentation scheme that can detect state changes, Under review as a conference paper at ICLR 2020 but it does infer what the current latent state is, so we cannot include it in Figure 3(b). As in  Table 1 , we find that our SNLDS method is significantly better than the other approaches.

Section Title: IMAGE DATASET (DUBINS PATH)
  IMAGE DATASET (DUBINS PATH) In this section, we apply our method to a new dataset that is created by "rendering" a point moving in the 2d plane. The motion follows the Dubins model 2 , which is a simple model for piece-wise nonlinear (but smooth) motion that is commonly used in the fields of robotics and control theory because it corresponds to the shortest path between two points that can be traversed by wheeled robots, airplanes, etc. In the Dubins model, the change in direction is determined by an external control signal u t . We replace this with three latent discrete control states: go straight, turn left, and turn right. These correspond to fixed, but unobserved, input signals u t (see Appendix A.5 for details). After generating the motion, we create a series of images, where we render the location of the moving object as a small circle on a white background. Our goal in generating this dataset was to assess how well we can recover latent dynamics from image data in a very simple, yet somewhat realistic, setting. The publicly released code for rSLDS and SVAE does not support high dimensional inputs like images (even though the SVAE has been applied to an image dataset in  Johnson et al. (2016) ), and there is no public code for CompILE. Therefore we could not compare to these methods for this experiment. Also, since we already showed in Section 4.2 that our method is much better than these Under review as a conference paper at ICLR 2020 approaches, as well as Kalman VAE and Gumbel-Softmax version of SNLDS, on the simpler reacher task, we expect the same conclusion to hold on the harder task of segmenting videos. Instead we focus on comparing SNLDS with SLDS to see the advantage of allowing each regime to be represented by a nonlinear model. The results of segmenting one sequence with these models using 5 states are shown in  Figure 1 . We see that the SLDS model has to approximate the left and right turns with multiple discrete states, whereas the non-linear model learns a more interpretable representation. We again compare the models using F 1 scores in  Table 2 . Because the SLDS model used too many states, we calculated two versions of the metric. The first was a greedy metric that optimally assigned the best single state to match the ground truth. The second used an oracle to optimally merge states to match the ground truth. The SNLDS model significantly outperforms the SLDS in both scenarios.

Section Title: ANALYSIS OF THE ANNEALING SCHEDULE
  ANALYSIS OF THE ANNEALING SCHEDULE Many latent variable models are trained in multiple stages, in order to avoid getting stuck in bad local optima. For example, to fit the rSLDS model,  Linderman et al. (2017)  firstly pretrain an AR-HMM and SLDS model, and then merge them; similarly, to fit the SVAE model,  Johnson et al. (2016)  first train with a single latent state and then increase K. We found a similar strategy was necessary for the Reacher and Dubins tasks, but we do this in a smooth way using annealed regularizations. Early in training, we train with large temperature τ and entropy coefficient β. This encourages the model to use all states equally, so that the dynamics, inference, and emission sub-networks stabilized before beginning to learn specialized behavior. We then anneal the entropy coefficient to 0, and the temperature to 1 over time. We found it best to first decay the entropy coefficient β and then decay the temperature τ .  Figure 4  demonstrates the effect of 3 different annealing schedules on the relative log likelihood (defined as L t − L min , where L min = min t L t;1,2,3 across all three runs, and L t is the negative log-likelihood.), and the F 1 score. The green curve starts annealing right away; we see the F 1 score Under review as a conference paper at ICLR 2020 is flat, since only one discrete state is used. The red curve starts annealing later, which improves F 1 . However, the best results are shown in the blue curve, which starts the decay even later. On real problems, where we have no ground truth, we cannot use the F 1 score as a metric to determine the best annealing schedule. However, it seems that the schedules that improve F 1 the most also improve likelihood the most.

Section Title: CONCLUSION
  CONCLUSION We have demonstrated that our proposed method can effectively learn to segment high dimensional sequences into meaningful discrete regimes. Future work includes applying this to harder image sequences, and to hierarchical reinforcement learning.
  In the case of sequential models, we can create tighter lower bounds using methods such as FIVO ( Maddison et al., 2017a ), although this is orthogonal to our work.

```
