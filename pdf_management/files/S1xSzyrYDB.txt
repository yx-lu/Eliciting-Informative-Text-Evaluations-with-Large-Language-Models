Title:
```
Under review as a conference paper at ICLR 2020 CYCLIC GRAPH DYNAMIC MULTILAYER PERCEPTRON FOR PERIODIC SIGNALS
```
Abstract:
```
We propose a feature extraction for periodic signals. Virtually every mechanized transportation vehicle, power generation, industrial machine, and robotic system contains rotating shafts. It is possible to collect data about periodicity by mea- suring a shaft's rotation. However, it is difficult to perfectly control the collection timing of the measurements. Imprecise timing creates phase shifts in the resulting data. Although a phase shift does not materially affect the measurement of any given data point collected, it does alter the order in which all of the points are col- lected. It is difficult for classical methods, like multi-layer perceptron, to identify or quantify these alterations because they depend on the order of the input vectors' components. This paper proposes a robust method for extracting features from phase shift data by adding a graph structure to each data point and constructing a suitable machine learning architecture for graph data with cyclic permutation. Simulation and experimental results illustrate its effectiveness.
```

Figures/Tables Captions:
```
Figure 1: Graph dynamic multilayer perceptron (GDMLP).
Figure 2: (a): Two waves with a phase shift. The above wave x represented by xt = sin 2πt 100 + 0.3 sin 16πt 100 with 0 ≤ t ≤ 140 and the below x ′ is phase shifted wave of x with 30 delay. (b): The graphs obtained from the left waves by the operation in Section 2.2 with ws = 20, ss = 15, euclidean distance as d and ε = 4.5. (c): The subgraphs of the left graphs whose are equivalence up to cyclic order of vertices.
Figure 3: Cyclic graph dynamic multilayer perceptron (CGDMLP).
Figure 4: Learning Architecture.
Figure 5: (a): Periodic noise, (b): Non-periodic noise.
Figure 6: Experimental test setup.
Figure 7: Learning Model for the Test Setup Data.
Table 1: Validation set accuracy for simple periodic data.
Table 2: Result of each classification method.
```

Main Content:
```

Section Title: INTRODUCTION
  INTRODUCTION Understanding what phenomena, a rotating shaft is experiencing is critical for machine health mon- itoring. From industrial manufacturing equipment, transportation systems, to consumer products, rotating shafts are in many mechanical devices. Many issues such as long-term fatigue, wear related issues, and acute failures can cause symptoms that are detectable from the shaft. The effort and flow variables associated with the shaft are desirable state variables to measure in nearly all these cases mentioned. Although these physical variables may provide useful information for detecting anomalies and estimating symptoms, one should extract features hidden in these signals. Therefore, an efficient feature extraction method plays an important role in anomaly detection and symptoms recognition. Deep learning networks achieved remarkable results compared to the traditional methods. The time- frequency analysis, such as the short-time Fourier transform  Xie et al. (2012)  and the wavelet trans- form  YanPing et al. (2006) ;  Al-Badour et al. (2011) , are well known feature extraction methods. For example, one can detect a certain bending mode by paying attention to the resonance frequency. Namely, domain knowledge expertise is needed to extract features from a time-frequency represen- tation associated with particular phenomena. Some deep convolutional neural network (CNN) ar- chitectures achieved good results by taking time-frequency images as inputs  Verstraete et al. (2017) ;  Guo et al. (2018) . Although many machine learning methods with preprocessing schemes were used to extract signal features, many of them do not really consider the specific characteristics of signals. For example, the output from a general CNN is compressed by pooling regardless of time or frequency direction. A method that considers the relative order information of signals is necessary. Classical methods, such as multi-layer perceptron (MLP), regard signals as vectors and accordingly use vectors as in- puts. However, a vector does not give relationship information that might exist between coordinates. Therefore, while classical methods can measure data points, it is difficult to detect whether they are in proper order relative to each other. This could occur due to pooling even if the signal is converted into an image by some method and input to the CNN. The relative order is very important to classify them. For example, the data obtained from a rotating machinery is periodic as in  Figure 5 . Figure 5a shows noise associated with the rotation period, and so it is related to a rotation anomaly such as a crack in a gear. However, Figure 5b shows noise that is different from the rotation period, and Under review as a conference paper at ICLR 2020 thus there is a possibility that it is not related to rotation, but perhaps an abnormality of the sensor system. Even with a classical method, it is possible to classify them if such data are included in the training data. However industrial machines would require significant time and cost to run the nec- essary experiments for collecting data. If the abnormality to be detected was rare, then the required effort would be magnified. The proposed method to solve this problem, considers a graph structure for each data point. This scheme provides a relative order information about the vector coordinates. It then applies a graph neural network, such as  Atwood & Towsley (2016) ;  Kipf & Welling (2017) , to the graph structured data. For example, the relative information can be obtained by calculating cross-correlations be- tween the points. Since some deep learning approaches achieved results by concatenating different numerical sequences such as different sensor signals and treating them as inputs, we can concate- nate the original sensor signal with the cross-correlations. This defines the relative information, and treat it as an input. However it is not natural to treat them in the same way by simply concatenating them because the sensor signal represents a physical value and the cross-correlation represents their relationship. Hence, the essential meaning is different. We deal with these different values simul- taneously by using a graph structure that represents each point and their relationships. Then, the obtained graph data is fed to a graph neural network for feature extraction. This enables the system to learn by focusing on the relative relationship of each coordinate of the data point. The main reason for using a graph structure is to give data additional information. The time- frequency representation simply converts the original signals to other forms. Inspired by the success of CNN in computer vision,  Wang & Oates (2015) ;  Zhu et al. (2019)  proposed encoding time series as different types of images using methods other than time-frequency analysis and inputting them into CNN.  Umeda (2017)  proposed a method of converting the original signals to high dimensional data cloud. While they are all categorized as information conversions, conversions meaning that they do not add any other information, we add relationship information as edges to the original signals, thus the graph hold richer information than the original signal and its conversions. A key feature of the method is phase shift invariance. The application of our current research is for industrial machines with rotating shafts. Virtually every mechanized transportation vehicle, power generation, industrial machine, and robotic system contains rotating shafts. The shafts provide an opportunity to collect periodic signals. In practice, most measuring instruments such as sensors, processors and loggers along with their data acquisition systems show time delay respectively in the availability of the data. There is a limitation to correct the delays by hardware design or implemen- tation. Hence, phase shifts may occur in the obtained periodic signals. However, these phase shifted signals are essentially the same. We identify them using a shift invariance method. Our proposed method performs a cyclic permutation to a graph neural network. This method assures that the results account for phase shift of the periodic measurements. It is not necessary to consider the vertex order in the graph originally, but it is necessary to give the order for computability. Here, we identify the graphs whose vertex orders are different due to phase shifts. The conventional graph neural networks regard them different. Therefore, we propose a method that intentionally focuses on shift invariance by acting a cyclic permutation to a graph neural network. The use of this method in Section 3 shows that it offers predictions with sufficient accuracies for idealized data and the experimental data obtained from a test setup  Gest et al. (2019) .

Section Title: MACHINE LEARNING METHODOLOGY
  MACHINE LEARNING METHODOLOGY In this section, we define our machine learning method. First we introduce necessary terminology to review the graph theory. Then we describe the method of constructing a graph structure for each data point, and introduce the learning model corresponding to the graph data. Finally we extend the learning model to periodic data.

Section Title: NOTATION AND TERMINOLOGY OF GRAPHS
  NOTATION AND TERMINOLOGY OF GRAPHS The notation and terminology of graphs is as follows. Let G be a graph. We denote the vertex set and the edge set of G by the symbol V (G) and E(G). A simple graph is a graph containing no graph loops or multiple edges. A complete graph is a graph in which each pair of graph vertices is connected by an edge. An ordered graph is a graph with a total order over its vertices. If a graph Under review as a conference paper at ICLR 2020 G is ordered with |V (G)| = N , then we regard V (G) as an ordered set {v i } 1≤i≤N . The adjacency matrix A(G) of a simple ordered graph G is a matrix with rows and columns labeled by graph vertices, with a 1 or 0 in position (v i , v j ) according to whether the vertices v i and v j are connected by an edge or not, respectively. For a graph G, a vertex labeling is a function from V (G) to a set of labels. A graph with such a function defined is called a vertex-labeled graph. For a vertex-labeled graph G, we denote the vertex labeling by the symbol L(G). Unless otherwise stated we assume that graphs are simple ordered graphs labeled by real numbers.

Section Title: CONSTRUCTION OF GRAPH STRUCTURE
  CONSTRUCTION OF GRAPH STRUCTURE Now we construct a graph structure on each data point. Let x be a data point, namely, x be an N - dimensional real vector (x 1 , x 2 , . . . , x N ) for some integer N . For simplicity of notation, we write (x i ) 1≤i≤N instated of (x 1 , x 2 , . . . , x N ). Fix integers ws and ss with 1 ≤ ws, ss ≤ N , we call these a window size and a slide size. Let ⌊·⌋ be the floor function, namely ⌊a⌋ := max{n ∈ Z | n ≤ a}. Then we obtain the following N ′ -length sequence of ws-dimensional real vectors {v i }, where We fix a real number ε and a distance function d on the ws-dimensional real vector space, such as the Euclidean distance or the correlation distance. Then we can define a graph G as follows: If the slide size and the window size are small enough, then maximum, minimum and mean work the same as a projection for the labeling function. However, in our case, vertices should be at least one period sub-waves because we construct edges by their similarity. Then max and min become constant values for every vertex. Also, periodically the window size becomes equal to a constant multiple of the period because our experimental data consists of many different frequencies. Then the mean becomes the same value for every vertex. Therefore, we use the projection as a vertex labeling in this paper.

Section Title: LEARNING MODEL FOR GRAPH DATA
  LEARNING MODEL FOR GRAPH DATA Here we define our machine learning model suitable for graph data set. Our model draws inspiration from recent work on a graph neural network ( Kipf & Welling, 2017 ). However, they consider the problem of classifying vertices of a graph by sharing filter parameters for each vertex and treat all vertices equal. On the other hand, since we consider graph-wise feature extraction and the vertices of our graph have time information as index, we think that it is not suitable to treat the vertices in the same way. Therefore, we avoid weight sharing by using the Hadamard product as shown below. Set an integer N . Let G N be a set of graphs with N -vertices. Set an integer M , which is a number of hidden layers. We take a finite sequence of N -by-N matrices {W m } 0≤m≤M , called trainable weights, and a finite sequence of N -dimensional real vectors {b m } 0≤m≤M , called trainable bias. Then we define a function ϕ from G N to R N as follows: ϕ(G) = L M +1 , where, L 0 is the image of the labeling function L(G)(V (G)), Here,Ã(G) = A(G) + I N with the rank N identity matrix I N and τ is an activation function, such as the ReLU, and · means the matrix product and • means the Hadamard product. Graph neural networks usually use the Laplacian asÃ(G), but our experimental results were almost the same, so we usedÃ(G) = A(G) + I N instead. This turned out to be simpler than the Laplacian. This function can be regarded as a natural extension of a multi-layer perceptron (MLP) obtained by admitting a graph structure on each data point. In fact, our function on the complete graph G, namely all the elements ofÃ(G) are 1, is equal to a MLP. Hence we call this function a graph dynamic multi-layer perceptron (GDMLP).

Section Title: EXTENSION OF LEARNING MODEL TO PERIODIC DATA
  EXTENSION OF LEARNING MODEL TO PERIODIC DATA In this section, we extend the above learning model to another model which is suitable for periodic data. We consider its application to data obtained from industrial machineries containing rotating shafts. Accordingly each data point x = (x i ) 1≤i≤N obtained from them is periodic defined as follows. Let T be the sampling interval, that is time between which data is recorded. Then x = (x i ) 1≤i≤N is periodic if there exists a period T x = n x T with a positive integer n x such that x i = x j if i ≡ j mod n x . On the other hand, it is difficult to perfectly control the collection timing of these data points because there is a limitation to correct the delays by hardware design or implementation. To account for this the data includes a phase shift x ′ = (x ′ i ) 1≤i≤N of x, namely, for periodic data points x and x ′ with a period T x = T x ′ = nT , there is a delay T (x,x ′ ) = n (x,x ′ ) T with an integer n (x,x ′ ) such that x i = x ′ j−n (x,x ′ ) if i ≡ j − n (x,x ′ ) mod n. A period and a delay are multiples of the sampling interval T . This is a practical limitation and not a theoretical limitation. In general, sensor measurements are discrete in time. The sampling interval T is the minimum interval when the sensor actually measures. Although we use this notation to clarify this practical limitation, sampling interval T is not a limitation in the theoretical claim (see the appendix for details). Although phase shift data points are different as vectors, the graphs obtained from them by the operation in Section 2.2 have "large" equivalent induced subgraphs up to cyclic order of vertices. To state more precisely we make the following definition; pick a N -vertices graph G. Let {v i } 1≤i≤N be a vertex set V (G). Let σ be a cyclic permutation on V (G) such that σ(v i ) = v i+1 . Then the cyclic permutated graph σ(G) of G is defined as follows: Under review as a conference paper at ICLR 2020 Let x and x ′ be phase shift data points. They are different as vectors (see Figure 2a). Hence the graphs G x , G x ′ obtained from them by the operation in Section 2.2 are not equivalent as ordered graphs (see Figure 2b). However, most of them produce identical vertices to each other up to cyclic order (see Figure 2c). In fact we can prove the following claim. Claim . Let x and x ′ be phase shifted data points with period T x = T x ′ = nT , and delay T (x,x ′ ) = n (x,x ′ ) T . Assume that x and x ′ is more than 3 periods, namely, |x| = |x ′ | ≥ kn for an integer k ≥ 3. Then there exists a window size ws and a slide size ss satisfying the following condition. For graphs G x and G x ′ which obtained from x and x ′ by the operation in Section 2.2, there exists an integer K (x,x ′ ) such that both of G x and σ K (x,x ′ ) (G x ′ ) have a induced ordered subgraph We provide a proof of the claim in the appendix. By the claim, it is expected that the GDMLP outputs of G x and σ K (x,x ′ ) (G x ′ ) will be approximately the same. For the above reason, we improve a GDMLP with a cyclic order as shown in  Figure 3 . We fix a GDMLP model ϕ on G N . Then we define a function Φ ϕ from G N to R N as follows:

Section Title: LEARNING ARCHITECTURE
  LEARNING ARCHITECTURE Since a GDMLP is a feature extraction of the graph vertex labels, it is necessary to compose a function with a GDMLP according to the final processing to be performed, such as a classification or a regression. Our main purpose is to extract similar features from phase shifted signals. In our experiments, we confirm the performance of the proposed feature extraction by checking the difference in accuracy with others. And this is independent of the classifier used. Therefore we compose a MLP with a GDMLP, which is a simple method. The MLP input layer consists of the same number of perceptrons as the dimension of the GDMLP output. Its output layer and the hidden layer is optimized according to the sophistication of the problem, such as the number of classifications desired. Similarly, in the case of a CGDMLP, we compose tailored a MLP according to the output desired (see  Figure 4 ). For simplicity of notation, we use the same letter GDMLP and CGDMLP for the learning architecture whose feature extraction part are the feature extraction GDMLP and CGDMLP respectively.

Section Title: EXPERIMENTS
  EXPERIMENTS We now give an example where we compare our method for analyzing periodic data.

Section Title: IDEAL DATA
  IDEAL DATA First, we apply our method to idealized data that abstracts the problem we are considering, such as a crack in a shaft, sensor malfunction, or external force that would impede mechanical rotation. The first of these would typically cause periodic noise, and the last two non-periodic noise. Reports of noises and their recurrence from a sensor, then, can be used to diagnose each of those and other issues. Our proposed method, which adds a graph structure to each data point to give a relative in- formation, should effectively make such a diagnosis. Also, because our proposed CGDMLP is with a focus on cyclic order invariance, it is expected that phase shift signals can be identified because they produce approximately the same outputs in either unshifted or differently shifted signals. Based on the above, we compare the classification result of each method for noisy sine waves (x t ) 1≤t≤T with some integer T defined as follows: x t = sin(2πf (t/T − t 0 )) + ϵ + δ f , where f is the frequency, t 0 is a phase shift, ϵ is a random noise from a uniform distribution over the half open interval [−0.05, 0.05) and δ f is periodic or non-periodic noise (see  Figure 5 ). Set the frequency f to three types, 3, 6 and 9. We then execute (x t ) 1≤t≤T over the range of ϵ six times, once per each combination of frequency and periodic vs. non-periodic noise. Verification is performed with and without phase shift t 0 . The validation set size for each result is fixed at 100. We train with several training set sizes, as shown in  Table 1 . The architecture used for comparison is the architecture GDMLP and CGDMLP defined in Section 2.5. In addition, we use the architecture MLP and CMLP which are fully-connected networks ob- tained from GDMLP and CGDMLP by replacing all the elements ofÃ(G) with 1 respectively. We set the learning rate based on the LR range test (see Section 3.3 in  Smith (2017) ). The results are summarized in  Table 1 . Our main purpose is to extract similar features from phase shifted signals. We focused on the difference in accuracy with other methods. In the middle and the bottom of  Table 1  including phase shifted signals, when the training set size per class is 10, the difference in accuracy is higher than 30 %. It indicates that the proposed method can be performed with a small experimental dataset with phase shifts. On the other hand, the bottom third of  Table 1  shows that the training data does not include phase shifted signals, however the proposed method performs acceptable with the validation set which includes unknown delays in signals. This could be considered as generalization performance when applied to phase shifted signals.

Section Title: VALIDATION WITH REAL DATA
  VALIDATION WITH REAL DATA

Section Title: TEST SETUP
  TEST SETUP In order to validate our model on a real-world dataset, we use data obtained from the test setup  Gest et al. (2019)  as shown in  Figure 6 . The shaft is attached at both ends to brushed DC motors by compliant couplers. One motor, the driving motor, is connected to a power supply and electronic speed control and is controlled by a computer. The controls permit electrical current to the motor at any of five discrete voltage levels. The second motor, the damping motor, is attached to a resistor array to create a variable rotary damper. In the resistor array, relays are used connect and bypass individual resisters. The possible combinations allow for sixteen discrete levels of resistance. Five different weights of different masses and sizes are attached to the shaft to simulate the shaft bending, a possible real-world anomaly. Tests are also run and data collected with no weights attached. The sensors mounted on the shaft collect triaxial acceleration and strain, and audio data is collected with an external microphone. We collect a total of 400 cases of data from the above discrete variables. Each case consists of 50 data points. Each data point consists of 1.5 seconds signals. This time width is set to collect at least three rotations at the minimum rotation speed of 120 rpm. Due to the computational cost, each data point is downsampled to consist of 150 points.

Section Title: CONSTRUCT MODELS FOR THE TEST SETUP DATA
  CONSTRUCT MODELS FOR THE TEST SETUP DATA To confirm the performance of the proposed feature extraction, we construct classification models to estimate the shaft bending. We use the measurements of tangental acceleration, radial acceleration and strain, as input by permutation importance (see  Altmann et al. (2010) ,  Breiman (2001) ).

Section Title: Under review as a conference paper at ICLR 2020
  Under review as a conference paper at ICLR 2020 The basic architecture is the one defined in Section 2.5, but this time there are three types of sensor signals used for input, so each feature is extracted in parallel and the outputs concatenation is input to the multi-layer perceptron, which is a classifier (see  Figure 7 ). As in Section 3.1, for comparison we use GDMLP and CGDMLP, and MLP and CMLP which are fully-connected networks obtained from GDML and CGDMLP respectively. In the preprocessing part each of the above three sensors data are converted to the graph data by the operation introduced in Section 2.2 with the following parameters. The window size ws is set to 50, which is set to include at least one period at minimum rotation speed of 120 rpm. The slide size ss is set to 3, which is set to be smaller than one period at the maximum rotation speed of 1200 rpm. We set the distance function d the correlation distance and ε = 0.3, namely, a pair of vertices are connected if they have a strong positive linear relationship. We set the learning rates in this instance based on the LR range test as in Section 3.1 and we use a grid search optimization method for other parameters.

Section Title: RESULTS
  RESULTS   Table 2  shows the resulting accuracy of each method. There are only 60 samples in each case of the experimental data. For this limited data, our proposed method achieves sufficiently higher accuracy than either of the based methods MLP and CMLP. Of the proposed methods CGDMLP in particular achieves the highest accuracy. We suggest that our methods would be superior even with limited data since relative order information on the time axis was assigned here. We further suggest that CDGMLP, especially, would be superior even when evaluating data sets that include phase shift because our proposed CGDMLP is with a focus on cyclic order invariance.

Section Title: CONCLUSION
  CONCLUSION In this paper, we proposed a machine learning method for analyzing periodic data by admitting a graph structure to each data point and constructing a machine learning model according to the characters of the graph structure and the original data. Another point of importance is that adding a certain structure to data is shown to be very effective for feature extraction. The paper demonstrates experimentally the effectiveness of adding a graph structure to the data.

Section Title: A APPENDIX
  A APPENDIX We give a proof of the claim in Section 2.4. First we recall the claim. Claim . Let x and x ′ be phase shifted data points with period T x = T x ′ = nT , and delay T (x,x ′ ) = n (x,x ′ ) T . Assume that x and x ′ is more than 3 periods, namely, |x| = |x ′ | ≥ kn for an integer k ≥ 3. Then there exists a window size ws and a slide size ss satisfying the following condition. For graphs G x and G x ′ which obtained from x and x ′ by the operation in Section 2.2, there exists an integer K (x,x ′ ) such that both of G x and σ K (x,x ′ ) (G x ′ ) have a induced ordered subgraph Proof. If n = 1, it implies that x and x ′ are constant sequences. Thus we assume n ≥ 2. Let n ′ (x,x ′ ) be the remainder when n (x,x ′ ) is divided by n. By the definition of periodic and delay, we have x 0 = x ′ n ′ (x,x ′ ) as follows: Similarly, we have x ′ 0 = x n−n ′ (x,x ′ ) . Note that n ′ (x,x ′ ) < n by the definition of the remainder. If n ′ (x,x ′ ) ≥ n/2, then n − n ′ (x,x ′ ) < n/2. Thus, we can assume that there is an integer m (x,x ′ ) < n/2 such that x m (x,x ′ ) = x ′ 0 by replacing x and x ′ if needed. Then x and x ′ have a continuous subsequence s such that |s| > (k − 1)n. Set ws < |s| − km (x,x ′ ) and let ss be a divisor of m (x,x ′ ) . Note that we have |s| − km (x,x ′ ) > 1 as follows: Hence we can define ws satisfying ws < |s| − km (x,x ′ ) . Since ss is a divisor of m (x,x ′ ) , for each i > m (x,x ′ ) /ss, the vertex v i of G x is equivalent to some vertex v ′ j of G x ′ . Let S (x,x ′ ) be the equivalent induced subgraphs consists of the above vertices. Since the graph G x is obtained by the operation in Section 2.2 and ss is a divisor of m (x,x ′ ) , we have |V (G)| = |S (x,x ′ ) |+m (x,x ′ ) /ss and |S (x,x ′ ) | = ⌊(|s|−ws)/ss⌋. Since we set ws < |s|−km (x,x ′ ) and ss is a divisor of m (x,x ′ ) , we have |S (x,x ′ ) | ≥ ⌊km (x,x ′ ) /ss⌋ = km (x,x ′ ) /ss. Then we have |S (x,x ′ ) |/|V (G)| ≥ k/(k + 1) as follows: Then m (x,x ′ ) /ss is the desired integer K (x,x ′ ) .

```
