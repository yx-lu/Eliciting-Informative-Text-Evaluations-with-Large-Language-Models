Title:
```
Under review as a conference paper at ICLR 2020 MIN-MAX OPTIMIZATION WITHOUT GRADIENTS: CONVERGENCE AND APPLICATIONS TO ADVERSAR- IAL ML
```
Abstract:
```
In this paper, we study the problem of constrained robust (min-max) optimization in a black-box setting, where the desired optimizer cannot access the gradients of the objective function but may query its values. We present a principled optimization framework, integrating a zeroth-order (ZO) gradient estimator with an alternating projected stochastic gradient descent-ascent method, where the former only requires a small number of function queries and the later needs just one-step descent/ascent update. We show that the proposed framework, referred to as ZO-Min-Max, has a sub-linear convergence rate under mild conditions and scales gracefully with problem size. From an application side, we explore a promising connection between black-box min-max optimization and black-box evasion and poisoning attacks in adversarial machine learning (ML). Our empirical evaluations on these use cases demonstrate the effectiveness of our approach and its scalability to dimensions that prohibit using recent black-box solvers.
```

Figures/Tables Captions:
```
Figure 1: Convergence performance of ZO-Min-Max in design of black-box ensemble attack. a) Stationary gap of ZO-Min-Max vs. FO-Min-Max, b) attack loss of using ZO-Min-Max vs. FO-Min-Max, and c) attack loss of using ZO-Min-Max vs. ZO-Finite-Sum.
Figure 2: Empirical performance of ZO-Min-Max in design of poisoning attack: a) stationary gap versus iterations b) testing accuracy versus iterations (the shaded region represents variance of 10 random trials), and c) testing accuracy versus data poisoning ratio.
Figure 3: Comparison between ZO- Min-Max and STABLEOPT on testing accuracy versus optimization time.
```

Main Content:
```

Section Title: INTRODUCTION
  INTRODUCTION In numerous real-world applications, one is faced with various forms of adversary that are not accounted for by standard optimization algorithms. For instance, when training a machine learning model on user-provided data, malicious users can carry out a data poisoning attack: providing false data with the aim of corrupting the learned model (Steinhardt et al., 2017; Tran et al., 2018; Jagielski et al., 2018). At inference time, malicious users can evade detection of multiple models in the form of adversarial example attacks (Goodfellow et al., 2014; Liu et al., 2016; 2018a). Min-max (robust) optimization is a natural framework to address adversarial (worst-case) robustness (Madry et al., 2017b; Al-Dujaili et al., 2018b). It converts a standard minimization problem into a composition of an inner maximization problem and an outer minimization problem. Min-max optimization problems have been studied for multiple decades (Wald, 1945), and the majority of the proposed methods assume access to first-order (FO) information, i.e. gradients, to find or approximate robust solutions (Nesterov, 2007; Gidel et al., 2017; Hamedani et al., 2018; Qian et al., 2019; Rafique et al., 2018; Sanjabi et al., 2018b; Lu et al., 2019; Nouiehed et al., 2019; Lu et al., 2019; Jin et al., 2019). In this paper, we focus on design and analysis of black-box (gradient-free) min-max optimization methods, where gradients are neither symbolically nor numerically available, or they are tedious to compute (Conn et al., 2009). Our study is particularly motivated by the design of data poisoning and evasion adversarial attacks from black-box machine learning (ML) or deep learning (DL) systems, whose internal configuration and operating mechanism are unknown to adversaries. The extension of min-max optimization from the FO domain to the gradient-free regime is challenging since the solver suffers from uncertainties in both black-box objective functions and optimization procedure and do not scale well to high-dimensional problems. We develop a provable and unified black-box min-max stochastic optimization method by integrating a query-efficient randomized zeroth-order (ZO) gradient estimator with a computation-efficient alternating gradient descent-ascent framework, where the former requires a small number of function queries to build a gradient estimate, and the latter needs just one-step descent/ascent update. Recently, ZO optimization has attracted increasing attention in solving ML/DL problems. For example, ZO optimization serves as a powerful and practical tool for generation of black-box adversarial examples Under review as a conference paper at ICLR 2020 to evaluate the adversarial robustness of ML/DL models (Chen et al., 2017; Ilyas et al., 2018; Tu et al., 2018; Ilyas et al., 2019). ZO optimization can also help to solve automated ML problems, where the gradients with respect to ML pipeline configuration parameters are intractable (Aggarwal et al., 2019). Furthermore, ZO optimization provides computationally-efficient alternatives of high-order optimization methods for solving complex ML/DL tasks, e.g., robust training by leveraging input gradient or curvature regularization (Finlay & Oberman, 2019; Moosavi-Dezfooli et al., 2019), model- agnostic meta-learning (Fallah et al., 2019), network control and management (Chen & Giannakis, 2018), and data processing in high dimension (Liu et al., 2018b). Other recent applications include generating model-agnostic contrastive explanations (Dhurandhar et al., 2019) and escaping saddle points (Flokas et al., 2019). Current studies (Ghadimi & Lan, 2013; Nesterov & Spokoiny, 2015; Duchi et al., 2015; Ghadimi et al., 2016; Shamir, 2017; Liu et al., 2019) suggested that ZO methods typically agree with the iteration complexity of FO methods but encounter a slowdown factor up to a small-degree polynomial of the problem dimensionality. To the best of our knowledge, it was an open question whether any convergence rate analysis can be established for black-box min-max optimization.

Section Title: Contribution
  Contribution We summarize our contributions as follows. (i) We first identify a class of black-box attack and robust learning problems which turn out to be min-max black-box optimization problems. (ii) We propose a scalable and principled framework (ZO-Min-Max) for solving constrained min- max saddle point problems under both one-sided and two-sided black-box objective functions. Here the one-sided setting refers to the scenario where only the outer minimization problem is black-box. (iii) We provide a novel convergence analysis characterizing the number of objective function evaluations required to attain locally robust solution to black-box min-max problems with nonconvex outer minimization and strongly concave inner maximization. Our analysis handles stochasticity in both objective function and ZO gradient estimator, and shows that ZO-Min-Max yields O(1/T + 1/b + d/q) convergence rate, where T is number of iterations, b is mini-batch size, q is number of random direction vectors used in ZO gradient estimation, and d is number of optimization variables. (iv) We demonstrate the effectiveness of our proposal in practical data poisoning and evasion attack generation problems. 1

Section Title: RELATED WORK
  RELATED WORK FO min-max optimization. Gradient-based methods have been applied with celebrated success to solve min-max problems such as robust learning (Qian et al., 2019), generative adversarial networks (GANs) (Sanjabi et al., 2018a), adversarial training (Al-Dujaili et al., 2018b; Madry et al., 2017a), and robust adversarial attack generation (Wang et al., 2019b). Some of FO methods are motivated by theoretical justifications based on Danskin's theorem (Danskin, 1966), which implies that the negative of the gradient of the outer minimization problem at inner maximizer is a descent direction (Madry et al., 2017a). Convergence analysis of other FO min-max methods has been studied under different problem settings, e.g., (Lu et al., 2019; Qian et al., 2019; Rafique et al., 2018; Sanjabi et al., 2018b; Nouiehed et al., 2019). It was shown in (Lu et al., 2019) that a deterministic FO min-max algorithm has O(1/T ) convergence rate. In (Qian et al., 2019; Rafique et al., 2018), stochastic FO min-max methods have also been proposed, which yield the convergence rate in the order of O(1/ √ T ) and O(1/T 1/4 ), respectively. However, these works were restricted to unconstrained optimization at the minimization side. In (Sanjabi et al., 2018b), noncovnex-concave min-max problems were studied, but the proposed analysis requires solving the maximization problem only up to some small error. In (Nouiehed et al., 2019), the O(1/T ) convergence rate was proved for nonconvex-nonconcave min-max problems under Polyak- Łojasiewicz conditions. Different from the aforementioned FO settings, ZO min-max stochastic optimization suffers randomness from both stochastic sampling in objective function and ZO gradient estimation, and this randomness would be coupled in alternating gradient descent-descent steps and thus make it more challenging in convergence analysis.

Section Title: Gradient-free min-max optimization
  Gradient-free min-max optimization In the black-box setup, coevolutionary algorithms were used extensively to solve min-max problems (Herrmann, 1999; Schmiedlechner et al., 2018). However, they may oscillate and never converge to a solution due to pathological behaviors such as focusing and relativism (Watson & Pollack, 2001). Fixes to these issues have been proposed and analyzed-e.g., Under review as a conference paper at ICLR 2020 asymmetric fitness (Jensen, 2003; Branke & Rosenbusch, 2008). In (Al-Dujaili et al., 2018c), the authors employed an evolution strategy as an unbiased approximate for the descent direction of the outer minimization problem and showed empirical gains over coevlutionary techniques, albeit without any theoretical guarantees. Min-max black-box problems can also be addressed by resorting to direct search and model-based descent and trust region methods (Audet & Hare, 2017; Larson et al., 2019; Rios & Sahinidis, 2013). However, these methods lack convergence rate analysis and are difficult to scale to high-dimensional problems. For example, the off-the-shelf model-based solver COBYLA only supports problems with 2 16 variables at maximum in SciPy Python library (Jones et al., 2001), which is even smaller than the size of a single ImageNet image. The recent work (Bogunovic et al., 2018) proposed a robust Bayesian optimization (BO) algorithm and established a theoretical lower bound on the required number of the min-max objective evaluations to find a near-optimal point. However, BO approaches are often tailored to low-dimensional problems and its computational complexity prohibits scalable application. From a game theory perspective, the min-max solution for some problems correspond to the Nash equilibrium between the outer minimizer and the inner maximizer, and hence black-box Nash equilibria solvers can be used (Picheny et al., 2019; Al-Dujaili et al., 2018a). This setup, however, does not always hold in general. Our work contrasts with the above lines of work in designing and analyzing black-box min-max techniques that are both scalable and theoretically grounded.

Section Title: PROBLEM SETUP
  PROBLEM SETUP In this section, we define the black-box min-max problem and briefly motivate its applications. By min-max, we mean that the problem is a composition of inner maximization and outer minimization of the objective function f . By black-box, we mean that the objective function f is only accessible via point-wise functional evaluations. Mathematically, we have min x∈X max y∈Y f (x, y) (1) where x and y are optimization variables, f is a differentiable objective function, and X ⊂ R dx and Y ⊂ R dy are compact convex sets. For ease of notation, let d x = d y = d. In (1), the objective function f could represent either a deterministic loss or stochastic loss f (x, y) = E ξ∼p [f (x, y; ξ)], where ξ is a random variable following the distribution p. In this paper, we consider the stochastic variant in (1). We focus on two black-box scenarios in which gradients (or stochastic gradients under randomly sampled ξ) of f w.r.t. x or y are not accessed. (a) One-sided black-box: f (x, y) is a white box w.r.t. y but a black box w.r.t. x. (b) Two-sided black-box: f (x, y) is a black box w.r.t. both x and y. Motivation of setup (a) and (b). Both setups are well motivated from the design of black-box adversarial attacks. The formulation of the one-sided black-box min-max problem corresponds to a particular type of attack, known as black-box ensemble evasion attack, where the attacker generates adversarial examples (i.e., crafted examples with slight perturbations for misclassification at the testing phase) and optimizes its worst-case performance against an ensemble of black-box classifiers and/or example classes. The formulation of two-sided black-box min-max problem represents another type of attack at the training phase, known as black-box poisoning attack, where the attacker deliberately influences the training data (by injecting poisoned samples) to manipulate the results of a black-box predictive model. Although problems of designing ensemble evasion attack (Liu et al., 2016; 2018a; Wang et al., 2019b) and data poisoning attack (Jagielski et al., 2018; Wang et al., 2019a) have been studied in the literature, most of them assumed that the adversary has the full knowledge of the target ML model, leading to an impractical white-box attack setting. By contrast, we provide a solution to min-max attack generation under black-box ML models. We refer readers to Section 6 for further discussion and demonstration of our framework on these problems.

Section Title: ZO-MIN-MAX: A FRAMEWORK FOR BLACK-BOX MIN-MAX OPTIMIZATION
  ZO-MIN-MAX: A FRAMEWORK FOR BLACK-BOX MIN-MAX OPTIMIZATION Our interest is in a scalable and theoretically principled framework for black-box min-max problems of the form (1). To this end, we first introduce a randomized gradient estimator that only requires a few number of point-wise function evaluations. Based on that, we then propose a ZO alternating projected gradient method to solve (1) under both one-sided and two-sided black-box setups.

Section Title: Randomized gradient estimator
  Randomized gradient estimator In the ZO setting, we adopt a randomized gradient estimator to estimate the gradient of a function with the generic form h(x) := E ξ [h(x; ξ)] (Liu et al., 2019; Gao et al., 2014), ∇xh(x) = 1 bq j∈I q i=1 d[h(x + µui; ξ j ) − h(x; ξ j )] µ ui, (2) where d is number of variables, I denotes the mini-batch set of b i.i.d. stochastic samples {ξ j } b j=1 , {u i } q i=1 are q i.i.d. random direction vectors drawn uniformly from the unit sphere, and µ > 0 is a smoothing parameter. We note that the ZO gradient estimator (2) involves randomness from both stochastic sampling w.r.t. u i as well as the random direction sampling w.r.t. ξ j . It is known from (Gao et al., 2014, Lemma 2) that ∇ x h(x) provides an unbiased estimate of the gradient of the smoothing function of h rather than the true gradient of h. Here the smoothing function of h is defined by h µ (x) = E v [h(x + µv)], where v follows the uniform distribution over the unit Euclidean ball. Besides the bias, we provide an upper bound on the variance of (2) in Lemma 1. where the expectation is taken over all randomness. Proof: See Appendix A.2. In Lemma 1, if we choose µ ≤ 1/ √ d, then the variance bound is given by O(1/b + d/q). In our problem setting (1), the ZO gradients ∇ x f (x, y) and ∇ y f (x, y) follow the generic form of (2) by fixing y and letting h(·) := f (·, y) or by fixing x and letting h(·) := f (x, ·), respectively.

Section Title: Algorithmic framework
  Algorithmic framework To solve problem (1), we alternatingly perform ZO projected gradient descent/ascent method for updating x and y. Specifically, for one-sided ZO min-max optimization, the ZO projected gradient descent (ZO-PGD) over x yields x (t) = proj X x (t−1) − α ∇xf x (t−1) , y (t−1) , (4) where t is the iteration index, ∇ x f denotes the ZO gradient estimate of f w.r.t. x, α > 0 is the learning rate at the x-minimization step, and proj X (a) signifies the projection of a onto X , given by the solution to the problem min x∈X x − a 2 2 . For two-sided ZO min-max optimization, in addition to (4), our update on y obeys the ZO projected gradient ascent (ZO-PGA) y (t) = proj Y y (t−1) + β ∇yf x (t) , y (t−1) , (5) where β > 0 is the learning rate at the y-maximization step. The proposed method is named as ZO-Min-Max; see Algorithm 1. Why estimates gradient rather than distribution of function values? Besides ZO optimization using random gradient estimates, the black-box min-max problem (1) can also be solved using the Bayesian optimization (BO) approach, e.g., (Bogunovic et al., 2018; Al-Dujaili et al., 2018a). The core idea of BO is to approximate the objective function as a Gaussian process (GP) learnt from the history of function values at queried points. Based on GP, the solution to problem (1) is then updated by maximizing a certain reward function, known as acquisition function. The advantage of BO is Under review as a conference paper at ICLR 2020 its mild requirements on the setting of black-box problems, e.g., at the absence of differentiability. However, BO usually does not scale beyond low-dimensional problems since learning the accurate GP model and solving the acquisition problem takes intensive computation cost per iteration. By contrast, our proposed method is more efficient, and mimics the first-order method by just using the random gradient estimate (2) as the descent/ascent direction. In Figure A1, we compare ZO-Min-Max with the BO based STABLEOPT algorithm proposed by (Bogunovic et al., 2018) through a toy example shown in (Bogunovic et al., 2018, Sec. 5). As we can see, ZO-Min-Max not only achieves more accurate solution but also requires less computation time. We refer readers to Appendix B for details. The convergence analysis of ZO-Min-Max is more challenging than the case of FO min-max algorithms. Besides the inaccurate estimate of the gradient, the stochasticity of the estimator makes the convergence analysis sufficiently dif- ferent from the FO deterministic case (Lu et al., 2019; Qian et al., 2019), since the errors in min- imization and maximization are coupled as the algorithm proceeds. Moreover, the conventioanl analysis of ZO op- timization for single-objective problems cannot directly be applied to ZO-Min-Max. Even at the one-sided black-box setting, ZO-Min-Max conducts alternating optimization using one-step ZO-PGD and PGA with respect to x and y re- spectively. This is different from a reduced ZO optimization problem with respect to x only by solving problem min x∈X h(x) := min y∈Y f (x, y), which requires the algorithm to obtain the solu- tion to min y∈Y f (x, y) at a given x (when querying h(x) for a ZO gradient estimation). However, this process is usually non-trivial or computationally intensive. In particular, one key difficulty stems from the alternating algorithmic structure (namely, primal-dual framework) as the problem is in the min-max form, which leads to opposite optimization directions (minimization vs maximization) over variable x and y respectively. Even applying ZO optimization only to one side, it needs to quantify the effect of ZO gradient estimation on the descent over both x and y. We provide a detailed convergence analysis of ZO-Min-Max in the next section.

Section Title: CONVERGENCE ANALYSIS
  CONVERGENCE ANALYSIS We begin by elaborating on assumptions and notations used in analyzing the convergence of ZO-Min- Max (Algorithm 1). A1: In (1), f (x, y) is continuously differentiable, and is strongly concave w.r.t. y with parameter all points y 1 , y 2 ∈ Y. And f is lower bounded by a finite number f * and has bounded gradients ∇ x f (x, y; ξ) ≤ η 2 and ∇ y f (x, y; ξ) ≤ η 2 for stochastic optimization with ξ ∼ p. Here · denotes the 2 norm. The constraint sets X , Y are convex and bounded with diameter R. A2: f (x, y) has Lipschitz continuous gradients, i.e., there exists We note that A1 and A2 are required for analyzing the convergence of ZO-Min-Max. They were used even for the analysis of first-order min-max optimization methods (Lu et al., 2019; Nouiehed et al., 2019) and first-order methods for nonconvex optimization with a single objective function (Chen et al., 2019; Ward et al., 2019). In A1, the strongly concavity of f (x, y) with respect to y holds for applications such as robust learning over multiple domains (Qian et al., 2019), and adversarial attack generation that will be introduced in Section 6. In A2, the assumption of smoothness Under review as a conference paper at ICLR 2020 (namely, Lipschitz continuous gradient) is required to quantify the descent of the alternating projected stochastic gradient descent-ascent method. Even for single-objective non-convex optimization, e.g., (Chen et al., 2019; Bernstein et al., 2018), A2 is needed in analysis. For clarity, we also summarize the problem and algorithmic parameters used in our convergence analysis in Table A1 of Appendix. We measure the convergence of ZO-Min-Max by the proximal gradient (Lu et al., 2019; Ghadimi et al., 2016), where (x, y) is a first-order stationary point of (1) iff G(x, y) = 0. In what follows, we delve into our convergence analysis. First, Lemma 2 shows the descent property of ZO-PGD at the x-minimization step in Algorithm 1. Lemma 2. (Descent lemma in minimization) Under A1-A2, let (x (t) , y (t) ) be a sequence generated by Algorithm 1. When f (x, y) is black-box w.r.t. x, then we have following descent property w.r.t. x: Proof: See Appendix A.3.1. It is clear from Lemma 2 that updating x leads to the reduced objective value when choosing a small learning rate α. However, ZO gradient estimation brings in additional errors in terms of ασ 2 x and L x µ 2 , where the former is induced by the variance of gradient estimates in (3) and the latter is originated from bounding the distance between f and its smoothing version; see (25) in Appendix A.3.

Section Title: Convergence rate of ZO-Min-Max by performing PGA
  Convergence rate of ZO-Min-Max by performing PGA We next investigate the convergence of ZO-Min-Max when FO PGA is used at the y-maximization step (Line 8 of Algorithm 1) for solving one-sided black-box optimization problems. Lemma 3. (Descent lemma in maximization) Under A1-A2, let (x (t) , y (t) ) be a sequence generated by Algorithm 1 and define the potential function as where ∆ (t) y := y (t) − y (t−1) . When f (x, y) is black-box w.r.t. x and white-box w.r.t. y, then we have the following descent property w.r.t. y: It is shown from (9) that when β is small enough, then the term (1/(2β) − 2L 2 y /γ)E ∆ (t+1) y 2 will give some descent of the potential function after performing PGA, while the last term in (9) will give some ascent to the potential function. However, such a quantity will be compensated by the descent of the objective function in the minimization step shown by Lemma 2. Combining Lemma 2 and Lemma 3, we obtain the convergence rate of ZO-Min-Max in Theorem 1. To better interpret Theorem 1, we begin by clarifying the parameters involved in our convergence rate (10). First, the parameter ζ appears in the denominator of the derived convergence error. However, ζ has a non-trivial lower bound given appropriate learning rates α and β (see Remark 1 that we will show later). Second, the parameter c is inversely proportional to α and β. Thus, to guarantee the constant effect of the ratio c/ξ, it is better not to set these learning rates too small; see a specification in Remark 1-2. Third, the parameter ν is non-negative and appears in terms of −νR 2 , thus, it will not make convergence rate worse. Fourth, P 1 is the initial value of the potential function (8). By setting an appropriate learning rate β (e.g., following Remark 2), P 1 is then upper bounded by a constant determined by the initial value of the objective function, the distance of the first two updates, Lipschitz constant L y and strongly concave parameter γ. We next provide Remarks 1-3 on Theorem 1. Thus, we obtain that ζ ≥ min{ 2L 2 y γ , 2L 2 x γ + Lx 2 }. This justifies that ζ has a non-trivial lower bound, which will not make the convergence error bound (10) vacuous (although the bound has not been optimized over α and β). Remark 2. It is not wise to set learning rates α and β to extremely small values since c is inversely proportional to α and β. Thus, we typically choose β = γ 8L 2 y and α = 1/(L x + 4L 2 x γ 2 β + βL 2 x ) in Remark 1 to guarantee the constant effect of c/ζ. Remark 3. By setting µ ≤ min{1/ √ d, 1/ √ T }, we obtain σ 2 x = O(1/b + d/q) from Lemma 1, and Theorem 1 implies that ZO-Min-Max yields O(1/T + 1/b + d/q) convergence rate for one-sided black-box optimization. Compared to the FO rate O(1/T ) (Lu et al., 2019; Sanjabi et al., 2018a), ZO-Min-Max converges only to a neighborhood of stationary points with O(1/T ) rate, where the size of the neighborhood is determined by the mini-batch size b and the number of random direction vectors q used in ZO gradient estimation. It is also worth mentioning that such a stationary gap may exist even in the FO/ZO projected stochastic gradient descent for solving single-objective minimization problems (Ghadimi et al., 2016). As shown in Remark 3, ZO-Min-Max could result in a stationary gap. A large mini-batch size b or number of random direction vectors q can improve its iteration complexity. However, this requires O(bq) times more function queries per iteration from (2). It implies the tradeoff between iteration complexity and function query complexity in ZO optimization.

Section Title: Convergence rate of ZO-Min-Max by performing ZO-PGA
  Convergence rate of ZO-Min-Max by performing ZO-PGA We now focus on the convergence analysis of ZO-Min-Max when ZO PGA is used at the y-maximization step (Line 6 of Algorithm 1) for two-sided black-box optimization problems. Lemma 4. (Descent lemma in maximization) Under A1-A2, let (x (t) , y (t) ) be a sequence generated by Algorithm 1 and define the potential function as When function f (x, y) is black-box w.r.t. both x and y, we have the following descent w.r.t. y: Proof: See Appendix A.4.2. Following the similar argument in Remark 1 of Theorem 1, one can choose proper learning rates α and β to obtain valid lower bound on ζ . However, different from Theorem 1, the convergence error shown by Theorem 2 involves an additional error term related to σ 2 y and has worse dimension-dependence on the term related to µ 2 . The latter yields a more restricted choice of the smoothing parameter µ: we obtain O(1/T + 1/b + d/q) convergence rate when µ ≤ 1/(d √ T ).

Section Title: EXPERIMENTS
  EXPERIMENTS In this section, we evaluate the empirical performance of ZO-Min-Max on applications of adversarial exploration: 1) design of black-box ensemble attack against two neural networks Inception-V3 (Szegedy et al., 2016) and ResNet-50 (He et al., 2016) under ImageNet (Deng et al., 2009), and 2) design of black-box poisoning attack against a logistic regression model.

Section Title: Black-box ensemble evasion attack via universal perturbation
  Black-box ensemble evasion attack via universal perturbation We consider the scenario in which the attacker generates adversarial examples against an ensemble of multiple classifiers and/or image classes (Liu et al., 2016; 2018a). More formally, let (z, l) denote a legitimate image z with the true class label l, and z := z + x denote an adversarial example, where x signifies the adversarial perturbation. Here the natural image z and the perturbed image z + x are normalized to [−0.5, 0.5] d . Considering I classes of images (each group of images corresponding to the same class l i is denoted by Ω i ) and J network models, the adversary is to find the universal perturbation x across I image classes and J models. The proposed attack problem is given by minimize x∈X maximize w∈W f1(x, w) := J j=1 I i=1 [wijFij (x; Ωi, li)] − λ w − 1/(IJ) 2 2 , (13) where x and w ∈ R IJ are optimization variables, and w ij denotes the (i, j)th entry of w correspond- ing to the importance weight of attacking image class i under neural network model j. In problem (13), X denotes the perturbation constraint, e.g., X = {x | x ∞ ≤ , z + x ∈ [−0.5, 0.5] d , ∀z ∈ ∪ i Ω i }, W = {w | 1 T w = 1, w ≥ 0}, F ij (x; Ω i , l i ) is the attack loss for attacking the set of images at class l i under model j, and λ > 0 is a regularization parameter. We note that {F ij } in (13) are black-box functions w.r.t. x since the network models are blind to the adversary, which cannot perform back-propagation to obtain gradients. By contrast, it is a white-box and strongly concave function w.r.t. w once the function values of {F ij } are given. Thus, problem (13) belongs to the one-sided black-box optimization problem. In our experiments, we consider J = 2 for Inception-V3 and ResNet-50, and I = 2 for two classes, each of which contains 20 images randomly selected from ImageNet (Deng et al., 2009). We also Under review as a conference paper at ICLR 2020 specify the attack loss F ij in (13) as the C&W untargeted attack loss (Carlini & Wagner, 2017), Fij (x; Ωi, li) = (1/|Ωi|) z∈Ω i max{gj(z + x) l i − max k =l i gj(z + x) k , 0}, (14) where |Ω i | is the cardinality of the set Ω i , g j (z + x) k denotes the prediction score of class k given the input z + x using model j. In (13), we also set λ = 5. In Algorithm 1, we set α = 0.05, β = 0.01, q = 10 and µ = 5 × 10 −3 , and use the full batch of image samples in attack generation. In experiment, we compare ZO-Min-Max with FO-Min-Max and ZO-Finite-Sum, where the former is the FO counterpart of Algorithm 1, and the latter is ZO-PSGD (Ghadimi et al., 2016) to minimize the finite-sum (average) loss rather than the worst-case (min-max) loss. The comparison with ZO- Finite-Sum was motivated by the previous work on designing the adversarial perturbation against model ensembles (Liu et al., 2018a) in which the averaging attack loss over multiple models was considered. Note that although ZO-Finite-Sum consider a different loss function, it is a baseline from the perspective of attack generation. In  Figure 1 , we demonstrate the empirical convergence of ZO-Min-Max to solve problem (13) from the stationary gap G(x, y) 2 given in (6) and the attack loss F ij under each model-class pair. In Figure 1-(a), the stationary gap decreases as the iteration increases, which is consistent with the reduction in the attack loss at each MjCi. Here M and C represents network model and image class, respectively. By comparing ZO-Min-Max with FO-Min-Max in Figure 1-(b), we see that the latter yields faster convergence than the former. However, FO-Min-Max has to access the full knowledge on the target neural network for computing the gradient of individual attack losses, yielding white-box attack rather than black-box attack. In Figure 1-(c), We also compare ZO-Min-Max with ZO-Finite- Sum, where the latter minimizes the average loss J j=1 I i=1 F ij over all model-class combinations. As we can see, our approach significantly improves the worst-case attack performance (corresponding to M1C1). Here the worst case represents the most robust model-class pair against the attack. This suggests that ZO-Min-Max takes into account different robustness levels of model-class pairs through the design of importance weights w. This can also be evidenced from Figure A2 in Appendix: M1C1 has the largest weight while M2C2 corresponds to the smallest weight. In Figure A3 of Appendix, we further contrast the success or failure of attacking each image using the obtained universal perturbation x with the attacking difficulty (in terms of required iterations for successful adversarial example) of using per-image non-universal PGD attack (Madry et al., 2017b). Black-box poisoning attack against logistic regression model Let D = {z i , t i } n i=1 denote the training dataset, among which n n samples are corrupted by a perturbation vector x, leading to poisoned training data z i + x towards breaking the training process and thus the prediction accuracy. The poisoning attack problem is then formulated as maximize x ∞ ≤ minimize θ f2(x, θ) := Ftr(x, θ; D0) + λ θ 2 2 , (15) where x and θ are optimization variables, F tr (x, θ; D 0 ) denotes the training loss over model parame- ters θ at the presence of data poison x, and λ > 0 is a regularization parameter. Note that problem (15) can be written in the form of (1) with the objective function −f 2 (x, θ). Clearly, if F tr is a convex Under review as a conference paper at ICLR 2020 loss (e.g., logistic regression or linear regression (Jagielski et al., 2018)), then −f 2 is strongly concave in θ. Since the adversary has no knowledge on the training procedure and data, f 2 (x, θ) is a two-sided black-box function. We provide more details on problem (15) in Appendix C. In Algorithm 1, unless specified otherwise we choose b = 100, q = 5, α = 0.02, β = 0.05, and T = 50000. We report the empirical results averaged over 10 independent trials with random initialization. We compare our method with FO-Min-Max and the BO solver for robust optimization STABLEOPT (Bogunovic et al., 2018) in the data poisoning example of a relatively small problem size. In  Figure 2 , we present the convergence performance of ZO-Min-Max to generate the data poi- soning attack and validate its attack performance in terms of testing accuracy of the logistic regression model trained on the poisoned dataset. Unless specified otherwise, we set 15% poi- soning ratio and λ = 10 −3 for problem (15). We examine the sensitivity of the regulariza- tion parameter λ in Figure A4. Figure 2-(a) shows the stationary gap defined in (6) obtained by ZO-Min-Max under different number of random direction vectors while estimating gradi- ents (2). As we can see, a moderate choice of q (e.g., q ≥ 5 in our example) is sufficient to achieve near-optimal solution compared with FO-Min-Max. However, it suffers from a con- vergence bias due to the presence of stochastic sampling, consistent with Theorem 1 and 2. Figure 2-(b) demonstrates the testing accuracy (against itera- tions) of the model learnt from poisoned training data, where the poisoning attack is generated by ZO-Min-Max (black-box attack) and FO-Min-Max (white-box attack). As we can see, ZO-Min-Max yields promising attacking performance compa- rable to FO-Min-Max. We can also see that by contrast with the testing accuracy of the clean model (94% without poison), the poisoning attack eventually reduces the testing accuracy (below 70%). Furthermore, in Figure 2-(c), we present the testing ac- curacy of the learnt model under different data poisoning ratios. As we can see, only 5% poisoned training data can significantly break the testing accuracy of a well-trained model. In  Figure 3 , we compare ZO-Min-Max with STABLEOPT (Bogunovic et al., 2018) in terms of testing accuracy versus computation time. Fol- lowing (Bogunovic et al., 2018), we present the best accuracy achieved up to the current time step. We observe that STABLEOPT is has a poorer scalability while our method reaches a data poisoning attack that induces much worse testing accuracy within 500 seconds.

Section Title: CONCLUSION
  CONCLUSION This paper addresses black-box robust optimization problems given a finite number of function evaluations. In particular, we present ZO-Min-Max: a framework of alternating, randomized gradient estimation based ZO optimization algorithm to find a first-order stationary solution to the black-box min-max problem. Under mild assumptions, ZO-Min-Max enjoys a sub-linear convergence rate. It scales to dimensions that are infeasible for recent robust solvers based on Bayesian optimization. Furthermore, we experimentally demonstrate the potential application of the framework on real-world scenarios, viz. black-box evasion and data poisoning attacks.

```
